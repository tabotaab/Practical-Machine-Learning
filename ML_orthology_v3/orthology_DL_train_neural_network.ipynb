{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from Bio import SeqIO\n",
    "from Bio.Data import IUPACData \n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "\n",
    "#data_path = 'features_CENH3_DMR6_LUCA-CHLRE00002_orthologues.csv'\n",
    "#data_path = 'features_oma-seqs-viridiplantae_test-7-8.csv'\n",
    "#data_path = 'features_oma-seqs-viridiplantae_test-5-6-7-8.csv'\n",
    "#data_path = 'features_oma-seqs-viridiplantae_test-4-5-6-7-8-9.csv'\n",
    "data_path = 'features_oma-seqs-viridiplantae_test-4-5-6-7-8-9-10.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def protein2integer(in_seq):\n",
    "    \n",
    "    ## define universe of possible input values\n",
    "    all_protein_letters = list(IUPACData.extended_protein_letters)\n",
    "    #print(all_protein_letters)\n",
    "    ## define a mapping of chars to integers \n",
    "    ## i+1 beacuse we want to start from integer 1 instead of 0. 0 will be used for padding\n",
    "    char_to_int = dict((c, i+1) for i, c in enumerate(all_protein_letters))\n",
    "    int_to_char = dict((i+1, c) for i, c in enumerate(all_protein_letters))\n",
    "    ## integer encode input data\n",
    "    integer_encoded = [char_to_int[char] for char in in_seq.upper()]\n",
    "    \n",
    "    \n",
    "    #return(integer_encoded,len(all_protein_letters))\n",
    "    return(integer_encoded)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(in_file):\n",
    "    with open(in_file, 'r') as f:\n",
    "        reader = csv.reader(f, delimiter=\"\\t\")\n",
    "        # get all the rows as a list\n",
    "        d_set = list(reader)\n",
    "        # transform data into numpy array\n",
    "        d_set = np.array(d_set).astype(str)\n",
    "        \n",
    "    integer_encoded_proteins = np.array([protein2integer(seq) for seq in d_set[:,1]])\n",
    "    \n",
    "    G = d_set[:, 0]\n",
    "    X = integer_encoded_proteins\n",
    "    Y = d_set[:, 2].astype(int)\n",
    "                         \n",
    "    return(d_set,G,X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_dask(in_file):\n",
    "    data = dd.read_csv(in_file,sep='\\t', header=None)\n",
    "    df = data.compute().reset_index(drop=True)\n",
    "    integer_encoded_proteins = da.from_array([protein2integer(seq) for seq in df.values[:,1]],chunks=1000)\n",
    "    G = df.values[:,0]\n",
    "    X = integer_encoded_proteins.compute()\n",
    "    Y = df.values[:,2].astype(int)\n",
    "                     \n",
    "    return(df,G,X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_test_set_idea1(G,X,Y):\n",
    "    \n",
    "    # here we keep 80% of random indexes in train set and the rest in test set\n",
    "    \n",
    "    indices = np.random.permutation(X.shape[0])\n",
    "    train_size = int(indices.size*0.80)\n",
    "    train_idx, test_idx = indices[:train_size], indices[train_size:]\n",
    "    #print(len(train_idx),len(test_idx))\n",
    "    \n",
    "    X_train, X_test = X[train_idx,], X[test_idx,]\n",
    "    #print(X_train.shape,X_test.shape)\n",
    "    \n",
    "    y_train, y_test = Y[train_idx,], Y[test_idx,]\n",
    "    \n",
    "    #print(X[train_idx[0],])\n",
    "    #print(Y[train_idx[0],])\n",
    "\n",
    "    #print(X_train[0,])\n",
    "    #print(y_train[0,])\n",
    "    \n",
    "    return(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_test_set_idea2(G,X,Y):\n",
    "    \n",
    "    # here we try to keep one item from each cluster in test set\n",
    "    # the rest goes to train set\n",
    "    \n",
    "    test_idx = []\n",
    "    train_idx = []\n",
    "    seen_cluster_id = []\n",
    "    \n",
    "    for i in range(0,Y.shape[0]):\n",
    "            if Y[i] in seen_cluster_id :\n",
    "                train_idx.append(i)\n",
    "            else:\n",
    "                test_idx.append(i)\n",
    "                seen_cluster_id.append(Y[i])\n",
    "                \n",
    "    #print(len(train_idx),len(test_idx))\n",
    "    \n",
    "    X_train, X_test = X[train_idx,], X[test_idx,]\n",
    "    #print(X_train.shape,X_test.shape)\n",
    "    \n",
    "    y_train, y_test = Y[train_idx,], Y[test_idx,]\n",
    "    \n",
    "    #print(X[train_idx[0],])\n",
    "    #print(Y[train_idx[0],])\n",
    "\n",
    "    #print(X_train[0,])\n",
    "    #print(y_train[0,])\n",
    "    \n",
    "    return(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1(X_train_new, y_train,X_test_new, y_test,in_batch_size=100,in_epochs=10): # RNN: Recurrent Neural Networks\n",
    "    # https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
    "    # create the model\n",
    "    embedding_vecor_length = 4\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(num_letters, embedding_vecor_length, input_length=fixed_seq_length))\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(LSTM(75))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='rmsprop', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    \n",
    "#''' \n",
    "#    model.fit(X_train_new, y_train, epochs=in_epochs, batch_size=in_batch_size) #epochs=3, batch_size=64)\n",
    "#    ## Final evaluation of the model\n",
    "#    scores = model.evaluate(X_test_new, y_test, verbose=0)\n",
    "#    print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "#'''\n",
    "\n",
    "\n",
    "    # Convert labels to categorical one-hot encoding & fit the model\n",
    "    y_train_one_hot_labels = to_categorical(y_train, num_classes=n_classes)\n",
    "    model.fit(X_train_new, y_train_one_hot_labels, epochs=in_epochs, batch_size=in_batch_size)\n",
    "\n",
    "#    y_train_one_hot_labels = to_categorical(y_train, num_classes=n_classes)\n",
    "#    model.fit(X_train_new, y_train_one_hot_labels, epochs=in_epochs, verbose=1)\n",
    "\n",
    "    # evaluate the model\n",
    "    y_test_one_hot_labels = to_categorical(y_test, num_classes=n_classes)\n",
    "    loss, accuracy = model.evaluate(X_test_new, y_test_one_hot_labels, verbose=0)\n",
    "    print('Accuracy: %f' % (accuracy*100))\n",
    "    \n",
    "    return()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2(X_train_new, y_train,X_test_new, y_test,in_batch_size=100,in_epochs=10): # RNN: Recurrent Neural Networks\n",
    "    # Initializing the Sequential model from KERAS.\n",
    "    model = Sequential()\n",
    "\n",
    "    # Creating a 16 neuron hidden layer with Linear Rectified activation function.\n",
    "    #model.add(Dense(16, input_dim=1, init='uniform', activation='relu'))\n",
    "    model.add(Dense(16, input_dim=fixed_seq_length, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "    # Creating a 8 neuron hidden layer.\n",
    "    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "    # Adding a output layer.\n",
    "    model.add(Dense(n_classes, kernel_initializer='uniform', activation='softmax'))\n",
    "    \n",
    "    # Compiling the model\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "   \n",
    "    # Convert labels to categorical one-hot encoding & fit the model\n",
    "    y_train_one_hot_labels = to_categorical(y_train, num_classes=n_classes)\n",
    "    model.fit(X_train_new, y_train_one_hot_labels, epochs=in_epochs, batch_size=in_batch_size)\n",
    "\n",
    "    # fit the model\n",
    "#    y_train_one_hot_labels = to_categorical(y_train, num_classes=n_classes)\n",
    "#    model.fit(X_train_new, y_train_one_hot_labels, epochs=in_epochs, verbose=1)\n",
    "\n",
    "    # evaluate the model\n",
    "    y_test_one_hot_labels = to_categorical(y_test, num_classes=n_classes)\n",
    "    loss, accuracy = model.evaluate(X_test_new, y_test_one_hot_labels, verbose=0)\n",
    "    print('Accuracy: %f' % (accuracy*100))\n",
    "    \n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_matrix(labels,C):\n",
    "    \n",
    "    C = tf.constant(C,name=\"C\")\n",
    "    one_hot_matrix = tf.one_hot(labels,C,axis=1)\n",
    "    sess = tf.Session()\n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    sess.close()\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model3(X_train_new, y_train,X_test_new, y_test, batch_size =100, hm_epochs =100): # CNN: Convolutional Neural Networks\n",
    "    # Number of nodes in each NN hidden layer\n",
    "    n_nodes_hl1 = 1500\n",
    "    n_nodes_hl2 = 1500\n",
    "    n_nodes_hl3 = 1500\n",
    "\n",
    "    # Number of orthology clusters\n",
    "    #n_classes = len(np.unique(np.concatenate((y_train,y_test),axis=0)))     #2 or 3 or ...\n",
    "    \n",
    "    #y_all = np.concatenate((y_train,y_test),axis=0)\n",
    "    #y_min = np.amin(y_all)\n",
    "    #n_classes = np.amax(y_all-y_min)+1\n",
    "    \n",
    "    \n",
    "    train_y = one_hot_matrix(y_train,n_classes)\n",
    "    test_y = one_hot_matrix(y_test,n_classes)\n",
    "\n",
    "    # Batch size and Epoch size for training the NN\n",
    "    #batch_size = 100   #100\n",
    "    #hm_epochs = 100    #1000\n",
    "\n",
    "    # Initializing X and Y\n",
    "    x = tf.placeholder('float')\n",
    "    y = tf.placeholder('float')\n",
    "\n",
    "    # Initializing NN layers\n",
    "    hidden_1_layer = {'f_fum':n_nodes_hl1,\n",
    "                  'weight':tf.Variable(tf.random_normal([len(X_train_new[0]), n_nodes_hl1])),\n",
    "                  'bias':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "\n",
    "    hidden_2_layer = {'f_fum':n_nodes_hl2,\n",
    "                  'weight':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
    "                  'bias':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "\n",
    "    hidden_3_layer = {'f_fum':n_nodes_hl3,\n",
    "                  'weight':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n",
    "                  'bias':tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
    "\n",
    "    output_layer = {'f_fum':None,\n",
    "                'weight':tf.Variable(tf.random_normal([n_nodes_hl3, n_classes])),\n",
    "                'bias':tf.Variable(tf.random_normal([n_classes])),}\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    l1 = tf.add(tf.matmul(x,hidden_1_layer['weight']), hidden_1_layer['bias'])\n",
    "    l1 = tf.nn.relu(l1)\n",
    "\n",
    "    l2 = tf.add(tf.matmul(l1,hidden_2_layer['weight']), hidden_2_layer['bias'])\n",
    "    l2 = tf.nn.relu(l2)\n",
    "\n",
    "    l3 = tf.add(tf.matmul(l2,hidden_3_layer['weight']), hidden_3_layer['bias'])\n",
    "    l3 = tf.nn.relu(l3)\n",
    "\n",
    "    prediction = tf.matmul(l3,output_layer['weight']) + output_layer['bias']\n",
    "\n",
    "        \n",
    "    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction,labels=y) )\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        #try:\n",
    "        #    epoch = int(open(tf_log,'r').read().split('\\n')[-2])+1\n",
    "        #    print('STARTING:',epoch)\n",
    "        #except:\n",
    "        #    epoch = 1\n",
    "        epoch = 1\n",
    "\n",
    "        while epoch <= hm_epochs:\n",
    "            epoch_loss = 1\n",
    "            \n",
    "            i=0\n",
    "            while i < len(X_train_new):\n",
    "                start = i\n",
    "                end = i+batch_size\n",
    "                batch_x = np.array(X_train_new[start:end])\n",
    "                batch_y = np.array(train_y[start:end])\n",
    "\n",
    "                _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,y: batch_y})\n",
    "                epoch_loss += c\n",
    "                i+=batch_size\n",
    "                \n",
    "            \n",
    "            print('Epoch ',epoch,' out of ',hm_epochs,'- loss:',epoch_loss)\n",
    " \n",
    "            \n",
    "            #with open(tf_log,'a') as f:\n",
    "            #    f.write(str(epoch)+'\\n') \n",
    "            epoch +=1\n",
    "            \n",
    "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "\n",
    "        #print(\"\\nModel saved in path: %s \" % my_model_save_path)\n",
    "        print('\\nAccuracy:',accuracy.eval({x:X_test_new, y:test_y}) * 100)\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model4(X_train_new, y_train,X_test_new, y_test,in_batch_size=100,in_epochs=10): # RNN: Recurrent Neural Networks\n",
    "    \n",
    "    # Convert labels to categorical one-hot encoding  \n",
    "    y_train_one_hot_labels = to_categorical(y_train, num_classes=n_classes)\n",
    "    y_test_one_hot_labels = to_categorical(y_test, num_classes=n_classes)\n",
    "    X_train_new_one_hot_labels = np.array([to_categorical(x, num_classes=num_letters) for x in X_train_new])\n",
    "    X_test_new_one_hot_labels = np.array([to_categorical(x, num_classes=num_letters) for x in X_test_new])\n",
    "\n",
    "    # create the model    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(75,input_shape=X_train_new_one_hot_labels[0].shape,return_sequences=True))\n",
    "    model.add(LSTM(75))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='rmsprop', metrics=['accuracy'])\n",
    "    print(model.summary())  \n",
    "\n",
    "    # fit the model\n",
    "    model.fit(X_train_new_one_hot_labels, y_train_one_hot_labels, epochs=in_epochs, batch_size=in_batch_size, verbose=1)\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test_new_one_hot_labels, y_test_one_hot_labels, verbose=0)\n",
    "    print('Accuracy: %f' % (accuracy*100))\n",
    "    \n",
    "    return()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model5(X_train_new, y_train,X_test_new, y_test,in_batch_size=100,in_epochs=10): # RNN: Recurrent Neural Networks\n",
    "    # LSTM\n",
    "    \n",
    "    # Convert labels to categorical one-hot encoding  \n",
    "    y_train_one_hot_labels = to_categorical(y_train, num_classes=n_classes)\n",
    "    y_test_one_hot_labels = to_categorical(y_test, num_classes=n_classes)\n",
    "\n",
    "    # create the model    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(num_letters, output_dim=fixed_seq_length))\n",
    "    model.add(LSTM(75,return_sequences=True))\n",
    "    model.add(LSTM(75))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='rmsprop', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "\n",
    "    # fit the model\n",
    "    model.fit(X_train_new, y_train_one_hot_labels, epochs=in_epochs, batch_size=in_batch_size)\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test_new, y_test_one_hot_labels, verbose=0)\n",
    "    print('Accuracy: %f' % (accuracy*100))\n",
    "    \n",
    "    return()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model6(X_train_new, y_train,X_test_new, y_test,in_batch_size=100,in_epochs=10): # RNN: Recurrent Neural Networks\n",
    "    # GRU\n",
    "    \n",
    "    # Convert labels to categorical one-hot encoding  \n",
    "    y_train_one_hot_labels = to_categorical(y_train, num_classes=n_classes)\n",
    "    y_test_one_hot_labels = to_categorical(y_test, num_classes=n_classes)\n",
    "    \n",
    "    # create the model    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(num_letters, output_dim=fixed_seq_length))\n",
    "    model.add(GRU(128, return_sequences=False))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "\n",
    "    # fit the model\n",
    "    model.fit(X_train_new, y_train_one_hot_labels, epochs=in_epochs, batch_size=in_batch_size)\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test_new, y_test_one_hot_labels, verbose=0)\n",
    "    print('Accuracy: %f' % (accuracy*100))\n",
    "    \n",
    "    return()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_model(model_json_file=\"model.json\",model_h5_file=\"model.h5\"):\n",
    "    # load json and create model\n",
    "    json_file = open(model_json_file, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(model_h5_file)\n",
    "    print(\"Loaded model from disk\")\n",
    " \n",
    "    # evaluate loaded model on test data\n",
    "    loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "    \n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model7(X_train_new, y_train,X_test_new, y_test,in_batch_size=100,in_epochs=10,model_json_file=\"model.json\",model_h5_file=\"model.h5\"): # RNN: Recurrent Neural Networks\n",
    "    # GRU\n",
    "    \n",
    "    # Convert labels to categorical one-hot encoding  \n",
    "    y_train_one_hot_labels = to_categorical(y_train, num_classes=n_classes)\n",
    "    y_test_one_hot_labels = to_categorical(y_test, num_classes=n_classes)\n",
    "    \n",
    "    # create the model    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(num_letters, output_dim=fixed_seq_length))\n",
    "    model.add(GRU(128, return_sequences=False))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "\n",
    "    # fit the model\n",
    "    model.fit(X_train_new, y_train_one_hot_labels, epochs=in_epochs, batch_size=in_batch_size)\n",
    "\n",
    "    # evaluate the model\n",
    "    #loss, accuracy = model.evaluate(X_test_new, y_test_one_hot_labels, verbose=0)\n",
    "    #print('Accuracy: %f' % (accuracy*100))\n",
    "    scores = model.evaluate(X_test_new, y_test_one_hot_labels, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[0], scores[0])) # Loss\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100)) # Accuracy\n",
    " \n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(model_json_file, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(model_h5_file)\n",
    "    print(\"Saved model to disk\")\n",
    "    \n",
    "    return()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_1(d_set):\n",
    "    print(d_set[:,0])\n",
    "    print(d_set[0:2,1])\n",
    "    print(d_set[:,2].astype(int))\n",
    "    print(d_set.shape)\n",
    "    print(d_set[:,1].shape)\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_2(d_set):\n",
    "    integer_encoded_proteins = np.array([protein2integer(seq) for seq in d_set[:,1]])\n",
    "    print(len(integer_encoded_proteins))\n",
    "    print(integer_encoded_proteins[0])\n",
    "    #np.array(integer_encoded_proteins).shape\n",
    "    print(integer_encoded_proteins.shape)\n",
    "    #protein2integer(dataset[:,1])\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_3(G,X,Y):\n",
    "    print(G.shape)\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "\n",
    "    print(G[0:3,])\n",
    "    print(X[0:3,])\n",
    "    print(Y[0:3,])\n",
    "    \n",
    "    print('Maximum review length: {}'.format(len(max(X, key=len))))\n",
    "    print('Minimum review length: {}'.format(len(min(X, key=len))))\n",
    "    \n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_4(X_train_new,X_train):\n",
    "    print(X_train_new.shape)\n",
    "    print(X_train_new[0,:])\n",
    "    print(X_train.shape)\n",
    "    print(X_train[0,])\n",
    "    return()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, G, X, Y = make_dataset(data_path)\n",
    "X_train,y_train,X_test,y_test = make_train_test_set_idea2(G,X,Y)\n",
    "\n",
    "#print(\"============ Test 1 =======================\")\n",
    "#test_1(dataset)\n",
    "#print(\"============ Test 2 =======================\")\n",
    "#test_2(dataset)\n",
    "#print(\"============ Test 3 =======================\")\n",
    "#test_3(G,X,Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_letters = len(list(IUPACData.extended_protein_letters)) # = 26\n",
    "#fixed_seq_length = len(max(X, key=len)) # maximum\n",
    "#fixed_seq_length = (sum(len(X[i,]) for i in range(X.shape[0]))/X.shape[0])  # average\n",
    "fixed_seq_length = 1000\n",
    "n_classes = int(np.amax(np.concatenate((y_train,y_test),axis=0))+1)\n",
    "# truncate and pad input sequences\n",
    "X_train_new = sequence.pad_sequences(X_train, maxlen=fixed_seq_length, padding='post', truncating='post')\n",
    "X_test_new = sequence.pad_sequences(X_test, maxlen=fixed_seq_length, padding='post', truncating='post')\n",
    "  \n",
    "#print(\"============ Test 4 =======================\")\n",
    "#test_4(X_train_new,X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1(X_train_new, y_train, X_test_new, y_test,256,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 16)                16016     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15999)             143991    \n",
      "=================================================================\n",
      "Total params: 160,143\n",
      "Trainable params: 160,143\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1000\n",
      "9719/9719 [==============================] - 5s 500us/step - loss: 9.1196 - acc: 3.0867e-04\n",
      "Epoch 2/1000\n",
      "9719/9719 [==============================] - 5s 486us/step - loss: 7.8655 - acc: 2.0578e-04\n",
      "Epoch 3/1000\n",
      "9719/9719 [==============================] - 5s 468us/step - loss: 7.4646 - acc: 2.0578e-04\n",
      "Epoch 4/1000\n",
      "9719/9719 [==============================] - 4s 462us/step - loss: 7.2126 - acc: 0.0014\n",
      "Epoch 5/1000\n",
      "9719/9719 [==============================] - 4s 448us/step - loss: 6.9559 - acc: 0.0016\n",
      "Epoch 6/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 6.6778 - acc: 0.0017\n",
      "Epoch 7/1000\n",
      "9719/9719 [==============================] - 5s 483us/step - loss: 6.4719 - acc: 0.0026\n",
      "Epoch 8/1000\n",
      "9719/9719 [==============================] - 5s 481us/step - loss: 6.3320 - acc: 0.0037\n",
      "Epoch 9/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 6.2341 - acc: 0.0044\n",
      "Epoch 10/1000\n",
      "9719/9719 [==============================] - 4s 451us/step - loss: 6.1674 - acc: 0.0040\n",
      "Epoch 11/1000\n",
      "9719/9719 [==============================] - 4s 445us/step - loss: 6.1037 - acc: 0.0044\n",
      "Epoch 12/1000\n",
      "9719/9719 [==============================] - 4s 447us/step - loss: 6.0574 - acc: 0.0047\n",
      "Epoch 13/1000\n",
      "9719/9719 [==============================] - 5s 487us/step - loss: 6.0138 - acc: 0.0051\n",
      "Epoch 14/1000\n",
      "9719/9719 [==============================] - 5s 474us/step - loss: 5.9717 - acc: 0.0061\n",
      "Epoch 15/1000\n",
      "9719/9719 [==============================] - 4s 459us/step - loss: 5.9350 - acc: 0.0077\n",
      "Epoch 16/1000\n",
      "9719/9719 [==============================] - 4s 444us/step - loss: 5.8947 - acc: 0.0083\n",
      "Epoch 17/1000\n",
      "9719/9719 [==============================] - 4s 447us/step - loss: 5.8671 - acc: 0.0071\n",
      "Epoch 18/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 5.8310 - acc: 0.0090\n",
      "Epoch 19/1000\n",
      "9719/9719 [==============================] - 5s 485us/step - loss: 5.7964 - acc: 0.0121\n",
      "Epoch 20/1000\n",
      "9719/9719 [==============================] - 5s 466us/step - loss: 5.7692 - acc: 0.0106\n",
      "Epoch 21/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 5.7381 - acc: 0.0107\n",
      "Epoch 22/1000\n",
      "9719/9719 [==============================] - 4s 443us/step - loss: 5.7065 - acc: 0.0133\n",
      "Epoch 23/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 5.6749 - acc: 0.0163\n",
      "Epoch 24/1000\n",
      "9719/9719 [==============================] - 5s 475us/step - loss: 5.6471 - acc: 0.0133\n",
      "Epoch 25/1000\n",
      "9719/9719 [==============================] - 5s 487us/step - loss: 5.6165 - acc: 0.0156\n",
      "Epoch 26/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 5.5915 - acc: 0.0187\n",
      "Epoch 27/1000\n",
      "9719/9719 [==============================] - 4s 456us/step - loss: 5.5616 - acc: 0.0202\n",
      "Epoch 28/1000\n",
      "9719/9719 [==============================] - 4s 445us/step - loss: 5.5333 - acc: 0.0210\n",
      "Epoch 29/1000\n",
      "9719/9719 [==============================] - 4s 442us/step - loss: 5.5059 - acc: 0.0230\n",
      "Epoch 30/1000\n",
      "9719/9719 [==============================] - 5s 466us/step - loss: 5.4796 - acc: 0.0244\n",
      "Epoch 31/1000\n",
      "9719/9719 [==============================] - 4s 455us/step - loss: 5.4499 - acc: 0.0269\n",
      "Epoch 32/1000\n",
      "9719/9719 [==============================] - 4s 461us/step - loss: 5.4281 - acc: 0.0284\n",
      "Epoch 33/1000\n",
      "9719/9719 [==============================] - 4s 456us/step - loss: 5.3945 - acc: 0.0288\n",
      "Epoch 34/1000\n",
      "9719/9719 [==============================] - 4s 459us/step - loss: 5.3688 - acc: 0.0298\n",
      "Epoch 35/1000\n",
      "9719/9719 [==============================] - 5s 465us/step - loss: 5.3505 - acc: 0.0304\n",
      "Epoch 36/1000\n",
      "9719/9719 [==============================] - 4s 443us/step - loss: 5.3213 - acc: 0.0321\n",
      "Epoch 37/1000\n",
      "9719/9719 [==============================] - 5s 466us/step - loss: 5.2910 - acc: 0.0333\n",
      "Epoch 38/1000\n",
      "9719/9719 [==============================] - 4s 447us/step - loss: 5.2695 - acc: 0.0357\n",
      "Epoch 39/1000\n",
      "9719/9719 [==============================] - 5s 471us/step - loss: 5.2483 - acc: 0.0354\n",
      "Epoch 40/1000\n",
      "9719/9719 [==============================] - 5s 479us/step - loss: 5.2231 - acc: 0.0393\n",
      "Epoch 41/1000\n",
      "9719/9719 [==============================] - 4s 461us/step - loss: 5.2007 - acc: 0.0465\n",
      "Epoch 42/1000\n",
      "9719/9719 [==============================] - 4s 450us/step - loss: 5.1748 - acc: 0.0429\n",
      "Epoch 43/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 5.1479 - acc: 0.0466\n",
      "Epoch 44/1000\n",
      "9719/9719 [==============================] - 4s 445us/step - loss: 5.1326 - acc: 0.0466\n",
      "Epoch 45/1000\n",
      "9719/9719 [==============================] - 5s 483us/step - loss: 5.1067 - acc: 0.0476\n",
      "Epoch 46/1000\n",
      "9719/9719 [==============================] - 5s 479us/step - loss: 5.0920 - acc: 0.0503\n",
      "Epoch 47/1000\n",
      "9719/9719 [==============================] - 4s 459us/step - loss: 5.0565 - acc: 0.0518\n",
      "Epoch 48/1000\n",
      "9719/9719 [==============================] - 4s 446us/step - loss: 5.0384 - acc: 0.0515\n",
      "Epoch 49/1000\n",
      "9719/9719 [==============================] - 4s 445us/step - loss: 5.0157 - acc: 0.0566\n",
      "Epoch 50/1000\n",
      "9719/9719 [==============================] - 4s 451us/step - loss: 4.9957 - acc: 0.0555\n",
      "Epoch 51/1000\n",
      "9719/9719 [==============================] - 5s 466us/step - loss: 4.9847 - acc: 0.0574\n",
      "Epoch 52/1000\n",
      "9719/9719 [==============================] - 4s 446us/step - loss: 4.9621 - acc: 0.0599\n",
      "Epoch 53/1000\n",
      "9719/9719 [==============================] - 5s 465us/step - loss: 4.9335 - acc: 0.0625\n",
      "Epoch 54/1000\n",
      "9719/9719 [==============================] - 4s 449us/step - loss: 4.9226 - acc: 0.0638\n",
      "Epoch 55/1000\n",
      "9719/9719 [==============================] - 4s 462us/step - loss: 4.8964 - acc: 0.0673\n",
      "Epoch 56/1000\n",
      "9719/9719 [==============================] - 5s 463us/step - loss: 4.8810 - acc: 0.0648\n",
      "Epoch 57/1000\n",
      "9719/9719 [==============================] - 4s 456us/step - loss: 4.8697 - acc: 0.0684\n",
      "Epoch 58/1000\n",
      "9719/9719 [==============================] - 5s 481us/step - loss: 4.8398 - acc: 0.0710\n",
      "Epoch 59/1000\n",
      "9719/9719 [==============================] - 5s 463us/step - loss: 4.8312 - acc: 0.0685\n",
      "Epoch 60/1000\n",
      "9719/9719 [==============================] - 4s 459us/step - loss: 4.8116 - acc: 0.0727\n",
      "Epoch 61/1000\n",
      "9719/9719 [==============================] - 4s 448us/step - loss: 4.7949 - acc: 0.0750\n",
      "Epoch 62/1000\n",
      "9719/9719 [==============================] - 4s 444us/step - loss: 4.7838 - acc: 0.0751\n",
      "Epoch 63/1000\n",
      "9719/9719 [==============================] - 5s 472us/step - loss: 4.7546 - acc: 0.0793\n",
      "Epoch 64/1000\n",
      "9719/9719 [==============================] - 5s 485us/step - loss: 4.7489 - acc: 0.0803\n",
      "Epoch 65/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 4.7286 - acc: 0.0818\n",
      "Epoch 66/1000\n",
      "9719/9719 [==============================] - 4s 455us/step - loss: 4.7153 - acc: 0.0822\n",
      "Epoch 67/1000\n",
      "9719/9719 [==============================] - 4s 445us/step - loss: 4.6953 - acc: 0.0852\n",
      "Epoch 68/1000\n",
      "9719/9719 [==============================] - 4s 442us/step - loss: 4.6842 - acc: 0.0828\n",
      "Epoch 69/1000\n",
      "9719/9719 [==============================] - 5s 467us/step - loss: 4.6694 - acc: 0.0862\n",
      "Epoch 70/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 4.6561 - acc: 0.0857\n",
      "Epoch 71/1000\n",
      "9719/9719 [==============================] - 5s 471us/step - loss: 4.6378 - acc: 0.0912\n",
      "Epoch 72/1000\n",
      "9719/9719 [==============================] - 5s 482us/step - loss: 4.6216 - acc: 0.0912\n",
      "Epoch 73/1000\n",
      "9719/9719 [==============================] - 5s 464us/step - loss: 4.6109 - acc: 0.0933\n",
      "Epoch 74/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9719/9719 [==============================] - 4s 453us/step - loss: 4.6026 - acc: 0.0975\n",
      "Epoch 75/1000\n",
      "9719/9719 [==============================] - 4s 445us/step - loss: 4.5788 - acc: 0.0942\n",
      "Epoch 76/1000\n",
      "9719/9719 [==============================] - 4s 444us/step - loss: 4.5781 - acc: 0.0964\n",
      "Epoch 77/1000\n",
      "9719/9719 [==============================] - 5s 481us/step - loss: 4.5625 - acc: 0.0941\n",
      "Epoch 78/1000\n",
      "9719/9719 [==============================] - 5s 480us/step - loss: 4.5416 - acc: 0.1008\n",
      "Epoch 79/1000\n",
      "9719/9719 [==============================] - 4s 461us/step - loss: 4.5404 - acc: 0.0963\n",
      "Epoch 80/1000\n",
      "9719/9719 [==============================] - 4s 446us/step - loss: 4.5148 - acc: 0.1033\n",
      "Epoch 81/1000\n",
      "9719/9719 [==============================] - 4s 447us/step - loss: 4.5201 - acc: 0.0985\n",
      "Epoch 82/1000\n",
      "9719/9719 [==============================] - 4s 450us/step - loss: 4.4929 - acc: 0.1047\n",
      "Epoch 83/1000\n",
      "9719/9719 [==============================] - 5s 483us/step - loss: 4.4929 - acc: 0.1052\n",
      "Epoch 84/1000\n",
      "9719/9719 [==============================] - 5s 468us/step - loss: 4.4845 - acc: 0.1074\n",
      "Epoch 85/1000\n",
      "9719/9719 [==============================] - 4s 463us/step - loss: 4.4584 - acc: 0.1069\n",
      "Epoch 86/1000\n",
      "9719/9719 [==============================] - 4s 449us/step - loss: 4.4604 - acc: 0.1108\n",
      "Epoch 87/1000\n",
      "9719/9719 [==============================] - 4s 442us/step - loss: 4.4413 - acc: 0.1134\n",
      "Epoch 88/1000\n",
      "9719/9719 [==============================] - 5s 463us/step - loss: 4.4387 - acc: 0.1105\n",
      "Epoch 89/1000\n",
      "9719/9719 [==============================] - 5s 485us/step - loss: 4.4234 - acc: 0.1135\n",
      "Epoch 90/1000\n",
      "9719/9719 [==============================] - 5s 468us/step - loss: 4.4010 - acc: 0.1150\n",
      "Epoch 91/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 4.4038 - acc: 0.1115\n",
      "Epoch 92/1000\n",
      "9719/9719 [==============================] - 4s 444us/step - loss: 4.3895 - acc: 0.1177\n",
      "Epoch 93/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 4.3839 - acc: 0.1196\n",
      "Epoch 94/1000\n",
      "9719/9719 [==============================] - 5s 474us/step - loss: 4.3665 - acc: 0.1198\n",
      "Epoch 95/1000\n",
      "9719/9719 [==============================] - 5s 485us/step - loss: 4.3698 - acc: 0.1140\n",
      "Epoch 96/1000\n",
      "9719/9719 [==============================] - 4s 455us/step - loss: 4.3530 - acc: 0.1250\n",
      "Epoch 97/1000\n",
      "9719/9719 [==============================] - 4s 454us/step - loss: 4.3556 - acc: 0.1179\n",
      "Epoch 98/1000\n",
      "9719/9719 [==============================] - 4s 445us/step - loss: 4.3350 - acc: 0.1212\n",
      "Epoch 99/1000\n",
      "9719/9719 [==============================] - 4s 439us/step - loss: 4.3333 - acc: 0.1240\n",
      "Epoch 100/1000\n",
      "9719/9719 [==============================] - 5s 480us/step - loss: 4.3093 - acc: 0.1283\n",
      "Epoch 101/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 4.3131 - acc: 0.1272\n",
      "Epoch 102/1000\n",
      "9719/9719 [==============================] - 4s 462us/step - loss: 4.2946 - acc: 0.1287\n",
      "Epoch 103/1000\n",
      "9719/9719 [==============================] - 4s 446us/step - loss: 4.2957 - acc: 0.1227\n",
      "Epoch 104/1000\n",
      "9719/9719 [==============================] - 4s 443us/step - loss: 4.2845 - acc: 0.1272\n",
      "Epoch 105/1000\n",
      "9719/9719 [==============================] - 4s 452us/step - loss: 4.2769 - acc: 0.1328\n",
      "Epoch 106/1000\n",
      "9719/9719 [==============================] - 5s 482us/step - loss: 4.2610 - acc: 0.1317\n",
      "Epoch 107/1000\n",
      "9719/9719 [==============================] - 5s 472us/step - loss: 4.2562 - acc: 0.1310\n",
      "Epoch 108/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 4.2546 - acc: 0.1302\n",
      "Epoch 109/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 4.2481 - acc: 0.1322\n",
      "Epoch 110/1000\n",
      "9719/9719 [==============================] - 4s 443us/step - loss: 4.2365 - acc: 0.1322\n",
      "Epoch 111/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 4.2323 - acc: 0.1380\n",
      "Epoch 112/1000\n",
      "9719/9719 [==============================] - 5s 482us/step - loss: 4.2198 - acc: 0.1337\n",
      "Epoch 113/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 4.2224 - acc: 0.1312\n",
      "Epoch 114/1000\n",
      "9719/9719 [==============================] - 4s 462us/step - loss: 4.2007 - acc: 0.1366\n",
      "Epoch 115/1000\n",
      "9719/9719 [==============================] - 4s 448us/step - loss: 4.2071 - acc: 0.1364\n",
      "Epoch 116/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 4.1921 - acc: 0.1387\n",
      "Epoch 117/1000\n",
      "9719/9719 [==============================] - 5s 471us/step - loss: 4.1785 - acc: 0.1425\n",
      "Epoch 118/1000\n",
      "9719/9719 [==============================] - 5s 484us/step - loss: 4.1757 - acc: 0.1373\n",
      "Epoch 119/1000\n",
      "9719/9719 [==============================] - 4s 462us/step - loss: 4.1732 - acc: 0.1425\n",
      "Epoch 120/1000\n",
      "9719/9719 [==============================] - 4s 456us/step - loss: 4.1672 - acc: 0.1410\n",
      "Epoch 121/1000\n",
      "9719/9719 [==============================] - 4s 445us/step - loss: 4.1555 - acc: 0.1442\n",
      "Epoch 122/1000\n",
      "9719/9719 [==============================] - 4s 439us/step - loss: 4.1399 - acc: 0.1453\n",
      "Epoch 123/1000\n",
      "9719/9719 [==============================] - 5s 466us/step - loss: 4.1484 - acc: 0.1453\n",
      "Epoch 124/1000\n",
      "9719/9719 [==============================] - 4s 457us/step - loss: 4.1417 - acc: 0.1451\n",
      "Epoch 125/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 4.1277 - acc: 0.1461\n",
      "Epoch 126/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 4.1324 - acc: 0.1446\n",
      "Epoch 127/1000\n",
      "9719/9719 [==============================] - 4s 452us/step - loss: 4.1146 - acc: 0.1499\n",
      "Epoch 128/1000\n",
      "9719/9719 [==============================] - 5s 466us/step - loss: 4.0997 - acc: 0.1532\n",
      "Epoch 129/1000\n",
      "9719/9719 [==============================] - 4s 446us/step - loss: 4.1172 - acc: 0.1515\n",
      "Epoch 130/1000\n",
      "9719/9719 [==============================] - 5s 465us/step - loss: 4.0913 - acc: 0.1509\n",
      "Epoch 131/1000\n",
      "9719/9719 [==============================] - 4s 449us/step - loss: 4.0903 - acc: 0.1527\n",
      "Epoch 132/1000\n",
      "9719/9719 [==============================] - 5s 474us/step - loss: 4.0876 - acc: 0.1471\n",
      "Epoch 133/1000\n",
      "9719/9719 [==============================] - 5s 479us/step - loss: 4.0770 - acc: 0.1551\n",
      "Epoch 134/1000\n",
      "9719/9719 [==============================] - 4s 461us/step - loss: 4.0877 - acc: 0.1507\n",
      "Epoch 135/1000\n",
      "9719/9719 [==============================] - 4s 451us/step - loss: 4.0699 - acc: 0.1551\n",
      "Epoch 136/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 4.0758 - acc: 0.1533\n",
      "Epoch 137/1000\n",
      "9719/9719 [==============================] - 4s 442us/step - loss: 4.0614 - acc: 0.1527\n",
      "Epoch 138/1000\n",
      "9719/9719 [==============================] - 5s 486us/step - loss: 4.0488 - acc: 0.1599\n",
      "Epoch 139/1000\n",
      "9719/9719 [==============================] - 5s 482us/step - loss: 4.0397 - acc: 0.1573\n",
      "Epoch 140/1000\n",
      "9719/9719 [==============================] - 4s 462us/step - loss: 4.0641 - acc: 0.1583\n",
      "Epoch 141/1000\n",
      "9719/9719 [==============================] - 4s 448us/step - loss: 4.0322 - acc: 0.1604\n",
      "Epoch 142/1000\n",
      "9719/9719 [==============================] - 4s 449us/step - loss: 4.0562 - acc: 0.1544\n",
      "Epoch 143/1000\n",
      "9719/9719 [==============================] - 4s 456us/step - loss: 4.0110 - acc: 0.1649\n",
      "Epoch 144/1000\n",
      "9719/9719 [==============================] - 5s 483us/step - loss: 4.0325 - acc: 0.1601\n",
      "Epoch 145/1000\n",
      "9719/9719 [==============================] - 5s 469us/step - loss: 4.0091 - acc: 0.1593\n",
      "Epoch 146/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 4.0240 - acc: 0.1625\n",
      "Epoch 147/1000\n",
      "9719/9719 [==============================] - 4s 443us/step - loss: 4.0053 - acc: 0.1645\n",
      "Epoch 148/1000\n",
      "9719/9719 [==============================] - 4s 443us/step - loss: 4.0148 - acc: 0.1613\n",
      "Epoch 149/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 4.0005 - acc: 0.1646\n",
      "Epoch 150/1000\n",
      "9719/9719 [==============================] - 5s 465us/step - loss: 3.9949 - acc: 0.1627\n",
      "Epoch 151/1000\n",
      "9719/9719 [==============================] - 4s 457us/step - loss: 3.9893 - acc: 0.1657\n",
      "Epoch 152/1000\n",
      "9719/9719 [==============================] - 5s 483us/step - loss: 3.9793 - acc: 0.1662\n",
      "Epoch 153/1000\n",
      "9719/9719 [==============================] - 5s 467us/step - loss: 3.9945 - acc: 0.1641\n",
      "Epoch 154/1000\n",
      "9719/9719 [==============================] - 4s 461us/step - loss: 3.9750 - acc: 0.1664\n",
      "Epoch 155/1000\n",
      "9719/9719 [==============================] - 4s 449us/step - loss: 3.9844 - acc: 0.1611\n",
      "Epoch 156/1000\n",
      "9719/9719 [==============================] - 4s 443us/step - loss: 3.9664 - acc: 0.1682\n",
      "Epoch 157/1000\n",
      "9719/9719 [==============================] - 5s 467us/step - loss: 3.9771 - acc: 0.1654\n",
      "Epoch 158/1000\n",
      "9719/9719 [==============================] - 5s 486us/step - loss: 3.9621 - acc: 0.1649\n",
      "Epoch 159/1000\n",
      "9719/9719 [==============================] - 4s 462us/step - loss: 3.9430 - acc: 0.1684\n",
      "Epoch 160/1000\n",
      "9719/9719 [==============================] - 4s 459us/step - loss: 3.9576 - acc: 0.1688\n",
      "Epoch 161/1000\n",
      "9719/9719 [==============================] - 4s 447us/step - loss: 3.9527 - acc: 0.1686\n",
      "Epoch 162/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.9260 - acc: 0.1707\n",
      "Epoch 163/1000\n",
      "9719/9719 [==============================] - 5s 483us/step - loss: 3.9290 - acc: 0.1785\n",
      "Epoch 164/1000\n",
      "9719/9719 [==============================] - 5s 483us/step - loss: 3.9433 - acc: 0.1723\n",
      "Epoch 165/1000\n",
      "9719/9719 [==============================] - 4s 457us/step - loss: 3.9269 - acc: 0.1748\n",
      "Epoch 166/1000\n",
      "9719/9719 [==============================] - 4s 452us/step - loss: 3.9211 - acc: 0.1775\n",
      "Epoch 167/1000\n",
      "9719/9719 [==============================] - 4s 446us/step - loss: 3.9145 - acc: 0.1765\n",
      "Epoch 168/1000\n",
      "9719/9719 [==============================] - 4s 453us/step - loss: 3.9348 - acc: 0.1737\n",
      "Epoch 169/1000\n",
      "9719/9719 [==============================] - 5s 465us/step - loss: 3.9019 - acc: 0.1775\n",
      "Epoch 170/1000\n",
      "9719/9719 [==============================] - 4s 455us/step - loss: 3.9176 - acc: 0.1763\n",
      "Epoch 171/1000\n",
      "9719/9719 [==============================] - 5s 465us/step - loss: 3.9164 - acc: 0.1774\n",
      "Epoch 172/1000\n",
      "9719/9719 [==============================] - 4s 456us/step - loss: 3.8862 - acc: 0.1800\n",
      "Epoch 173/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 3.9093 - acc: 0.1769\n",
      "Epoch 174/1000\n",
      "9719/9719 [==============================] - 5s 469us/step - loss: 3.8817 - acc: 0.1758\n",
      "Epoch 175/1000\n",
      "9719/9719 [==============================] - 4s 452us/step - loss: 3.8916 - acc: 0.1803\n",
      "Epoch 176/1000\n",
      "9719/9719 [==============================] - 5s 465us/step - loss: 3.8709 - acc: 0.1857\n",
      "Epoch 177/1000\n",
      "9719/9719 [==============================] - 4s 448us/step - loss: 3.8863 - acc: 0.1791\n",
      "Epoch 178/1000\n",
      "9719/9719 [==============================] - 5s 479us/step - loss: 3.8968 - acc: 0.1744\n",
      "Epoch 179/1000\n",
      "9719/9719 [==============================] - 5s 475us/step - loss: 3.8564 - acc: 0.1821\n",
      "Epoch 180/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 3.8676 - acc: 0.1815\n",
      "Epoch 181/1000\n",
      "9719/9719 [==============================] - 4s 450us/step - loss: 3.8557 - acc: 0.1836\n",
      "Epoch 182/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.8568 - acc: 0.1803\n",
      "Epoch 183/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 3.8843 - acc: 0.1778\n",
      "Epoch 184/1000\n",
      "9719/9719 [==============================] - 5s 483us/step - loss: 3.8489 - acc: 0.1837\n",
      "Epoch 185/1000\n",
      "9719/9719 [==============================] - 5s 472us/step - loss: 3.8524 - acc: 0.1847\n",
      "Epoch 186/1000\n",
      "9719/9719 [==============================] - 4s 461us/step - loss: 3.8642 - acc: 0.1831\n",
      "Epoch 187/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.8484 - acc: 0.1907\n",
      "Epoch 188/1000\n",
      "9719/9719 [==============================] - 4s 442us/step - loss: 3.8515 - acc: 0.1836\n",
      "Epoch 189/1000\n",
      "9719/9719 [==============================] - 5s 467us/step - loss: 3.8458 - acc: 0.1893\n",
      "Epoch 190/1000\n",
      "9719/9719 [==============================] - 5s 485us/step - loss: 3.8168 - acc: 0.1890\n",
      "Epoch 191/1000\n",
      "9719/9719 [==============================] - 4s 461us/step - loss: 3.8410 - acc: 0.1896\n",
      "Epoch 192/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 3.8262 - acc: 0.1907\n",
      "Epoch 193/1000\n",
      "9719/9719 [==============================] - 4s 442us/step - loss: 3.8223 - acc: 0.1880\n",
      "Epoch 194/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 3.8289 - acc: 0.1912\n",
      "Epoch 195/1000\n",
      "9719/9719 [==============================] - 5s 483us/step - loss: 3.8253 - acc: 0.1915\n",
      "Epoch 196/1000\n",
      "9719/9719 [==============================] - 5s 482us/step - loss: 3.8048 - acc: 0.1907\n",
      "Epoch 197/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 3.8149 - acc: 0.1942\n",
      "Epoch 198/1000\n",
      "9719/9719 [==============================] - 4s 454us/step - loss: 3.8064 - acc: 0.1915\n",
      "Epoch 199/1000\n",
      "9719/9719 [==============================] - 4s 443us/step - loss: 3.8208 - acc: 0.1916\n",
      "Epoch 200/1000\n",
      "9719/9719 [==============================] - 4s 444us/step - loss: 3.8057 - acc: 0.1965\n",
      "Epoch 201/1000\n",
      "9719/9719 [==============================] - 5s 480us/step - loss: 3.8121 - acc: 0.1942\n",
      "Epoch 202/1000\n",
      "9719/9719 [==============================] - 5s 477us/step - loss: 3.7925 - acc: 0.1885\n",
      "Epoch 203/1000\n",
      "9719/9719 [==============================] - 4s 459us/step - loss: 3.8127 - acc: 0.1929\n",
      "Epoch 204/1000\n",
      "9719/9719 [==============================] - 4s 442us/step - loss: 3.7855 - acc: 0.1995\n",
      "Epoch 205/1000\n",
      "9719/9719 [==============================] - 4s 445us/step - loss: 3.7934 - acc: 0.1912\n",
      "Epoch 206/1000\n",
      "9719/9719 [==============================] - 4s 455us/step - loss: 3.7814 - acc: 0.1984\n",
      "Epoch 207/1000\n",
      "9719/9719 [==============================] - 5s 481us/step - loss: 3.7781 - acc: 0.2017\n",
      "Epoch 208/1000\n",
      "9719/9719 [==============================] - 5s 470us/step - loss: 3.7778 - acc: 0.2007\n",
      "Epoch 209/1000\n",
      "9719/9719 [==============================] - 4s 461us/step - loss: 3.7822 - acc: 0.1942\n",
      "Epoch 210/1000\n",
      "9719/9719 [==============================] - 4s 443us/step - loss: 3.7808 - acc: 0.1972\n",
      "Epoch 211/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.7741 - acc: 0.1990\n",
      "Epoch 212/1000\n",
      "9719/9719 [==============================] - 5s 467us/step - loss: 3.7692 - acc: 0.1989\n",
      "Epoch 213/1000\n",
      "9719/9719 [==============================] - 5s 482us/step - loss: 3.7607 - acc: 0.1981\n",
      "Epoch 214/1000\n",
      "9719/9719 [==============================] - 4s 459us/step - loss: 3.7470 - acc: 0.1981\n",
      "Epoch 215/1000\n",
      "9719/9719 [==============================] - 4s 457us/step - loss: 3.7476 - acc: 0.2000\n",
      "Epoch 216/1000\n",
      "9719/9719 [==============================] - 4s 445us/step - loss: 3.7693 - acc: 0.1945\n",
      "Epoch 217/1000\n",
      "9719/9719 [==============================] - 4s 436us/step - loss: 3.7765 - acc: 0.1993\n",
      "Epoch 218/1000\n",
      "9719/9719 [==============================] - 5s 480us/step - loss: 3.7517 - acc: 0.2045\n",
      "Epoch 219/1000\n",
      "9719/9719 [==============================] - 5s 483us/step - loss: 3.7299 - acc: 0.2085\n",
      "Epoch 220/1000\n",
      "9719/9719 [==============================] - 4s 456us/step - loss: 3.7472 - acc: 0.2013\n",
      "Epoch 221/1000\n",
      "9719/9719 [==============================] - 4s 452us/step - loss: 3.7516 - acc: 0.2018\n",
      "Epoch 222/1000\n",
      "9719/9719 [==============================] - 4s 452us/step - loss: 3.7535 - acc: 0.1970\n",
      "Epoch 223/1000\n",
      "9719/9719 [==============================] - 4s 445us/step - loss: 3.7263 - acc: 0.2076\n",
      "Epoch 224/1000\n",
      "9719/9719 [==============================] - 5s 483us/step - loss: 3.7330 - acc: 0.2042\n",
      "Epoch 225/1000\n",
      "9719/9719 [==============================] - 5s 473us/step - loss: 3.7355 - acc: 0.2021\n",
      "Epoch 226/1000\n",
      "9719/9719 [==============================] - 4s 462us/step - loss: 3.7346 - acc: 0.2037\n",
      "Epoch 227/1000\n",
      "9719/9719 [==============================] - 4s 447us/step - loss: 3.7264 - acc: 0.2073\n",
      "Epoch 228/1000\n",
      "9719/9719 [==============================] - 4s 444us/step - loss: 3.7339 - acc: 0.2042\n",
      "Epoch 229/1000\n",
      "9719/9719 [==============================] - 4s 461us/step - loss: 3.7214 - acc: 0.2028\n",
      "Epoch 230/1000\n",
      "9719/9719 [==============================] - 5s 484us/step - loss: 3.7438 - acc: 0.2017\n",
      "Epoch 231/1000\n",
      "9719/9719 [==============================] - 5s 476us/step - loss: 3.7155 - acc: 0.2027\n",
      "Epoch 232/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9719/9719 [==============================] - 4s 463us/step - loss: 3.7237 - acc: 0.2078\n",
      "Epoch 233/1000\n",
      "9719/9719 [==============================] - 4s 444us/step - loss: 3.7143 - acc: 0.2038\n",
      "Epoch 234/1000\n",
      "9719/9719 [==============================] - 4s 442us/step - loss: 3.7112 - acc: 0.2095\n",
      "Epoch 235/1000\n",
      "9719/9719 [==============================] - 5s 469us/step - loss: 3.7009 - acc: 0.2110\n",
      "Epoch 236/1000\n",
      "9719/9719 [==============================] - 5s 487us/step - loss: 3.7220 - acc: 0.2048\n",
      "Epoch 237/1000\n",
      "9719/9719 [==============================] - 4s 462us/step - loss: 3.7061 - acc: 0.2103\n",
      "Epoch 238/1000\n",
      "9719/9719 [==============================] - 4s 457us/step - loss: 3.6920 - acc: 0.2102\n",
      "Epoch 239/1000\n",
      "9719/9719 [==============================] - 4s 446us/step - loss: 3.7036 - acc: 0.2085\n",
      "Epoch 240/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.6978 - acc: 0.2143\n",
      "Epoch 241/1000\n",
      "9719/9719 [==============================] - 5s 480us/step - loss: 3.6930 - acc: 0.2097\n",
      "Epoch 242/1000\n",
      "9719/9719 [==============================] - 5s 481us/step - loss: 3.6856 - acc: 0.2128\n",
      "Epoch 243/1000\n",
      "9719/9719 [==============================] - 4s 456us/step - loss: 3.6895 - acc: 0.2099\n",
      "Epoch 244/1000\n",
      "9719/9719 [==============================] - 4s 451us/step - loss: 3.6968 - acc: 0.2122\n",
      "Epoch 245/1000\n",
      "9719/9719 [==============================] - 4s 446us/step - loss: 3.6805 - acc: 0.2122\n",
      "Epoch 246/1000\n",
      "9719/9719 [==============================] - 4s 449us/step - loss: 3.6894 - acc: 0.2139\n",
      "Epoch 247/1000\n",
      "9719/9719 [==============================] - 5s 486us/step - loss: 3.6740 - acc: 0.2142\n",
      "Epoch 248/1000\n",
      "9719/9719 [==============================] - 5s 477us/step - loss: 3.6763 - acc: 0.2164\n",
      "Epoch 249/1000\n",
      "9719/9719 [==============================] - 4s 463us/step - loss: 3.6770 - acc: 0.2221\n",
      "Epoch 250/1000\n",
      "9719/9719 [==============================] - 4s 442us/step - loss: 3.6610 - acc: 0.2133\n",
      "Epoch 251/1000\n",
      "9719/9719 [==============================] - 4s 444us/step - loss: 3.6904 - acc: 0.2162\n",
      "Epoch 252/1000\n",
      "9719/9719 [==============================] - 4s 454us/step - loss: 3.6573 - acc: 0.2147\n",
      "Epoch 253/1000\n",
      "9719/9719 [==============================] - 5s 467us/step - loss: 3.6657 - acc: 0.2170\n",
      "Epoch 254/1000\n",
      "9719/9719 [==============================] - 4s 461us/step - loss: 3.6678 - acc: 0.2137\n",
      "Epoch 255/1000\n",
      "9719/9719 [==============================] - 5s 483us/step - loss: 3.6665 - acc: 0.2180\n",
      "Epoch 256/1000\n",
      "9719/9719 [==============================] - 5s 470us/step - loss: 3.6614 - acc: 0.2167\n",
      "Epoch 257/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 3.6557 - acc: 0.2193\n",
      "Epoch 258/1000\n",
      "9719/9719 [==============================] - 4s 447us/step - loss: 3.6574 - acc: 0.2179\n",
      "Epoch 259/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.6588 - acc: 0.2178\n",
      "Epoch 260/1000\n",
      "9719/9719 [==============================] - 5s 466us/step - loss: 3.6592 - acc: 0.2177\n",
      "Epoch 261/1000\n",
      "9719/9719 [==============================] - 5s 484us/step - loss: 3.6395 - acc: 0.2201\n",
      "Epoch 262/1000\n",
      "9719/9719 [==============================] - 5s 470us/step - loss: 3.6587 - acc: 0.2172\n",
      "Epoch 263/1000\n",
      "9719/9719 [==============================] - 4s 459us/step - loss: 3.6497 - acc: 0.2166\n",
      "Epoch 264/1000\n",
      "9719/9719 [==============================] - 4s 443us/step - loss: 3.6378 - acc: 0.2181\n",
      "Epoch 265/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 3.6412 - acc: 0.2221\n",
      "Epoch 266/1000\n",
      "9719/9719 [==============================] - 5s 474us/step - loss: 3.6409 - acc: 0.2244\n",
      "Epoch 267/1000\n",
      "9719/9719 [==============================] - 5s 484us/step - loss: 3.6418 - acc: 0.2176\n",
      "Epoch 268/1000\n",
      "9719/9719 [==============================] - 4s 456us/step - loss: 3.6377 - acc: 0.2207\n",
      "Epoch 269/1000\n",
      "9719/9719 [==============================] - 4s 454us/step - loss: 3.6464 - acc: 0.2184\n",
      "Epoch 270/1000\n",
      "9719/9719 [==============================] - 4s 443us/step - loss: 3.6372 - acc: 0.2211\n",
      "Epoch 271/1000\n",
      "9719/9719 [==============================] - 4s 439us/step - loss: 3.6343 - acc: 0.2272\n",
      "Epoch 272/1000\n",
      "9719/9719 [==============================] - 5s 464us/step - loss: 3.6357 - acc: 0.2233\n",
      "Epoch 273/1000\n",
      "9719/9719 [==============================] - 4s 459us/step - loss: 3.6316 - acc: 0.2273\n",
      "Epoch 274/1000\n",
      "9719/9719 [==============================] - 5s 472us/step - loss: 3.6141 - acc: 0.2279\n",
      "Epoch 275/1000\n",
      "9719/9719 [==============================] - 5s 484us/step - loss: 3.6321 - acc: 0.2202\n",
      "Epoch 276/1000\n",
      "9719/9719 [==============================] - 5s 464us/step - loss: 3.6150 - acc: 0.2210\n",
      "Epoch 277/1000\n",
      "9719/9719 [==============================] - 4s 449us/step - loss: 3.6343 - acc: 0.2197\n",
      "Epoch 278/1000\n",
      "9719/9719 [==============================] - 4s 442us/step - loss: 3.6342 - acc: 0.2201\n",
      "Epoch 279/1000\n",
      "9719/9719 [==============================] - 4s 443us/step - loss: 3.6087 - acc: 0.2246\n",
      "Epoch 280/1000\n",
      "9719/9719 [==============================] - 5s 483us/step - loss: 3.6379 - acc: 0.2183\n",
      "Epoch 281/1000\n",
      "9719/9719 [==============================] - 5s 482us/step - loss: 3.6213 - acc: 0.2228\n",
      "Epoch 282/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 3.6063 - acc: 0.2297\n",
      "Epoch 283/1000\n",
      "9719/9719 [==============================] - 4s 447us/step - loss: 3.6161 - acc: 0.2235\n",
      "Epoch 284/1000\n",
      "9719/9719 [==============================] - 4s 443us/step - loss: 3.5962 - acc: 0.2321\n",
      "Epoch 285/1000\n",
      "9719/9719 [==============================] - 4s 452us/step - loss: 3.6230 - acc: 0.2220\n",
      "Epoch 286/1000\n",
      "9719/9719 [==============================] - 5s 484us/step - loss: 3.5984 - acc: 0.2243\n",
      "Epoch 287/1000\n",
      "9719/9719 [==============================] - 5s 473us/step - loss: 3.6112 - acc: 0.2289\n",
      "Epoch 288/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 3.6034 - acc: 0.2290\n",
      "Epoch 289/1000\n",
      "9719/9719 [==============================] - 4s 442us/step - loss: 3.5964 - acc: 0.2309\n",
      "Epoch 290/1000\n",
      "9719/9719 [==============================] - 4s 443us/step - loss: 3.5995 - acc: 0.2271\n",
      "Epoch 291/1000\n",
      "9719/9719 [==============================] - 4s 463us/step - loss: 3.6062 - acc: 0.2285\n",
      "Epoch 292/1000\n",
      "9719/9719 [==============================] - 5s 481us/step - loss: 3.5921 - acc: 0.2292\n",
      "Epoch 293/1000\n",
      "9719/9719 [==============================] - 5s 466us/step - loss: 3.5885 - acc: 0.2285\n",
      "Epoch 294/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 3.5770 - acc: 0.2319\n",
      "Epoch 295/1000\n",
      "9719/9719 [==============================] - 4s 443us/step - loss: 3.5735 - acc: 0.2327\n",
      "Epoch 296/1000\n",
      "9719/9719 [==============================] - 4s 439us/step - loss: 3.5901 - acc: 0.2327\n",
      "Epoch 297/1000\n",
      "9719/9719 [==============================] - 5s 476us/step - loss: 3.5944 - acc: 0.2279\n",
      "Epoch 298/1000\n",
      "9719/9719 [==============================] - 5s 486us/step - loss: 3.5814 - acc: 0.2321\n",
      "Epoch 299/1000\n",
      "9719/9719 [==============================] - 4s 455us/step - loss: 3.5794 - acc: 0.2330\n",
      "Epoch 300/1000\n",
      "9719/9719 [==============================] - 4s 454us/step - loss: 3.5804 - acc: 0.2319\n",
      "Epoch 301/1000\n",
      "9719/9719 [==============================] - 4s 445us/step - loss: 3.5747 - acc: 0.2311\n",
      "Epoch 302/1000\n",
      "9719/9719 [==============================] - 4s 445us/step - loss: 3.5897 - acc: 0.2293\n",
      "Epoch 303/1000\n",
      "9719/9719 [==============================] - 5s 484us/step - loss: 3.5753 - acc: 0.2374\n",
      "Epoch 304/1000\n",
      "9719/9719 [==============================] - 5s 480us/step - loss: 3.5669 - acc: 0.2290\n",
      "Epoch 305/1000\n",
      "9719/9719 [==============================] - 4s 462us/step - loss: 3.5739 - acc: 0.2330\n",
      "Epoch 306/1000\n",
      "9719/9719 [==============================] - 4s 448us/step - loss: 3.5675 - acc: 0.2345\n",
      "Epoch 307/1000\n",
      "9719/9719 [==============================] - 4s 448us/step - loss: 3.5462 - acc: 0.2346\n",
      "Epoch 308/1000\n",
      "9719/9719 [==============================] - 4s 452us/step - loss: 3.5613 - acc: 0.2326\n",
      "Epoch 309/1000\n",
      "9719/9719 [==============================] - 5s 483us/step - loss: 3.5768 - acc: 0.2354\n",
      "Epoch 310/1000\n",
      "9719/9719 [==============================] - 5s 471us/step - loss: 3.5686 - acc: 0.2319\n",
      "Epoch 311/1000\n",
      "9719/9719 [==============================] - 4s 462us/step - loss: 3.5466 - acc: 0.2347\n",
      "Epoch 312/1000\n",
      "9719/9719 [==============================] - 4s 443us/step - loss: 3.5755 - acc: 0.2377\n",
      "Epoch 313/1000\n",
      "9719/9719 [==============================] - 4s 444us/step - loss: 3.5298 - acc: 0.2415\n",
      "Epoch 314/1000\n",
      "9719/9719 [==============================] - 5s 466us/step - loss: 3.5675 - acc: 0.2326\n",
      "Epoch 315/1000\n",
      "9719/9719 [==============================] - 5s 484us/step - loss: 3.5468 - acc: 0.2369\n",
      "Epoch 316/1000\n",
      "9719/9719 [==============================] - 5s 469us/step - loss: 3.5548 - acc: 0.2366\n",
      "Epoch 317/1000\n",
      "9719/9719 [==============================] - 4s 459us/step - loss: 3.5347 - acc: 0.2421\n",
      "Epoch 318/1000\n",
      "9719/9719 [==============================] - 4s 445us/step - loss: 3.5808 - acc: 0.2281\n",
      "Epoch 319/1000\n",
      "9719/9719 [==============================] - 4s 439us/step - loss: 3.5402 - acc: 0.2407\n",
      "Epoch 320/1000\n",
      "9719/9719 [==============================] - 5s 479us/step - loss: 3.5542 - acc: 0.2336\n",
      "Epoch 321/1000\n",
      "9719/9719 [==============================] - 5s 484us/step - loss: 3.5414 - acc: 0.2360\n",
      "Epoch 322/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 3.5654 - acc: 0.2314\n",
      "Epoch 323/1000\n",
      "9719/9719 [==============================] - 4s 450us/step - loss: 3.5479 - acc: 0.2387\n",
      "Epoch 324/1000\n",
      "9719/9719 [==============================] - 4s 446us/step - loss: 3.5369 - acc: 0.2372\n",
      "Epoch 325/1000\n",
      "9719/9719 [==============================] - 4s 445us/step - loss: 3.5401 - acc: 0.2379\n",
      "Epoch 326/1000\n",
      "9719/9719 [==============================] - 5s 466us/step - loss: 3.5292 - acc: 0.2407\n",
      "Epoch 327/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 3.5361 - acc: 0.2425\n",
      "Epoch 328/1000\n",
      "9719/9719 [==============================] - 5s 466us/step - loss: 3.5461 - acc: 0.2397\n",
      "Epoch 329/1000\n",
      "9719/9719 [==============================] - 5s 463us/step - loss: 3.5215 - acc: 0.2414\n",
      "Epoch 330/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 3.5257 - acc: 0.2474\n",
      "Epoch 331/1000\n",
      "9719/9719 [==============================] - 5s 466us/step - loss: 3.5345 - acc: 0.2353\n",
      "Epoch 332/1000\n",
      "9719/9719 [==============================] - 4s 451us/step - loss: 3.5279 - acc: 0.2387\n",
      "Epoch 333/1000\n",
      "9719/9719 [==============================] - 5s 482us/step - loss: 3.5423 - acc: 0.2390\n",
      "Epoch 334/1000\n",
      "9719/9719 [==============================] - 5s 468us/step - loss: 3.5430 - acc: 0.2360\n",
      "Epoch 335/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 3.5104 - acc: 0.2507\n",
      "Epoch 336/1000\n",
      "9719/9719 [==============================] - 4s 445us/step - loss: 3.5127 - acc: 0.2447\n",
      "Epoch 337/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.5349 - acc: 0.2390\n",
      "Epoch 338/1000\n",
      "9719/9719 [==============================] - 5s 466us/step - loss: 3.5299 - acc: 0.2421\n",
      "Epoch 339/1000\n",
      "9719/9719 [==============================] - 5s 484us/step - loss: 3.5292 - acc: 0.2439\n",
      "Epoch 340/1000\n",
      "9719/9719 [==============================] - 5s 467us/step - loss: 3.5379 - acc: 0.2371\n",
      "Epoch 341/1000\n",
      "9719/9719 [==============================] - 4s 455us/step - loss: 3.4972 - acc: 0.2450\n",
      "Epoch 342/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.5274 - acc: 0.2398\n",
      "Epoch 343/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 3.5113 - acc: 0.2409\n",
      "Epoch 344/1000\n",
      "9719/9719 [==============================] - 5s 476us/step - loss: 3.5065 - acc: 0.2450\n",
      "Epoch 345/1000\n",
      "9719/9719 [==============================] - 5s 485us/step - loss: 3.5160 - acc: 0.2423\n",
      "Epoch 346/1000\n",
      "9719/9719 [==============================] - 4s 456us/step - loss: 3.5195 - acc: 0.2418\n",
      "Epoch 347/1000\n",
      "9719/9719 [==============================] - 4s 451us/step - loss: 3.5277 - acc: 0.2404\n",
      "Epoch 348/1000\n",
      "9719/9719 [==============================] - 4s 442us/step - loss: 3.4966 - acc: 0.2462\n",
      "Epoch 349/1000\n",
      "9719/9719 [==============================] - 4s 435us/step - loss: 3.5030 - acc: 0.2460\n",
      "Epoch 350/1000\n",
      "9719/9719 [==============================] - 5s 481us/step - loss: 3.4946 - acc: 0.2486\n",
      "Epoch 351/1000\n",
      "9719/9719 [==============================] - 5s 481us/step - loss: 3.5313 - acc: 0.2383\n",
      "Epoch 352/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 3.5261 - acc: 0.2450\n",
      "Epoch 353/1000\n",
      "9719/9719 [==============================] - 4s 449us/step - loss: 3.4789 - acc: 0.2514\n",
      "Epoch 354/1000\n",
      "9719/9719 [==============================] - 4s 444us/step - loss: 3.5025 - acc: 0.2432\n",
      "Epoch 355/1000\n",
      "9719/9719 [==============================] - 4s 447us/step - loss: 3.5031 - acc: 0.2435\n",
      "Epoch 356/1000\n",
      "9719/9719 [==============================] - 5s 486us/step - loss: 3.5166 - acc: 0.2392\n",
      "Epoch 357/1000\n",
      "9719/9719 [==============================] - 5s 474us/step - loss: 3.4907 - acc: 0.2459\n",
      "Epoch 358/1000\n",
      "9719/9719 [==============================] - 4s 457us/step - loss: 3.4909 - acc: 0.2484\n",
      "Epoch 359/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.4838 - acc: 0.2444\n",
      "Epoch 360/1000\n",
      "9719/9719 [==============================] - 4s 445us/step - loss: 3.5136 - acc: 0.2499\n",
      "Epoch 361/1000\n",
      "9719/9719 [==============================] - 4s 461us/step - loss: 3.4886 - acc: 0.2497\n",
      "Epoch 362/1000\n",
      "9719/9719 [==============================] - 5s 482us/step - loss: 3.4945 - acc: 0.2460\n",
      "Epoch 363/1000\n",
      "9719/9719 [==============================] - 5s 465us/step - loss: 3.5166 - acc: 0.2429\n",
      "Epoch 364/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 3.4631 - acc: 0.2536\n",
      "Epoch 365/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.4932 - acc: 0.2445\n",
      "Epoch 366/1000\n",
      "9719/9719 [==============================] - 4s 437us/step - loss: 3.5054 - acc: 0.2441\n",
      "Epoch 367/1000\n",
      "9719/9719 [==============================] - 5s 470us/step - loss: 3.4559 - acc: 0.2554\n",
      "Epoch 368/1000\n",
      "9719/9719 [==============================] - 5s 482us/step - loss: 3.4838 - acc: 0.2456\n",
      "Epoch 369/1000\n",
      "9719/9719 [==============================] - 4s 461us/step - loss: 3.4934 - acc: 0.2510\n",
      "Epoch 370/1000\n",
      "9719/9719 [==============================] - 4s 452us/step - loss: 3.4738 - acc: 0.2501\n",
      "Epoch 371/1000\n",
      "9719/9719 [==============================] - 4s 443us/step - loss: 3.4871 - acc: 0.2445\n",
      "Epoch 372/1000\n",
      "9719/9719 [==============================] - 4s 436us/step - loss: 3.4944 - acc: 0.2481\n",
      "Epoch 373/1000\n",
      "9719/9719 [==============================] - 5s 480us/step - loss: 3.4761 - acc: 0.2507\n",
      "Epoch 374/1000\n",
      "9719/9719 [==============================] - 5s 481us/step - loss: 3.4750 - acc: 0.2471\n",
      "Epoch 375/1000\n",
      "9719/9719 [==============================] - 4s 455us/step - loss: 3.4868 - acc: 0.2498\n",
      "Epoch 376/1000\n",
      "9719/9719 [==============================] - 4s 449us/step - loss: 3.4608 - acc: 0.2523\n",
      "Epoch 377/1000\n",
      "9719/9719 [==============================] - 4s 444us/step - loss: 3.4635 - acc: 0.2521\n",
      "Epoch 378/1000\n",
      "9719/9719 [==============================] - 4s 444us/step - loss: 3.4810 - acc: 0.2488\n",
      "Epoch 379/1000\n",
      "9719/9719 [==============================] - 4s 463us/step - loss: 3.4669 - acc: 0.2474\n",
      "Epoch 380/1000\n",
      "9719/9719 [==============================] - 4s 454us/step - loss: 3.4503 - acc: 0.2554\n",
      "Epoch 381/1000\n",
      "9719/9719 [==============================] - 5s 476us/step - loss: 3.4476 - acc: 0.2565\n",
      "Epoch 382/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.4847 - acc: 0.2500\n",
      "Epoch 383/1000\n",
      "9719/9719 [==============================] - 5s 469us/step - loss: 3.4614 - acc: 0.2546\n",
      "Epoch 384/1000\n",
      "9719/9719 [==============================] - 4s 448us/step - loss: 3.4486 - acc: 0.2541\n",
      "Epoch 385/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 3.4840 - acc: 0.2492\n",
      "Epoch 386/1000\n",
      "9719/9719 [==============================] - 4s 452us/step - loss: 3.4533 - acc: 0.2554\n",
      "Epoch 387/1000\n",
      "9719/9719 [==============================] - 5s 482us/step - loss: 3.4478 - acc: 0.2585\n",
      "Epoch 388/1000\n",
      "9719/9719 [==============================] - 5s 479us/step - loss: 3.4632 - acc: 0.2496\n",
      "Epoch 389/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 3.4897 - acc: 0.2465\n",
      "Epoch 390/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.4616 - acc: 0.2594\n",
      "Epoch 391/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.4400 - acc: 0.2568\n",
      "Epoch 392/1000\n",
      "9719/9719 [==============================] - 4s 455us/step - loss: 3.4491 - acc: 0.2523\n",
      "Epoch 393/1000\n",
      "9719/9719 [==============================] - 5s 480us/step - loss: 3.4527 - acc: 0.2533\n",
      "Epoch 394/1000\n",
      "9719/9719 [==============================] - 5s 506us/step - loss: 3.4605 - acc: 0.2513\n",
      "Epoch 395/1000\n",
      "9719/9719 [==============================] - 5s 465us/step - loss: 3.4607 - acc: 0.2469\n",
      "Epoch 396/1000\n",
      "9719/9719 [==============================] - 4s 435us/step - loss: 3.4479 - acc: 0.2598\n",
      "Epoch 397/1000\n",
      "9719/9719 [==============================] - 4s 443us/step - loss: 3.4697 - acc: 0.2524\n",
      "Epoch 398/1000\n",
      "9719/9719 [==============================] - 5s 468us/step - loss: 3.4388 - acc: 0.2587\n",
      "Epoch 399/1000\n",
      "9719/9719 [==============================] - 5s 477us/step - loss: 3.4678 - acc: 0.2499\n",
      "Epoch 400/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 3.4296 - acc: 0.2622\n",
      "Epoch 401/1000\n",
      "9719/9719 [==============================] - 4s 451us/step - loss: 3.4680 - acc: 0.2526\n",
      "Epoch 402/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.4439 - acc: 0.2549\n",
      "Epoch 403/1000\n",
      "9719/9719 [==============================] - 4s 435us/step - loss: 3.4471 - acc: 0.2567\n",
      "Epoch 404/1000\n",
      "9719/9719 [==============================] - 4s 461us/step - loss: 3.4264 - acc: 0.2587\n",
      "Epoch 405/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 3.4471 - acc: 0.2526\n",
      "Epoch 406/1000\n",
      "9719/9719 [==============================] - 5s 467us/step - loss: 3.4411 - acc: 0.2521\n",
      "Epoch 407/1000\n",
      "9719/9719 [==============================] - 5s 480us/step - loss: 3.4457 - acc: 0.2516\n",
      "Epoch 408/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 3.4473 - acc: 0.2526\n",
      "Epoch 409/1000\n",
      "9719/9719 [==============================] - 4s 449us/step - loss: 3.4188 - acc: 0.2668\n",
      "Epoch 410/1000\n",
      "9719/9719 [==============================] - 4s 443us/step - loss: 3.4539 - acc: 0.2545\n",
      "Epoch 411/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.4238 - acc: 0.2585\n",
      "Epoch 412/1000\n",
      "9719/9719 [==============================] - 5s 474us/step - loss: 3.4191 - acc: 0.2652\n",
      "Epoch 413/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.4491 - acc: 0.2561\n",
      "Epoch 414/1000\n",
      "9719/9719 [==============================] - 4s 456us/step - loss: 3.4189 - acc: 0.2666\n",
      "Epoch 415/1000\n",
      "9719/9719 [==============================] - 4s 447us/step - loss: 3.4393 - acc: 0.2523\n",
      "Epoch 416/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.4120 - acc: 0.2627\n",
      "Epoch 417/1000\n",
      "9719/9719 [==============================] - 4s 436us/step - loss: 3.4065 - acc: 0.2620\n",
      "Epoch 418/1000\n",
      "9719/9719 [==============================] - 5s 477us/step - loss: 3.4381 - acc: 0.2497\n",
      "Epoch 419/1000\n",
      "9719/9719 [==============================] - 5s 476us/step - loss: 3.4093 - acc: 0.2642\n",
      "Epoch 420/1000\n",
      "9719/9719 [==============================] - 4s 453us/step - loss: 3.4380 - acc: 0.2593\n",
      "Epoch 421/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.4228 - acc: 0.2620\n",
      "Epoch 422/1000\n",
      "9719/9719 [==============================] - 4s 439us/step - loss: 3.4075 - acc: 0.2637\n",
      "Epoch 423/1000\n",
      "9719/9719 [==============================] - 4s 448us/step - loss: 3.4346 - acc: 0.2555\n",
      "Epoch 424/1000\n",
      "9719/9719 [==============================] - 5s 475us/step - loss: 3.3981 - acc: 0.2694\n",
      "Epoch 425/1000\n",
      "9719/9719 [==============================] - 5s 470us/step - loss: 3.4282 - acc: 0.2577\n",
      "Epoch 426/1000\n",
      "9719/9719 [==============================] - 4s 454us/step - loss: 3.4028 - acc: 0.2671\n",
      "Epoch 427/1000\n",
      "9719/9719 [==============================] - 4s 434us/step - loss: 3.4204 - acc: 0.2577\n",
      "Epoch 428/1000\n",
      "9719/9719 [==============================] - 4s 437us/step - loss: 3.4231 - acc: 0.2607\n",
      "Epoch 429/1000\n",
      "9719/9719 [==============================] - 4s 454us/step - loss: 3.4198 - acc: 0.2635\n",
      "Epoch 430/1000\n",
      "9719/9719 [==============================] - 5s 473us/step - loss: 3.4234 - acc: 0.2608\n",
      "Epoch 431/1000\n",
      "9719/9719 [==============================] - 5s 467us/step - loss: 3.4269 - acc: 0.2591\n",
      "Epoch 432/1000\n",
      "9719/9719 [==============================] - 4s 453us/step - loss: 3.4115 - acc: 0.2626\n",
      "Epoch 433/1000\n",
      "9719/9719 [==============================] - 4s 432us/step - loss: 3.4076 - acc: 0.2621\n",
      "Epoch 434/1000\n",
      "9719/9719 [==============================] - 4s 435us/step - loss: 3.4123 - acc: 0.2658\n",
      "Epoch 435/1000\n",
      "9719/9719 [==============================] - 4s 463us/step - loss: 3.4102 - acc: 0.2641\n",
      "Epoch 436/1000\n",
      "9719/9719 [==============================] - 5s 474us/step - loss: 3.3949 - acc: 0.2657\n",
      "Epoch 437/1000\n",
      "9719/9719 [==============================] - 5s 470us/step - loss: 3.4105 - acc: 0.2633\n",
      "Epoch 438/1000\n",
      "9719/9719 [==============================] - 4s 450us/step - loss: 3.4013 - acc: 0.2662\n",
      "Epoch 439/1000\n",
      "9719/9719 [==============================] - 4s 436us/step - loss: 3.4115 - acc: 0.2618\n",
      "Epoch 440/1000\n",
      "9719/9719 [==============================] - 4s 432us/step - loss: 3.4004 - acc: 0.2648\n",
      "Epoch 441/1000\n",
      "9719/9719 [==============================] - 5s 471us/step - loss: 3.4173 - acc: 0.2657\n",
      "Epoch 442/1000\n",
      "9719/9719 [==============================] - 5s 477us/step - loss: 3.3732 - acc: 0.2700\n",
      "Epoch 443/1000\n",
      "9719/9719 [==============================] - 4s 456us/step - loss: 3.4073 - acc: 0.2674\n",
      "Epoch 444/1000\n",
      "9719/9719 [==============================] - 4s 447us/step - loss: 3.3747 - acc: 0.2689\n",
      "Epoch 445/1000\n",
      "9719/9719 [==============================] - 4s 436us/step - loss: 3.4369 - acc: 0.2579\n",
      "Epoch 446/1000\n",
      "9719/9719 [==============================] - 4s 434us/step - loss: 3.3934 - acc: 0.2665\n",
      "Epoch 447/1000\n",
      "9719/9719 [==============================] - 5s 479us/step - loss: 3.3984 - acc: 0.2650\n",
      "Epoch 448/1000\n",
      "9719/9719 [==============================] - 5s 480us/step - loss: 3.4041 - acc: 0.2674\n",
      "Epoch 449/1000\n",
      "9719/9719 [==============================] - 4s 455us/step - loss: 3.3687 - acc: 0.2704\n",
      "Epoch 450/1000\n",
      "9719/9719 [==============================] - 4s 444us/step - loss: 3.3848 - acc: 0.2669\n",
      "Epoch 451/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 3.3703 - acc: 0.2740\n",
      "Epoch 452/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.4037 - acc: 0.2611\n",
      "Epoch 453/1000\n",
      "9719/9719 [==============================] - 4s 456us/step - loss: 3.3663 - acc: 0.2691\n",
      "Epoch 454/1000\n",
      "9719/9719 [==============================] - 4s 454us/step - loss: 3.4128 - acc: 0.2559\n",
      "Epoch 455/1000\n",
      "9719/9719 [==============================] - 4s 459us/step - loss: 3.3964 - acc: 0.2676\n",
      "Epoch 456/1000\n",
      "9719/9719 [==============================] - 4s 454us/step - loss: 3.3881 - acc: 0.2756\n",
      "Epoch 457/1000\n",
      "9719/9719 [==============================] - 4s 462us/step - loss: 3.3890 - acc: 0.2656\n",
      "Epoch 458/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.3712 - acc: 0.2650\n",
      "Epoch 459/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 3.4020 - acc: 0.2673\n",
      "Epoch 460/1000\n",
      "9719/9719 [==============================] - 4s 452us/step - loss: 3.3824 - acc: 0.2665\n",
      "Epoch 461/1000\n",
      "9719/9719 [==============================] - 4s 437us/step - loss: 3.3744 - acc: 0.2707\n",
      "Epoch 462/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.3661 - acc: 0.2726\n",
      "Epoch 463/1000\n",
      "9719/9719 [==============================] - 5s 469us/step - loss: 3.3831 - acc: 0.2638\n",
      "Epoch 464/1000\n",
      "9719/9719 [==============================] - 5s 482us/step - loss: 3.3724 - acc: 0.2726\n",
      "Epoch 465/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 3.3750 - acc: 0.2683\n",
      "Epoch 466/1000\n",
      "9719/9719 [==============================] - 4s 451us/step - loss: 3.3730 - acc: 0.2717\n",
      "Epoch 467/1000\n",
      "9719/9719 [==============================] - 4s 437us/step - loss: 3.3809 - acc: 0.2662\n",
      "Epoch 468/1000\n",
      "9719/9719 [==============================] - 4s 434us/step - loss: 3.3987 - acc: 0.2627\n",
      "Epoch 469/1000\n",
      "9719/9719 [==============================] - 5s 476us/step - loss: 3.3770 - acc: 0.2679\n",
      "Epoch 470/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.3614 - acc: 0.2768\n",
      "Epoch 471/1000\n",
      "9719/9719 [==============================] - 4s 454us/step - loss: 3.3832 - acc: 0.2704\n",
      "Epoch 472/1000\n",
      "9719/9719 [==============================] - 4s 447us/step - loss: 3.3755 - acc: 0.2709\n",
      "Epoch 473/1000\n",
      "9719/9719 [==============================] - 4s 439us/step - loss: 3.3794 - acc: 0.2698\n",
      "Epoch 474/1000\n",
      "9719/9719 [==============================] - 4s 442us/step - loss: 3.3800 - acc: 0.2686\n",
      "Epoch 475/1000\n",
      "9719/9719 [==============================] - 5s 476us/step - loss: 3.3745 - acc: 0.2702\n",
      "Epoch 476/1000\n",
      "9719/9719 [==============================] - 5s 477us/step - loss: 3.3756 - acc: 0.2714\n",
      "Epoch 477/1000\n",
      "9719/9719 [==============================] - 4s 452us/step - loss: 3.3702 - acc: 0.2730\n",
      "Epoch 478/1000\n",
      "9719/9719 [==============================] - 4s 444us/step - loss: 3.3349 - acc: 0.2770\n",
      "Epoch 479/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 3.3746 - acc: 0.2675\n",
      "Epoch 480/1000\n",
      "9719/9719 [==============================] - 4s 451us/step - loss: 3.3613 - acc: 0.2756\n",
      "Epoch 481/1000\n",
      "9719/9719 [==============================] - 5s 480us/step - loss: 3.3677 - acc: 0.2700\n",
      "Epoch 482/1000\n",
      "9719/9719 [==============================] - 5s 473us/step - loss: 3.3530 - acc: 0.2731\n",
      "Epoch 483/1000\n",
      "9719/9719 [==============================] - 4s 454us/step - loss: 3.3573 - acc: 0.2741\n",
      "Epoch 484/1000\n",
      "9719/9719 [==============================] - 4s 433us/step - loss: 3.3803 - acc: 0.2739\n",
      "Epoch 485/1000\n",
      "9719/9719 [==============================] - 4s 439us/step - loss: 3.3547 - acc: 0.2751\n",
      "Epoch 486/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 3.3499 - acc: 0.2754\n",
      "Epoch 487/1000\n",
      "9719/9719 [==============================] - 5s 482us/step - loss: 3.3359 - acc: 0.2800\n",
      "Epoch 488/1000\n",
      "9719/9719 [==============================] - 5s 467us/step - loss: 3.3671 - acc: 0.2685\n",
      "Epoch 489/1000\n",
      "9719/9719 [==============================] - 4s 453us/step - loss: 3.3936 - acc: 0.2691\n",
      "Epoch 490/1000\n",
      "9719/9719 [==============================] - 4s 435us/step - loss: 3.3619 - acc: 0.2704\n",
      "Epoch 491/1000\n",
      "9719/9719 [==============================] - 4s 437us/step - loss: 3.3443 - acc: 0.2754\n",
      "Epoch 492/1000\n",
      "9719/9719 [==============================] - 5s 473us/step - loss: 3.3466 - acc: 0.2720\n",
      "Epoch 493/1000\n",
      "9719/9719 [==============================] - 5s 477us/step - loss: 3.3580 - acc: 0.2700\n",
      "Epoch 494/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 3.3678 - acc: 0.2742\n",
      "Epoch 495/1000\n",
      "9719/9719 [==============================] - 4s 448us/step - loss: 3.3474 - acc: 0.2749\n",
      "Epoch 496/1000\n",
      "9719/9719 [==============================] - 4s 439us/step - loss: 3.3206 - acc: 0.2817\n",
      "Epoch 497/1000\n",
      "9719/9719 [==============================] - 4s 432us/step - loss: 3.3412 - acc: 0.2791\n",
      "Epoch 498/1000\n",
      "9719/9719 [==============================] - 5s 474us/step - loss: 3.3441 - acc: 0.2799\n",
      "Epoch 499/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.3503 - acc: 0.2727\n",
      "Epoch 500/1000\n",
      "9719/9719 [==============================] - 4s 452us/step - loss: 3.3386 - acc: 0.2768\n",
      "Epoch 501/1000\n",
      "9719/9719 [==============================] - 4s 445us/step - loss: 3.3553 - acc: 0.2701\n",
      "Epoch 502/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.3457 - acc: 0.2729\n",
      "Epoch 503/1000\n",
      "9719/9719 [==============================] - 4s 437us/step - loss: 3.3538 - acc: 0.2748\n",
      "Epoch 504/1000\n",
      "9719/9719 [==============================] - 5s 477us/step - loss: 3.3564 - acc: 0.2690\n",
      "Epoch 505/1000\n",
      "9719/9719 [==============================] - 5s 479us/step - loss: 3.3390 - acc: 0.2776\n",
      "Epoch 506/1000\n",
      "9719/9719 [==============================] - 4s 451us/step - loss: 3.3409 - acc: 0.2801\n",
      "Epoch 507/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 3.3421 - acc: 0.2701\n",
      "Epoch 508/1000\n",
      "9719/9719 [==============================] - 4s 439us/step - loss: 3.3429 - acc: 0.2748\n",
      "Epoch 509/1000\n",
      "9719/9719 [==============================] - 4s 447us/step - loss: 3.3158 - acc: 0.2769\n",
      "Epoch 510/1000\n",
      "9719/9719 [==============================] - 5s 476us/step - loss: 3.3515 - acc: 0.2691\n",
      "Epoch 511/1000\n",
      "9719/9719 [==============================] - 5s 472us/step - loss: 3.3424 - acc: 0.2781\n",
      "Epoch 512/1000\n",
      "9719/9719 [==============================] - 4s 456us/step - loss: 3.3356 - acc: 0.2743\n",
      "Epoch 513/1000\n",
      "9719/9719 [==============================] - 4s 435us/step - loss: 3.3355 - acc: 0.2774\n",
      "Epoch 514/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.3399 - acc: 0.2744\n",
      "Epoch 515/1000\n",
      "9719/9719 [==============================] - 4s 457us/step - loss: 3.3251 - acc: 0.2809\n",
      "Epoch 516/1000\n",
      "9719/9719 [==============================] - 5s 479us/step - loss: 3.3364 - acc: 0.2749\n",
      "Epoch 517/1000\n",
      "9719/9719 [==============================] - 5s 466us/step - loss: 3.3241 - acc: 0.2808\n",
      "Epoch 518/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 3.3376 - acc: 0.2736\n",
      "Epoch 519/1000\n",
      "9719/9719 [==============================] - 4s 436us/step - loss: 3.3284 - acc: 0.2797\n",
      "Epoch 520/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.3374 - acc: 0.2765\n",
      "Epoch 521/1000\n",
      "9719/9719 [==============================] - 5s 465us/step - loss: 3.3360 - acc: 0.2818\n",
      "Epoch 522/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.3213 - acc: 0.2809\n",
      "Epoch 523/1000\n",
      "9719/9719 [==============================] - 5s 463us/step - loss: 3.3560 - acc: 0.2783\n",
      "Epoch 524/1000\n",
      "9719/9719 [==============================] - 4s 452us/step - loss: 3.3041 - acc: 0.2842\n",
      "Epoch 525/1000\n",
      "9719/9719 [==============================] - 4s 436us/step - loss: 3.3451 - acc: 0.2715\n",
      "Epoch 526/1000\n",
      "9719/9719 [==============================] - 4s 432us/step - loss: 3.3104 - acc: 0.2786\n",
      "Epoch 527/1000\n",
      "9719/9719 [==============================] - 5s 474us/step - loss: 3.3211 - acc: 0.2820\n",
      "Epoch 528/1000\n",
      "9719/9719 [==============================] - 5s 477us/step - loss: 3.3288 - acc: 0.2775\n",
      "Epoch 529/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 3.3318 - acc: 0.2737\n",
      "Epoch 530/1000\n",
      "9719/9719 [==============================] - 4s 447us/step - loss: 3.3101 - acc: 0.2808\n",
      "Epoch 531/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.3184 - acc: 0.2846\n",
      "Epoch 532/1000\n",
      "9719/9719 [==============================] - 4s 439us/step - loss: 3.3365 - acc: 0.2796\n",
      "Epoch 533/1000\n",
      "9719/9719 [==============================] - 5s 476us/step - loss: 3.3128 - acc: 0.2840\n",
      "Epoch 534/1000\n",
      "9719/9719 [==============================] - 5s 477us/step - loss: 3.3096 - acc: 0.2830\n",
      "Epoch 535/1000\n",
      "9719/9719 [==============================] - 4s 452us/step - loss: 3.3093 - acc: 0.2830\n",
      "Epoch 536/1000\n",
      "9719/9719 [==============================] - 4s 444us/step - loss: 3.3359 - acc: 0.2779\n",
      "Epoch 537/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.2899 - acc: 0.2875\n",
      "Epoch 538/1000\n",
      "9719/9719 [==============================] - 4s 445us/step - loss: 3.3336 - acc: 0.2784\n",
      "Epoch 539/1000\n",
      "9719/9719 [==============================] - 5s 474us/step - loss: 3.3019 - acc: 0.2843\n",
      "Epoch 540/1000\n",
      "9719/9719 [==============================] - 5s 475us/step - loss: 3.3097 - acc: 0.2833\n",
      "Epoch 541/1000\n",
      "9719/9719 [==============================] - 4s 455us/step - loss: 3.3237 - acc: 0.2787\n",
      "Epoch 542/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 3.3204 - acc: 0.2783\n",
      "Epoch 543/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 3.2846 - acc: 0.2884\n",
      "Epoch 544/1000\n",
      "9719/9719 [==============================] - 4s 453us/step - loss: 3.3362 - acc: 0.2725\n",
      "Epoch 545/1000\n",
      "9719/9719 [==============================] - 5s 484us/step - loss: 3.3017 - acc: 0.2825\n",
      "Epoch 546/1000\n",
      "9719/9719 [==============================] - 5s 472us/step - loss: 3.3075 - acc: 0.2862\n",
      "Epoch 547/1000\n",
      "9719/9719 [==============================] - 4s 455us/step - loss: 3.3233 - acc: 0.2824\n",
      "Epoch 548/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9719/9719 [==============================] - 4s 434us/step - loss: 3.3070 - acc: 0.2819\n",
      "Epoch 549/1000\n",
      "9719/9719 [==============================] - 4s 442us/step - loss: 3.2967 - acc: 0.2871\n",
      "Epoch 550/1000\n",
      "9719/9719 [==============================] - 5s 464us/step - loss: 3.3111 - acc: 0.2873\n",
      "Epoch 551/1000\n",
      "9719/9719 [==============================] - 5s 477us/step - loss: 3.3081 - acc: 0.2815\n",
      "Epoch 552/1000\n",
      "9719/9719 [==============================] - 5s 466us/step - loss: 3.3061 - acc: 0.2819\n",
      "Epoch 553/1000\n",
      "9719/9719 [==============================] - 4s 455us/step - loss: 3.2698 - acc: 0.2889\n",
      "Epoch 554/1000\n",
      "9719/9719 [==============================] - 4s 437us/step - loss: 3.3195 - acc: 0.2825\n",
      "Epoch 555/1000\n",
      "9719/9719 [==============================] - 4s 435us/step - loss: 3.2998 - acc: 0.2832\n",
      "Epoch 556/1000\n",
      "9719/9719 [==============================] - 5s 470us/step - loss: 3.2970 - acc: 0.2879\n",
      "Epoch 557/1000\n",
      "9719/9719 [==============================] - 5s 477us/step - loss: 3.2861 - acc: 0.2881\n",
      "Epoch 558/1000\n",
      "9719/9719 [==============================] - 4s 457us/step - loss: 3.3090 - acc: 0.2845\n",
      "Epoch 559/1000\n",
      "9719/9719 [==============================] - 4s 451us/step - loss: 3.2964 - acc: 0.2849\n",
      "Epoch 560/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.3104 - acc: 0.2841\n",
      "Epoch 561/1000\n",
      "9719/9719 [==============================] - 4s 437us/step - loss: 3.3001 - acc: 0.2824\n",
      "Epoch 562/1000\n",
      "9719/9719 [==============================] - 5s 479us/step - loss: 3.2879 - acc: 0.2873\n",
      "Epoch 563/1000\n",
      "9719/9719 [==============================] - 5s 481us/step - loss: 3.2975 - acc: 0.2847\n",
      "Epoch 564/1000\n",
      "9719/9719 [==============================] - 4s 453us/step - loss: 3.2995 - acc: 0.2811\n",
      "Epoch 565/1000\n",
      "9719/9719 [==============================] - 4s 443us/step - loss: 3.2974 - acc: 0.2842\n",
      "Epoch 566/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.2900 - acc: 0.2887\n",
      "Epoch 567/1000\n",
      "9719/9719 [==============================] - 4s 443us/step - loss: 3.3008 - acc: 0.2858\n",
      "Epoch 568/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.2976 - acc: 0.2811\n",
      "Epoch 569/1000\n",
      "9719/9719 [==============================] - 5s 476us/step - loss: 3.2882 - acc: 0.2846\n",
      "Epoch 570/1000\n",
      "9719/9719 [==============================] - 4s 455us/step - loss: 3.2923 - acc: 0.2858\n",
      "Epoch 571/1000\n",
      "9719/9719 [==============================] - 4s 436us/step - loss: 3.2720 - acc: 0.2864\n",
      "Epoch 572/1000\n",
      "9719/9719 [==============================] - 4s 439us/step - loss: 3.2889 - acc: 0.2884\n",
      "Epoch 573/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 3.2949 - acc: 0.2822\n",
      "Epoch 574/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.2687 - acc: 0.2899\n",
      "Epoch 575/1000\n",
      "9719/9719 [==============================] - 5s 471us/step - loss: 3.3041 - acc: 0.2874\n",
      "Epoch 576/1000\n",
      "9719/9719 [==============================] - 4s 452us/step - loss: 3.2905 - acc: 0.2816\n",
      "Epoch 577/1000\n",
      "9719/9719 [==============================] - 4s 431us/step - loss: 3.2813 - acc: 0.2857\n",
      "Epoch 578/1000\n",
      "9719/9719 [==============================] - 4s 436us/step - loss: 3.2904 - acc: 0.2817\n",
      "Epoch 579/1000\n",
      "9719/9719 [==============================] - 4s 462us/step - loss: 3.2640 - acc: 0.3013\n",
      "Epoch 580/1000\n",
      "9719/9719 [==============================] - 5s 474us/step - loss: 3.2643 - acc: 0.2893\n",
      "Epoch 581/1000\n",
      "9719/9719 [==============================] - 5s 464us/step - loss: 3.3060 - acc: 0.2821\n",
      "Epoch 582/1000\n",
      "9719/9719 [==============================] - 4s 451us/step - loss: 3.2519 - acc: 0.2925\n",
      "Epoch 583/1000\n",
      "9719/9719 [==============================] - 4s 436us/step - loss: 3.2861 - acc: 0.2866\n",
      "Epoch 584/1000\n",
      "9719/9719 [==============================] - 4s 434us/step - loss: 3.2997 - acc: 0.2827\n",
      "Epoch 585/1000\n",
      "9719/9719 [==============================] - 5s 471us/step - loss: 3.2864 - acc: 0.2909\n",
      "Epoch 586/1000\n",
      "9719/9719 [==============================] - 5s 475us/step - loss: 3.2613 - acc: 0.2959\n",
      "Epoch 587/1000\n",
      "9719/9719 [==============================] - 4s 457us/step - loss: 3.3215 - acc: 0.2790\n",
      "Epoch 588/1000\n",
      "9719/9719 [==============================] - 4s 447us/step - loss: 3.2504 - acc: 0.2959\n",
      "Epoch 589/1000\n",
      "9719/9719 [==============================] - 4s 435us/step - loss: 3.2753 - acc: 0.2874\n",
      "Epoch 590/1000\n",
      "9719/9719 [==============================] - 4s 434us/step - loss: 3.2822 - acc: 0.2871\n",
      "Epoch 591/1000\n",
      "9719/9719 [==============================] - 5s 475us/step - loss: 3.2946 - acc: 0.2864\n",
      "Epoch 592/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.2622 - acc: 0.2941\n",
      "Epoch 593/1000\n",
      "9719/9719 [==============================] - 4s 452us/step - loss: 3.2821 - acc: 0.2881\n",
      "Epoch 594/1000\n",
      "9719/9719 [==============================] - 4s 444us/step - loss: 3.2504 - acc: 0.2988\n",
      "Epoch 595/1000\n",
      "9719/9719 [==============================] - 4s 436us/step - loss: 3.2559 - acc: 0.2916\n",
      "Epoch 596/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.2725 - acc: 0.2915\n",
      "Epoch 597/1000\n",
      "9719/9719 [==============================] - 5s 475us/step - loss: 3.2652 - acc: 0.2909\n",
      "Epoch 598/1000\n",
      "9719/9719 [==============================] - 5s 475us/step - loss: 3.2532 - acc: 0.2921\n",
      "Epoch 599/1000\n",
      "9719/9719 [==============================] - 4s 456us/step - loss: 3.2943 - acc: 0.2821\n",
      "Epoch 600/1000\n",
      "9719/9719 [==============================] - 4s 443us/step - loss: 3.2595 - acc: 0.2962\n",
      "Epoch 601/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 3.2542 - acc: 0.2937\n",
      "Epoch 602/1000\n",
      "9719/9719 [==============================] - 4s 451us/step - loss: 3.2762 - acc: 0.2917\n",
      "Epoch 603/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.2713 - acc: 0.2917\n",
      "Epoch 604/1000\n",
      "9719/9719 [==============================] - 5s 472us/step - loss: 3.2773 - acc: 0.2877\n",
      "Epoch 605/1000\n",
      "9719/9719 [==============================] - 4s 452us/step - loss: 3.2494 - acc: 0.3004\n",
      "Epoch 606/1000\n",
      "9719/9719 [==============================] - 4s 430us/step - loss: 3.2608 - acc: 0.2895\n",
      "Epoch 607/1000\n",
      "9719/9719 [==============================] - 4s 437us/step - loss: 3.2711 - acc: 0.2864\n",
      "Epoch 608/1000\n",
      "9719/9719 [==============================] - 4s 455us/step - loss: 3.2380 - acc: 0.2963\n",
      "Epoch 609/1000\n",
      "9719/9719 [==============================] - 5s 474us/step - loss: 3.2621 - acc: 0.2924\n",
      "Epoch 610/1000\n",
      "9719/9719 [==============================] - 5s 468us/step - loss: 3.2845 - acc: 0.2880\n",
      "Epoch 611/1000\n",
      "9719/9719 [==============================] - 4s 453us/step - loss: 3.2397 - acc: 0.2963\n",
      "Epoch 612/1000\n",
      "9719/9719 [==============================] - 4s 431us/step - loss: 3.2487 - acc: 0.2937\n",
      "Epoch 613/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.2868 - acc: 0.2884\n",
      "Epoch 614/1000\n",
      "9719/9719 [==============================] - 5s 470us/step - loss: 3.2334 - acc: 0.2984\n",
      "Epoch 615/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.2812 - acc: 0.2881\n",
      "Epoch 616/1000\n",
      "9719/9719 [==============================] - 5s 465us/step - loss: 3.2396 - acc: 0.2941\n",
      "Epoch 617/1000\n",
      "9719/9719 [==============================] - 4s 450us/step - loss: 3.2544 - acc: 0.2993\n",
      "Epoch 618/1000\n",
      "9719/9719 [==============================] - 4s 437us/step - loss: 3.2575 - acc: 0.2952\n",
      "Epoch 619/1000\n",
      "9719/9719 [==============================] - 4s 432us/step - loss: 3.2512 - acc: 0.2894\n",
      "Epoch 620/1000\n",
      "9719/9719 [==============================] - 5s 471us/step - loss: 3.2482 - acc: 0.2937\n",
      "Epoch 621/1000\n",
      "9719/9719 [==============================] - 5s 477us/step - loss: 3.2591 - acc: 0.2917\n",
      "Epoch 622/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 3.2497 - acc: 0.2942\n",
      "Epoch 623/1000\n",
      "9719/9719 [==============================] - 4s 448us/step - loss: 3.2473 - acc: 0.2982\n",
      "Epoch 624/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.2570 - acc: 0.2921\n",
      "Epoch 625/1000\n",
      "9719/9719 [==============================] - 4s 439us/step - loss: 3.2595 - acc: 0.2883\n",
      "Epoch 626/1000\n",
      "9719/9719 [==============================] - 5s 481us/step - loss: 3.2622 - acc: 0.2896\n",
      "Epoch 627/1000\n",
      "9719/9719 [==============================] - 5s 480us/step - loss: 3.2428 - acc: 0.2917\n",
      "Epoch 628/1000\n",
      "9719/9719 [==============================] - 4s 452us/step - loss: 3.2421 - acc: 0.2948\n",
      "Epoch 629/1000\n",
      "9719/9719 [==============================] - 4s 444us/step - loss: 3.2596 - acc: 0.3004\n",
      "Epoch 630/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.2429 - acc: 0.2916\n",
      "Epoch 631/1000\n",
      "9719/9719 [==============================] - 4s 448us/step - loss: 3.2414 - acc: 0.2941\n",
      "Epoch 632/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.2658 - acc: 0.2877\n",
      "Epoch 633/1000\n",
      "9719/9719 [==============================] - 5s 475us/step - loss: 3.2283 - acc: 0.2980\n",
      "Epoch 634/1000\n",
      "9719/9719 [==============================] - 4s 455us/step - loss: 3.2597 - acc: 0.2904\n",
      "Epoch 635/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.2365 - acc: 0.2988\n",
      "Epoch 636/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.2673 - acc: 0.2863\n",
      "Epoch 637/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 3.2517 - acc: 0.2915\n",
      "Epoch 638/1000\n",
      "9719/9719 [==============================] - 5s 475us/step - loss: 3.2379 - acc: 0.2935\n",
      "Epoch 639/1000\n",
      "9719/9719 [==============================] - 5s 470us/step - loss: 3.2283 - acc: 0.3000\n",
      "Epoch 640/1000\n",
      "9719/9719 [==============================] - 4s 455us/step - loss: 3.2467 - acc: 0.2939\n",
      "Epoch 641/1000\n",
      "9719/9719 [==============================] - 4s 437us/step - loss: 3.2430 - acc: 0.2955\n",
      "Epoch 642/1000\n",
      "9719/9719 [==============================] - 4s 442us/step - loss: 3.2547 - acc: 0.2930\n",
      "Epoch 643/1000\n",
      "9719/9719 [==============================] - 5s 467us/step - loss: 3.2449 - acc: 0.2979\n",
      "Epoch 644/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.2547 - acc: 0.2942\n",
      "Epoch 645/1000\n",
      "9719/9719 [==============================] - 5s 465us/step - loss: 3.2218 - acc: 0.3000\n",
      "Epoch 646/1000\n",
      "9719/9719 [==============================] - 4s 450us/step - loss: 3.2404 - acc: 0.2961\n",
      "Epoch 647/1000\n",
      "9719/9719 [==============================] - 4s 439us/step - loss: 3.2349 - acc: 0.2966\n",
      "Epoch 648/1000\n",
      "9719/9719 [==============================] - 4s 434us/step - loss: 3.2257 - acc: 0.2911\n",
      "Epoch 649/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 3.2503 - acc: 0.2939\n",
      "Epoch 650/1000\n",
      "9719/9719 [==============================] - 4s 461us/step - loss: 3.2193 - acc: 0.2946\n",
      "Epoch 651/1000\n",
      "9719/9719 [==============================] - 4s 457us/step - loss: 3.2447 - acc: 0.2939\n",
      "Epoch 652/1000\n",
      "9719/9719 [==============================] - 4s 457us/step - loss: 3.2209 - acc: 0.3017\n",
      "Epoch 653/1000\n",
      "9719/9719 [==============================] - 4s 461us/step - loss: 3.2342 - acc: 0.2939\n",
      "Epoch 654/1000\n",
      "9719/9719 [==============================] - 5s 477us/step - loss: 3.2529 - acc: 0.2947\n",
      "Epoch 655/1000\n",
      "9719/9719 [==============================] - 5s 467us/step - loss: 3.2249 - acc: 0.2993\n",
      "Epoch 656/1000\n",
      "9719/9719 [==============================] - 4s 454us/step - loss: 3.2486 - acc: 0.2919\n",
      "Epoch 657/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.2045 - acc: 0.3013\n",
      "Epoch 658/1000\n",
      "9719/9719 [==============================] - 4s 432us/step - loss: 3.2340 - acc: 0.2945\n",
      "Epoch 659/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 3.2327 - acc: 0.2970\n",
      "Epoch 660/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.2162 - acc: 0.2991\n",
      "Epoch 661/1000\n",
      "9719/9719 [==============================] - 5s 470us/step - loss: 3.2200 - acc: 0.2999\n",
      "Epoch 662/1000\n",
      "9719/9719 [==============================] - 4s 453us/step - loss: 3.2513 - acc: 0.2913\n",
      "Epoch 663/1000\n",
      "9719/9719 [==============================] - 4s 434us/step - loss: 3.2186 - acc: 0.3009\n",
      "Epoch 664/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 3.2524 - acc: 0.2932\n",
      "Epoch 665/1000\n",
      "9719/9719 [==============================] - 4s 453us/step - loss: 3.1986 - acc: 0.3016\n",
      "Epoch 666/1000\n",
      "9719/9719 [==============================] - 4s 459us/step - loss: 3.2048 - acc: 0.2982\n",
      "Epoch 667/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 3.2420 - acc: 0.2933\n",
      "Epoch 668/1000\n",
      "9719/9719 [==============================] - 4s 459us/step - loss: 3.2284 - acc: 0.2957\n",
      "Epoch 669/1000\n",
      "9719/9719 [==============================] - 4s 450us/step - loss: 3.1937 - acc: 0.3068\n",
      "Epoch 670/1000\n",
      "9719/9719 [==============================] - 4s 457us/step - loss: 3.2233 - acc: 0.2953\n",
      "Epoch 671/1000\n",
      "9719/9719 [==============================] - 4s 453us/step - loss: 3.2548 - acc: 0.2892\n",
      "Epoch 672/1000\n",
      "9719/9719 [==============================] - 5s 469us/step - loss: 3.1930 - acc: 0.3009\n",
      "Epoch 673/1000\n",
      "9719/9719 [==============================] - 5s 476us/step - loss: 3.2373 - acc: 0.2878\n",
      "Epoch 674/1000\n",
      "9719/9719 [==============================] - 4s 459us/step - loss: 3.2319 - acc: 0.3019\n",
      "Epoch 675/1000\n",
      "9719/9719 [==============================] - 4s 445us/step - loss: 3.2007 - acc: 0.2991\n",
      "Epoch 676/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 3.2235 - acc: 0.2958\n",
      "Epoch 677/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.2185 - acc: 0.2969\n",
      "Epoch 678/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.1996 - acc: 0.3072\n",
      "Epoch 679/1000\n",
      "9719/9719 [==============================] - 5s 479us/step - loss: 3.2365 - acc: 0.3019\n",
      "Epoch 680/1000\n",
      "9719/9719 [==============================] - 4s 452us/step - loss: 3.2027 - acc: 0.3015\n",
      "Epoch 681/1000\n",
      "9719/9719 [==============================] - 4s 449us/step - loss: 3.2445 - acc: 0.2905\n",
      "Epoch 682/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.2175 - acc: 0.3025\n",
      "Epoch 683/1000\n",
      "9719/9719 [==============================] - 4s 442us/step - loss: 3.1845 - acc: 0.3063\n",
      "Epoch 684/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.2223 - acc: 0.3000\n",
      "Epoch 685/1000\n",
      "9719/9719 [==============================] - 5s 476us/step - loss: 3.2024 - acc: 0.2999\n",
      "Epoch 686/1000\n",
      "9719/9719 [==============================] - 4s 452us/step - loss: 3.2376 - acc: 0.3003\n",
      "Epoch 687/1000\n",
      "9719/9719 [==============================] - 4s 439us/step - loss: 3.2240 - acc: 0.3006\n",
      "Epoch 688/1000\n",
      "9719/9719 [==============================] - 4s 436us/step - loss: 3.2197 - acc: 0.2930\n",
      "Epoch 689/1000\n",
      "9719/9719 [==============================] - 4s 453us/step - loss: 3.2047 - acc: 0.3040\n",
      "Epoch 690/1000\n",
      "9719/9719 [==============================] - 5s 479us/step - loss: 3.2272 - acc: 0.2956\n",
      "Epoch 691/1000\n",
      "9719/9719 [==============================] - 5s 475us/step - loss: 3.2025 - acc: 0.3033\n",
      "Epoch 692/1000\n",
      "9719/9719 [==============================] - 4s 453us/step - loss: 3.2210 - acc: 0.2969\n",
      "Epoch 693/1000\n",
      "9719/9719 [==============================] - 4s 434us/step - loss: 3.2000 - acc: 0.3035\n",
      "Epoch 694/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.2095 - acc: 0.3045\n",
      "Epoch 695/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 3.1918 - acc: 0.3049\n",
      "Epoch 696/1000\n",
      "9719/9719 [==============================] - 5s 475us/step - loss: 3.2177 - acc: 0.2939\n",
      "Epoch 697/1000\n",
      "9719/9719 [==============================] - 5s 471us/step - loss: 3.1937 - acc: 0.3032\n",
      "Epoch 698/1000\n",
      "9719/9719 [==============================] - 4s 456us/step - loss: 3.2183 - acc: 0.2958\n",
      "Epoch 699/1000\n",
      "9719/9719 [==============================] - 4s 433us/step - loss: 3.2156 - acc: 0.2954\n",
      "Epoch 700/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.2234 - acc: 0.2991\n",
      "Epoch 701/1000\n",
      "9719/9719 [==============================] - 4s 454us/step - loss: 3.2007 - acc: 0.3031\n",
      "Epoch 702/1000\n",
      "9719/9719 [==============================] - 4s 459us/step - loss: 3.1850 - acc: 0.3052\n",
      "Epoch 703/1000\n",
      "9719/9719 [==============================] - 4s 463us/step - loss: 3.2099 - acc: 0.2954\n",
      "Epoch 704/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.1901 - acc: 0.3075\n",
      "Epoch 705/1000\n",
      "9719/9719 [==============================] - 5s 470us/step - loss: 3.2259 - acc: 0.2975\n",
      "Epoch 706/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9719/9719 [==============================] - 4s 457us/step - loss: 3.2098 - acc: 0.3012\n",
      "Epoch 707/1000\n",
      "9719/9719 [==============================] - 4s 442us/step - loss: 3.2065 - acc: 0.3038\n",
      "Epoch 708/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.1804 - acc: 0.3091\n",
      "Epoch 709/1000\n",
      "9719/9719 [==============================] - 5s 469us/step - loss: 3.2237 - acc: 0.2977\n",
      "Epoch 710/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.2157 - acc: 0.3023\n",
      "Epoch 711/1000\n",
      "9719/9719 [==============================] - 5s 472us/step - loss: 3.2011 - acc: 0.3038\n",
      "Epoch 712/1000\n",
      "9719/9719 [==============================] - 4s 454us/step - loss: 3.2026 - acc: 0.3081\n",
      "Epoch 713/1000\n",
      "9719/9719 [==============================] - 4s 437us/step - loss: 3.1986 - acc: 0.3055\n",
      "Epoch 714/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.1977 - acc: 0.3044\n",
      "Epoch 715/1000\n",
      "9719/9719 [==============================] - 5s 469us/step - loss: 3.2005 - acc: 0.3021\n",
      "Epoch 716/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.1767 - acc: 0.3027\n",
      "Epoch 717/1000\n",
      "9719/9719 [==============================] - 5s 465us/step - loss: 3.2158 - acc: 0.2982\n",
      "Epoch 718/1000\n",
      "9719/9719 [==============================] - 4s 452us/step - loss: 3.1887 - acc: 0.3002\n",
      "Epoch 719/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.1892 - acc: 0.3000\n",
      "Epoch 720/1000\n",
      "9719/9719 [==============================] - 4s 437us/step - loss: 3.2044 - acc: 0.3013\n",
      "Epoch 721/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.1962 - acc: 0.3030\n",
      "Epoch 722/1000\n",
      "9719/9719 [==============================] - 5s 482us/step - loss: 3.2075 - acc: 0.3018\n",
      "Epoch 723/1000\n",
      "9719/9719 [==============================] - 4s 454us/step - loss: 3.2093 - acc: 0.3029\n",
      "Epoch 724/1000\n",
      "9719/9719 [==============================] - 4s 446us/step - loss: 3.1709 - acc: 0.3115\n",
      "Epoch 725/1000\n",
      "9719/9719 [==============================] - 4s 439us/step - loss: 3.2081 - acc: 0.3019\n",
      "Epoch 726/1000\n",
      "9719/9719 [==============================] - 4s 445us/step - loss: 3.1783 - acc: 0.3057\n",
      "Epoch 727/1000\n",
      "9719/9719 [==============================] - 5s 479us/step - loss: 3.1843 - acc: 0.3087\n",
      "Epoch 728/1000\n",
      "9719/9719 [==============================] - 5s 479us/step - loss: 3.2101 - acc: 0.3008\n",
      "Epoch 729/1000\n",
      "9719/9719 [==============================] - 4s 451us/step - loss: 3.1790 - acc: 0.3115\n",
      "Epoch 730/1000\n",
      "9719/9719 [==============================] - 4s 437us/step - loss: 3.1958 - acc: 0.3093\n",
      "Epoch 731/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.1843 - acc: 0.3023\n",
      "Epoch 732/1000\n",
      "9719/9719 [==============================] - 4s 455us/step - loss: 3.2055 - acc: 0.3010\n",
      "Epoch 733/1000\n",
      "9719/9719 [==============================] - 5s 477us/step - loss: 3.1636 - acc: 0.3166\n",
      "Epoch 734/1000\n",
      "9719/9719 [==============================] - 5s 475us/step - loss: 3.1892 - acc: 0.3040\n",
      "Epoch 735/1000\n",
      "9719/9719 [==============================] - 4s 461us/step - loss: 3.2008 - acc: 0.2975\n",
      "Epoch 736/1000\n",
      "9719/9719 [==============================] - 4s 433us/step - loss: 3.1765 - acc: 0.3124\n",
      "Epoch 737/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 3.1847 - acc: 0.3098\n",
      "Epoch 738/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 3.2024 - acc: 0.2982\n",
      "Epoch 739/1000\n",
      "9719/9719 [==============================] - 5s 476us/step - loss: 3.1748 - acc: 0.3059\n",
      "Epoch 740/1000\n",
      "9719/9719 [==============================] - 5s 468us/step - loss: 3.1870 - acc: 0.3029\n",
      "Epoch 741/1000\n",
      "9719/9719 [==============================] - 4s 451us/step - loss: 3.1870 - acc: 0.3065\n",
      "Epoch 742/1000\n",
      "9719/9719 [==============================] - 4s 434us/step - loss: 3.1997 - acc: 0.2978\n",
      "Epoch 743/1000\n",
      "9719/9719 [==============================] - 4s 436us/step - loss: 3.1952 - acc: 0.3031\n",
      "Epoch 744/1000\n",
      "9719/9719 [==============================] - 5s 467us/step - loss: 3.1501 - acc: 0.3134\n",
      "Epoch 745/1000\n",
      "9719/9719 [==============================] - 5s 479us/step - loss: 3.1865 - acc: 0.3073\n",
      "Epoch 746/1000\n",
      "9719/9719 [==============================] - 4s 463us/step - loss: 3.1923 - acc: 0.3070\n",
      "Epoch 747/1000\n",
      "9719/9719 [==============================] - 4s 449us/step - loss: 3.1864 - acc: 0.3047\n",
      "Epoch 748/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 3.1706 - acc: 0.3037\n",
      "Epoch 749/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.1786 - acc: 0.3095\n",
      "Epoch 750/1000\n",
      "9719/9719 [==============================] - 5s 480us/step - loss: 3.1847 - acc: 0.3050\n",
      "Epoch 751/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.1502 - acc: 0.3140\n",
      "Epoch 752/1000\n",
      "9719/9719 [==============================] - 4s 459us/step - loss: 3.2119 - acc: 0.2961\n",
      "Epoch 753/1000\n",
      "9719/9719 [==============================] - 4s 447us/step - loss: 3.1799 - acc: 0.3097\n",
      "Epoch 754/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 3.1676 - acc: 0.3121\n",
      "Epoch 755/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.1776 - acc: 0.3082\n",
      "Epoch 756/1000\n",
      "9719/9719 [==============================] - 5s 475us/step - loss: 3.1654 - acc: 0.3086\n",
      "Epoch 757/1000\n",
      "9719/9719 [==============================] - 5s 477us/step - loss: 3.1610 - acc: 0.3131\n",
      "Epoch 758/1000\n",
      "9719/9719 [==============================] - 4s 455us/step - loss: 3.1942 - acc: 0.3064\n",
      "Epoch 759/1000\n",
      "9719/9719 [==============================] - 4s 442us/step - loss: 3.1685 - acc: 0.3066\n",
      "Epoch 760/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.1680 - acc: 0.3067\n",
      "Epoch 761/1000\n",
      "9719/9719 [==============================] - 4s 446us/step - loss: 3.1790 - acc: 0.3067\n",
      "Epoch 762/1000\n",
      "9719/9719 [==============================] - 4s 461us/step - loss: 3.1745 - acc: 0.3063\n",
      "Epoch 763/1000\n",
      "9719/9719 [==============================] - 4s 459us/step - loss: 3.1734 - acc: 0.3068\n",
      "Epoch 764/1000\n",
      "9719/9719 [==============================] - 4s 457us/step - loss: 3.1685 - acc: 0.3080\n",
      "Epoch 765/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 3.1790 - acc: 0.3058\n",
      "Epoch 766/1000\n",
      "9719/9719 [==============================] - 4s 459us/step - loss: 3.1476 - acc: 0.3156\n",
      "Epoch 767/1000\n",
      "9719/9719 [==============================] - 4s 459us/step - loss: 3.1851 - acc: 0.3054\n",
      "Epoch 768/1000\n",
      "9719/9719 [==============================] - 5s 464us/step - loss: 3.1588 - acc: 0.3122\n",
      "Epoch 769/1000\n",
      "9719/9719 [==============================] - 5s 474us/step - loss: 3.1721 - acc: 0.3106\n",
      "Epoch 770/1000\n",
      "9719/9719 [==============================] - 5s 465us/step - loss: 3.1947 - acc: 0.3036\n",
      "Epoch 771/1000\n",
      "9719/9719 [==============================] - 4s 455us/step - loss: 3.1677 - acc: 0.3052\n",
      "Epoch 772/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.1674 - acc: 0.3104\n",
      "Epoch 773/1000\n",
      "9719/9719 [==============================] - 4s 435us/step - loss: 3.1705 - acc: 0.3076\n",
      "Epoch 774/1000\n",
      "9719/9719 [==============================] - 5s 471us/step - loss: 3.1818 - acc: 0.3092\n",
      "Epoch 775/1000\n",
      "9719/9719 [==============================] - 5s 477us/step - loss: 3.1672 - acc: 0.3109\n",
      "Epoch 776/1000\n",
      "9719/9719 [==============================] - 5s 470us/step - loss: 3.1466 - acc: 0.3100\n",
      "Epoch 777/1000\n",
      "9719/9719 [==============================] - 4s 453us/step - loss: 3.1641 - acc: 0.3113\n",
      "Epoch 778/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.1584 - acc: 0.3085\n",
      "Epoch 779/1000\n",
      "9719/9719 [==============================] - 4s 437us/step - loss: 3.1634 - acc: 0.3084\n",
      "Epoch 780/1000\n",
      "9719/9719 [==============================] - 5s 470us/step - loss: 3.1717 - acc: 0.3080\n",
      "Epoch 781/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.1639 - acc: 0.3112\n",
      "Epoch 782/1000\n",
      "9719/9719 [==============================] - 5s 465us/step - loss: 3.1690 - acc: 0.3086\n",
      "Epoch 783/1000\n",
      "9719/9719 [==============================] - 4s 449us/step - loss: 3.1596 - acc: 0.3134\n",
      "Epoch 784/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 3.1720 - acc: 0.3069\n",
      "Epoch 785/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.1839 - acc: 0.3028\n",
      "Epoch 786/1000\n",
      "9719/9719 [==============================] - 5s 476us/step - loss: 3.1548 - acc: 0.3108\n",
      "Epoch 787/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.1529 - acc: 0.3111\n",
      "Epoch 788/1000\n",
      "9719/9719 [==============================] - 4s 459us/step - loss: 3.1542 - acc: 0.3145\n",
      "Epoch 789/1000\n",
      "9719/9719 [==============================] - 4s 451us/step - loss: 3.1714 - acc: 0.3086\n",
      "Epoch 790/1000\n",
      "9719/9719 [==============================] - 4s 439us/step - loss: 3.1767 - acc: 0.3113\n",
      "Epoch 791/1000\n",
      "9719/9719 [==============================] - 4s 447us/step - loss: 3.1638 - acc: 0.3133\n",
      "Epoch 792/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.1337 - acc: 0.3201\n",
      "Epoch 793/1000\n",
      "9719/9719 [==============================] - 5s 479us/step - loss: 3.1647 - acc: 0.3138\n",
      "Epoch 794/1000\n",
      "9719/9719 [==============================] - 4s 452us/step - loss: 3.1641 - acc: 0.3133\n",
      "Epoch 795/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 3.1626 - acc: 0.3077\n",
      "Epoch 796/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.1768 - acc: 0.3105\n",
      "Epoch 797/1000\n",
      "9719/9719 [==============================] - 4s 454us/step - loss: 3.1407 - acc: 0.3115\n",
      "Epoch 798/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.1808 - acc: 0.3100\n",
      "Epoch 799/1000\n",
      "9719/9719 [==============================] - 5s 474us/step - loss: 3.1571 - acc: 0.3103\n",
      "Epoch 800/1000\n",
      "9719/9719 [==============================] - 4s 457us/step - loss: 3.1687 - acc: 0.3130\n",
      "Epoch 801/1000\n",
      "9719/9719 [==============================] - 4s 434us/step - loss: 3.1464 - acc: 0.3108\n",
      "Epoch 802/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.1542 - acc: 0.3110\n",
      "Epoch 803/1000\n",
      "9719/9719 [==============================] - 5s 463us/step - loss: 3.1643 - acc: 0.3080\n",
      "Epoch 804/1000\n",
      "9719/9719 [==============================] - 5s 480us/step - loss: 3.1411 - acc: 0.3168\n",
      "Epoch 805/1000\n",
      "9719/9719 [==============================] - 5s 469us/step - loss: 3.1364 - acc: 0.3143\n",
      "Epoch 806/1000\n",
      "9719/9719 [==============================] - 4s 449us/step - loss: 3.1591 - acc: 0.3076\n",
      "Epoch 807/1000\n",
      "9719/9719 [==============================] - 4s 435us/step - loss: 3.1757 - acc: 0.3116\n",
      "Epoch 808/1000\n",
      "9719/9719 [==============================] - 4s 439us/step - loss: 3.1403 - acc: 0.3160\n",
      "Epoch 809/1000\n",
      "9719/9719 [==============================] - 4s 457us/step - loss: 3.1473 - acc: 0.3118\n",
      "Epoch 810/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 3.1663 - acc: 0.3105\n",
      "Epoch 811/1000\n",
      "9719/9719 [==============================] - 5s 470us/step - loss: 3.1410 - acc: 0.3138\n",
      "Epoch 812/1000\n",
      "9719/9719 [==============================] - 5s 476us/step - loss: 3.1702 - acc: 0.3101\n",
      "Epoch 813/1000\n",
      "9719/9719 [==============================] - 5s 468us/step - loss: 3.1501 - acc: 0.3115\n",
      "Epoch 814/1000\n",
      "9719/9719 [==============================] - 4s 452us/step - loss: 3.1567 - acc: 0.3113\n",
      "Epoch 815/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.1233 - acc: 0.3166\n",
      "Epoch 816/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.1324 - acc: 0.3151\n",
      "Epoch 817/1000\n",
      "9719/9719 [==============================] - 5s 473us/step - loss: 3.1797 - acc: 0.2994\n",
      "Epoch 818/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.1413 - acc: 0.3166\n",
      "Epoch 819/1000\n",
      "9719/9719 [==============================] - 5s 464us/step - loss: 3.1294 - acc: 0.3199\n",
      "Epoch 820/1000\n",
      "9719/9719 [==============================] - 4s 447us/step - loss: 3.1453 - acc: 0.3145\n",
      "Epoch 821/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.1471 - acc: 0.3129\n",
      "Epoch 822/1000\n",
      "9719/9719 [==============================] - 4s 434us/step - loss: 3.1579 - acc: 0.3080\n",
      "Epoch 823/1000\n",
      "9719/9719 [==============================] - 5s 475us/step - loss: 3.1222 - acc: 0.3232\n",
      "Epoch 824/1000\n",
      "9719/9719 [==============================] - 5s 476us/step - loss: 3.1787 - acc: 0.3026\n",
      "Epoch 825/1000\n",
      "9719/9719 [==============================] - 4s 459us/step - loss: 3.1274 - acc: 0.3216\n",
      "Epoch 826/1000\n",
      "9719/9719 [==============================] - 4s 446us/step - loss: 3.1700 - acc: 0.3085\n",
      "Epoch 827/1000\n",
      "9719/9719 [==============================] - 4s 439us/step - loss: 3.1541 - acc: 0.3107\n",
      "Epoch 828/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.1327 - acc: 0.3161\n",
      "Epoch 829/1000\n",
      "9719/9719 [==============================] - 5s 480us/step - loss: 3.1606 - acc: 0.3066\n",
      "Epoch 830/1000\n",
      "9719/9719 [==============================] - 5s 476us/step - loss: 3.1316 - acc: 0.3135\n",
      "Epoch 831/1000\n",
      "9719/9719 [==============================] - 4s 454us/step - loss: 3.1532 - acc: 0.3176\n",
      "Epoch 832/1000\n",
      "9719/9719 [==============================] - 4s 442us/step - loss: 3.1279 - acc: 0.3177\n",
      "Epoch 833/1000\n",
      "9719/9719 [==============================] - 4s 443us/step - loss: 3.1364 - acc: 0.3195\n",
      "Epoch 834/1000\n",
      "9719/9719 [==============================] - 4s 444us/step - loss: 3.1421 - acc: 0.3123\n",
      "Epoch 835/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 3.1570 - acc: 0.3111\n",
      "Epoch 836/1000\n",
      "9719/9719 [==============================] - 5s 463us/step - loss: 3.1437 - acc: 0.3124\n",
      "Epoch 837/1000\n",
      "9719/9719 [==============================] - 5s 475us/step - loss: 3.1335 - acc: 0.3172\n",
      "Epoch 838/1000\n",
      "9719/9719 [==============================] - 5s 477us/step - loss: 3.1303 - acc: 0.3182\n",
      "Epoch 839/1000\n",
      "9719/9719 [==============================] - 4s 463us/step - loss: 3.1342 - acc: 0.3211\n",
      "Epoch 840/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.1328 - acc: 0.3187\n",
      "Epoch 841/1000\n",
      "9719/9719 [==============================] - 4s 439us/step - loss: 3.1372 - acc: 0.3152\n",
      "Epoch 842/1000\n",
      "9719/9719 [==============================] - 4s 449us/step - loss: 3.1622 - acc: 0.3059\n",
      "Epoch 843/1000\n",
      "9719/9719 [==============================] - 5s 482us/step - loss: 3.1610 - acc: 0.3057\n",
      "Epoch 844/1000\n",
      "9719/9719 [==============================] - 5s 477us/step - loss: 3.1205 - acc: 0.3201\n",
      "Epoch 845/1000\n",
      "9719/9719 [==============================] - 4s 452us/step - loss: 3.1447 - acc: 0.3127\n",
      "Epoch 846/1000\n",
      "9719/9719 [==============================] - 4s 436us/step - loss: 3.1246 - acc: 0.3178\n",
      "Epoch 847/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 3.1306 - acc: 0.3130\n",
      "Epoch 848/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 3.1533 - acc: 0.3153\n",
      "Epoch 849/1000\n",
      "9719/9719 [==============================] - 5s 476us/step - loss: 3.1518 - acc: 0.3081\n",
      "Epoch 850/1000\n",
      "9719/9719 [==============================] - 5s 474us/step - loss: 3.1290 - acc: 0.3199\n",
      "Epoch 851/1000\n",
      "9719/9719 [==============================] - 4s 455us/step - loss: 3.1344 - acc: 0.3130\n",
      "Epoch 852/1000\n",
      "9719/9719 [==============================] - 4s 434us/step - loss: 3.1506 - acc: 0.3116\n",
      "Epoch 853/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 3.1473 - acc: 0.3121\n",
      "Epoch 854/1000\n",
      "9719/9719 [==============================] - 5s 465us/step - loss: 3.1099 - acc: 0.3172\n",
      "Epoch 855/1000\n",
      "9719/9719 [==============================] - 5s 480us/step - loss: 3.1371 - acc: 0.3158\n",
      "Epoch 856/1000\n",
      "9719/9719 [==============================] - 5s 470us/step - loss: 3.1320 - acc: 0.3081\n",
      "Epoch 857/1000\n",
      "9719/9719 [==============================] - 4s 456us/step - loss: 3.1451 - acc: 0.3116\n",
      "Epoch 858/1000\n",
      "9719/9719 [==============================] - 4s 437us/step - loss: 3.1140 - acc: 0.3189\n",
      "Epoch 859/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.1560 - acc: 0.3085\n",
      "Epoch 860/1000\n",
      "9719/9719 [==============================] - 5s 473us/step - loss: 3.1114 - acc: 0.3230\n",
      "Epoch 861/1000\n",
      "9719/9719 [==============================] - 5s 477us/step - loss: 3.1201 - acc: 0.3182\n",
      "Epoch 862/1000\n",
      "9719/9719 [==============================] - 5s 467us/step - loss: 3.1405 - acc: 0.3150\n",
      "Epoch 863/1000\n",
      "9719/9719 [==============================] - 4s 448us/step - loss: 3.1036 - acc: 0.3223\n",
      "Epoch 864/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9719/9719 [==============================] - 4s 442us/step - loss: 3.1504 - acc: 0.3100\n",
      "Epoch 865/1000\n",
      "9719/9719 [==============================] - 4s 437us/step - loss: 3.1314 - acc: 0.3085\n",
      "Epoch 866/1000\n",
      "9719/9719 [==============================] - 5s 480us/step - loss: 3.1239 - acc: 0.3169\n",
      "Epoch 867/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.1274 - acc: 0.3180\n",
      "Epoch 868/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 3.1318 - acc: 0.3159\n",
      "Epoch 869/1000\n",
      "9719/9719 [==============================] - 4s 447us/step - loss: 3.1224 - acc: 0.3155\n",
      "Epoch 870/1000\n",
      "9719/9719 [==============================] - 4s 449us/step - loss: 3.1295 - acc: 0.3146\n",
      "Epoch 871/1000\n",
      "9719/9719 [==============================] - 4s 447us/step - loss: 3.1056 - acc: 0.3250\n",
      "Epoch 872/1000\n",
      "9719/9719 [==============================] - 5s 481us/step - loss: 3.1271 - acc: 0.3167\n",
      "Epoch 873/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.1313 - acc: 0.3111\n",
      "Epoch 874/1000\n",
      "9719/9719 [==============================] - 4s 457us/step - loss: 3.1415 - acc: 0.3103\n",
      "Epoch 875/1000\n",
      "9719/9719 [==============================] - 4s 442us/step - loss: 3.1030 - acc: 0.3226\n",
      "Epoch 876/1000\n",
      "9719/9719 [==============================] - 4s 443us/step - loss: 3.1158 - acc: 0.3213\n",
      "Epoch 877/1000\n",
      "9719/9719 [==============================] - 4s 455us/step - loss: 3.1124 - acc: 0.3198\n",
      "Epoch 878/1000\n",
      "9719/9719 [==============================] - 5s 482us/step - loss: 3.1147 - acc: 0.3195\n",
      "Epoch 879/1000\n",
      "9719/9719 [==============================] - 5s 476us/step - loss: 3.0985 - acc: 0.3227\n",
      "Epoch 880/1000\n",
      "9719/9719 [==============================] - 4s 453us/step - loss: 3.1288 - acc: 0.3169\n",
      "Epoch 881/1000\n",
      "9719/9719 [==============================] - 4s 433us/step - loss: 3.1200 - acc: 0.3191\n",
      "Epoch 882/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.1372 - acc: 0.3110\n",
      "Epoch 883/1000\n",
      "9719/9719 [==============================] - 5s 463us/step - loss: 3.1200 - acc: 0.3213\n",
      "Epoch 884/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.1061 - acc: 0.3186\n",
      "Epoch 885/1000\n",
      "9719/9719 [==============================] - 5s 470us/step - loss: 3.1302 - acc: 0.3166\n",
      "Epoch 886/1000\n",
      "9719/9719 [==============================] - 4s 449us/step - loss: 3.1295 - acc: 0.3178\n",
      "Epoch 887/1000\n",
      "9719/9719 [==============================] - 4s 435us/step - loss: 3.1029 - acc: 0.3184\n",
      "Epoch 888/1000\n",
      "9719/9719 [==============================] - 4s 436us/step - loss: 3.1124 - acc: 0.3140\n",
      "Epoch 889/1000\n",
      "9719/9719 [==============================] - 5s 474us/step - loss: 3.1439 - acc: 0.3126\n",
      "Epoch 890/1000\n",
      "9719/9719 [==============================] - 5s 480us/step - loss: 3.1177 - acc: 0.3252\n",
      "Epoch 891/1000\n",
      "9719/9719 [==============================] - 5s 465us/step - loss: 3.0964 - acc: 0.3224\n",
      "Epoch 892/1000\n",
      "9719/9719 [==============================] - 4s 447us/step - loss: 3.1125 - acc: 0.3239\n",
      "Epoch 893/1000\n",
      "9719/9719 [==============================] - 4s 437us/step - loss: 3.1361 - acc: 0.3107\n",
      "Epoch 894/1000\n",
      "9719/9719 [==============================] - 4s 437us/step - loss: 3.1026 - acc: 0.3205\n",
      "Epoch 895/1000\n",
      "9719/9719 [==============================] - 4s 459us/step - loss: 3.1119 - acc: 0.3211\n",
      "Epoch 896/1000\n",
      "9719/9719 [==============================] - 4s 459us/step - loss: 3.1259 - acc: 0.3156\n",
      "Epoch 897/1000\n",
      "9719/9719 [==============================] - 5s 479us/step - loss: 3.1010 - acc: 0.3187\n",
      "Epoch 898/1000\n",
      "9719/9719 [==============================] - 5s 477us/step - loss: 3.1307 - acc: 0.3151\n",
      "Epoch 899/1000\n",
      "9719/9719 [==============================] - 5s 466us/step - loss: 3.1217 - acc: 0.3174\n",
      "Epoch 900/1000\n",
      "9719/9719 [==============================] - 4s 447us/step - loss: 3.1362 - acc: 0.3197\n",
      "Epoch 901/1000\n",
      "9719/9719 [==============================] - 4s 437us/step - loss: 3.1193 - acc: 0.3166\n",
      "Epoch 902/1000\n",
      "9719/9719 [==============================] - 4s 437us/step - loss: 3.1178 - acc: 0.3205\n",
      "Epoch 903/1000\n",
      "9719/9719 [==============================] - 5s 474us/step - loss: 3.0716 - acc: 0.3290\n",
      "Epoch 904/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.1256 - acc: 0.3117\n",
      "Epoch 905/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 3.1122 - acc: 0.3133\n",
      "Epoch 906/1000\n",
      "9719/9719 [==============================] - 4s 443us/step - loss: 3.1191 - acc: 0.3178\n",
      "Epoch 907/1000\n",
      "9719/9719 [==============================] - 4s 443us/step - loss: 3.1275 - acc: 0.3164\n",
      "Epoch 908/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.1063 - acc: 0.3159\n",
      "Epoch 909/1000\n",
      "9719/9719 [==============================] - 5s 477us/step - loss: 3.1011 - acc: 0.3242\n",
      "Epoch 910/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.1166 - acc: 0.3156\n",
      "Epoch 911/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 3.0736 - acc: 0.3240\n",
      "Epoch 912/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 3.1327 - acc: 0.3153\n",
      "Epoch 913/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 3.1087 - acc: 0.3166\n",
      "Epoch 914/1000\n",
      "9719/9719 [==============================] - 4s 451us/step - loss: 3.1034 - acc: 0.3259\n",
      "Epoch 915/1000\n",
      "9719/9719 [==============================] - 5s 476us/step - loss: 3.1344 - acc: 0.3118\n",
      "Epoch 916/1000\n",
      "9719/9719 [==============================] - 5s 476us/step - loss: 3.0901 - acc: 0.3289\n",
      "Epoch 917/1000\n",
      "9719/9719 [==============================] - 4s 451us/step - loss: 3.1328 - acc: 0.3210\n",
      "Epoch 918/1000\n",
      "9719/9719 [==============================] - 4s 435us/step - loss: 3.0851 - acc: 0.3295\n",
      "Epoch 919/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.0842 - acc: 0.3252\n",
      "Epoch 920/1000\n",
      "9719/9719 [==============================] - 4s 457us/step - loss: 3.1192 - acc: 0.3166\n",
      "Epoch 921/1000\n",
      "9719/9719 [==============================] - 5s 476us/step - loss: 3.0995 - acc: 0.3229\n",
      "Epoch 922/1000\n",
      "9719/9719 [==============================] - 5s 473us/step - loss: 3.0970 - acc: 0.3190\n",
      "Epoch 923/1000\n",
      "9719/9719 [==============================] - 4s 452us/step - loss: 3.1071 - acc: 0.3216\n",
      "Epoch 924/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 3.1159 - acc: 0.3208\n",
      "Epoch 925/1000\n",
      "9719/9719 [==============================] - 4s 439us/step - loss: 3.1123 - acc: 0.3179\n",
      "Epoch 926/1000\n",
      "9719/9719 [==============================] - 5s 468us/step - loss: 3.0829 - acc: 0.3294\n",
      "Epoch 927/1000\n",
      "9719/9719 [==============================] - 5s 476us/step - loss: 3.1131 - acc: 0.3239\n",
      "Epoch 928/1000\n",
      "9719/9719 [==============================] - 5s 468us/step - loss: 3.0992 - acc: 0.3225\n",
      "Epoch 929/1000\n",
      "9719/9719 [==============================] - 4s 449us/step - loss: 3.0921 - acc: 0.3244\n",
      "Epoch 930/1000\n",
      "9719/9719 [==============================] - 4s 437us/step - loss: 3.1061 - acc: 0.3233\n",
      "Epoch 931/1000\n",
      "9719/9719 [==============================] - 4s 437us/step - loss: 3.1128 - acc: 0.3195\n",
      "Epoch 932/1000\n",
      "9719/9719 [==============================] - 5s 473us/step - loss: 3.1039 - acc: 0.3219\n",
      "Epoch 933/1000\n",
      "9719/9719 [==============================] - 5s 477us/step - loss: 3.0917 - acc: 0.3281\n",
      "Epoch 934/1000\n",
      "9719/9719 [==============================] - 5s 465us/step - loss: 3.1067 - acc: 0.3209\n",
      "Epoch 935/1000\n",
      "9719/9719 [==============================] - 4s 447us/step - loss: 3.0850 - acc: 0.3271\n",
      "Epoch 936/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 3.0921 - acc: 0.3186\n",
      "Epoch 937/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 3.1023 - acc: 0.3197\n",
      "Epoch 938/1000\n",
      "9719/9719 [==============================] - 5s 480us/step - loss: 3.0992 - acc: 0.3228\n",
      "Epoch 939/1000\n",
      "9719/9719 [==============================] - 5s 482us/step - loss: 3.1052 - acc: 0.3219\n",
      "Epoch 940/1000\n",
      "9719/9719 [==============================] - 4s 459us/step - loss: 3.1204 - acc: 0.3112\n",
      "Epoch 941/1000\n",
      "9719/9719 [==============================] - 4s 445us/step - loss: 3.0891 - acc: 0.3241\n",
      "Epoch 942/1000\n",
      "9719/9719 [==============================] - 4s 440us/step - loss: 3.0965 - acc: 0.3254\n",
      "Epoch 943/1000\n",
      "9719/9719 [==============================] - 4s 445us/step - loss: 3.0975 - acc: 0.3263\n",
      "Epoch 944/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.0871 - acc: 0.3279\n",
      "Epoch 945/1000\n",
      "9719/9719 [==============================] - 5s 477us/step - loss: 3.1022 - acc: 0.3252\n",
      "Epoch 946/1000\n",
      "9719/9719 [==============================] - 4s 456us/step - loss: 3.1058 - acc: 0.3189\n",
      "Epoch 947/1000\n",
      "9719/9719 [==============================] - 4s 442us/step - loss: 3.0881 - acc: 0.3216\n",
      "Epoch 948/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.1134 - acc: 0.3206\n",
      "Epoch 949/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 3.0830 - acc: 0.3278\n",
      "Epoch 950/1000\n",
      "9719/9719 [==============================] - 5s 479us/step - loss: 3.1104 - acc: 0.3210\n",
      "Epoch 951/1000\n",
      "9719/9719 [==============================] - 5s 495us/step - loss: 3.0909 - acc: 0.3232\n",
      "Epoch 952/1000\n",
      "9719/9719 [==============================] - 4s 453us/step - loss: 3.0980 - acc: 0.3218\n",
      "Epoch 953/1000\n",
      "9719/9719 [==============================] - 4s 436us/step - loss: 3.1063 - acc: 0.3246\n",
      "Epoch 954/1000\n",
      "9719/9719 [==============================] - 4s 445us/step - loss: 3.0828 - acc: 0.3215\n",
      "Epoch 955/1000\n",
      "9719/9719 [==============================] - 5s 469us/step - loss: 3.1123 - acc: 0.3240\n",
      "Epoch 956/1000\n",
      "9719/9719 [==============================] - 5s 479us/step - loss: 3.0630 - acc: 0.3309\n",
      "Epoch 957/1000\n",
      "9719/9719 [==============================] - 5s 475us/step - loss: 3.0915 - acc: 0.3226\n",
      "Epoch 958/1000\n",
      "9719/9719 [==============================] - 4s 450us/step - loss: 3.1019 - acc: 0.3183\n",
      "Epoch 959/1000\n",
      "9719/9719 [==============================] - 4s 437us/step - loss: 3.0827 - acc: 0.3243\n",
      "Epoch 960/1000\n",
      "9719/9719 [==============================] - 4s 437us/step - loss: 3.0726 - acc: 0.3316\n",
      "Epoch 961/1000\n",
      "9719/9719 [==============================] - 5s 479us/step - loss: 3.1155 - acc: 0.3220\n",
      "Epoch 962/1000\n",
      "9719/9719 [==============================] - 5s 478us/step - loss: 3.0883 - acc: 0.3212\n",
      "Epoch 963/1000\n",
      "9719/9719 [==============================] - 5s 464us/step - loss: 3.1001 - acc: 0.3228\n",
      "Epoch 964/1000\n",
      "9719/9719 [==============================] - 4s 447us/step - loss: 3.0588 - acc: 0.3271\n",
      "Epoch 965/1000\n",
      "9719/9719 [==============================] - 4s 446us/step - loss: 3.1125 - acc: 0.3176\n",
      "Epoch 966/1000\n",
      "9719/9719 [==============================] - 4s 437us/step - loss: 3.0914 - acc: 0.3231\n",
      "Epoch 967/1000\n",
      "9719/9719 [==============================] - 5s 480us/step - loss: 3.0925 - acc: 0.3253\n",
      "Epoch 968/1000\n",
      "9719/9719 [==============================] - 5s 487us/step - loss: 3.0678 - acc: 0.3255\n",
      "Epoch 969/1000\n",
      "9719/9719 [==============================] - 4s 462us/step - loss: 3.0915 - acc: 0.3252\n",
      "Epoch 970/1000\n",
      "9719/9719 [==============================] - 4s 457us/step - loss: 3.0857 - acc: 0.3239\n",
      "Epoch 971/1000\n",
      "9719/9719 [==============================] - 4s 461us/step - loss: 3.1048 - acc: 0.3189\n",
      "Epoch 972/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 3.0883 - acc: 0.3251\n",
      "Epoch 973/1000\n",
      "9719/9719 [==============================] - 5s 466us/step - loss: 3.0839 - acc: 0.3263\n",
      "Epoch 974/1000\n",
      "9719/9719 [==============================] - 5s 476us/step - loss: 3.1028 - acc: 0.3234\n",
      "Epoch 975/1000\n",
      "9719/9719 [==============================] - 5s 473us/step - loss: 3.0726 - acc: 0.3310\n",
      "Epoch 976/1000\n",
      "9719/9719 [==============================] - 4s 452us/step - loss: 3.0767 - acc: 0.3275\n",
      "Epoch 977/1000\n",
      "9719/9719 [==============================] - 4s 436us/step - loss: 3.0838 - acc: 0.3204\n",
      "Epoch 978/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.0828 - acc: 0.3284\n",
      "Epoch 979/1000\n",
      "9719/9719 [==============================] - 4s 461us/step - loss: 3.0862 - acc: 0.3202\n",
      "Epoch 980/1000\n",
      "9719/9719 [==============================] - 5s 475us/step - loss: 3.1022 - acc: 0.3242\n",
      "Epoch 981/1000\n",
      "9719/9719 [==============================] - 5s 472us/step - loss: 3.0814 - acc: 0.3241\n",
      "Epoch 982/1000\n",
      "9719/9719 [==============================] - 4s 449us/step - loss: 3.0704 - acc: 0.3301\n",
      "Epoch 983/1000\n",
      "9719/9719 [==============================] - 4s 434us/step - loss: 3.0864 - acc: 0.3198\n",
      "Epoch 984/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.0995 - acc: 0.3247\n",
      "Epoch 985/1000\n",
      "9719/9719 [==============================] - 4s 456us/step - loss: 3.0480 - acc: 0.3323\n",
      "Epoch 986/1000\n",
      "9719/9719 [==============================] - 4s 457us/step - loss: 3.0677 - acc: 0.3305\n",
      "Epoch 987/1000\n",
      "9719/9719 [==============================] - 4s 460us/step - loss: 3.0970 - acc: 0.3226\n",
      "Epoch 988/1000\n",
      "9719/9719 [==============================] - 4s 457us/step - loss: 3.0861 - acc: 0.3274\n",
      "Epoch 989/1000\n",
      "9719/9719 [==============================] - 5s 463us/step - loss: 3.0607 - acc: 0.3311\n",
      "Epoch 990/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 3.0841 - acc: 0.3246\n",
      "Epoch 991/1000\n",
      "9719/9719 [==============================] - 4s 458us/step - loss: 3.0650 - acc: 0.3302\n",
      "Epoch 992/1000\n",
      "9719/9719 [==============================] - 5s 473us/step - loss: 3.0844 - acc: 0.3212\n",
      "Epoch 993/1000\n",
      "9719/9719 [==============================] - 5s 475us/step - loss: 3.0631 - acc: 0.3340\n",
      "Epoch 994/1000\n",
      "9719/9719 [==============================] - 4s 462us/step - loss: 3.1015 - acc: 0.3217\n",
      "Epoch 995/1000\n",
      "9719/9719 [==============================] - 4s 441us/step - loss: 3.0488 - acc: 0.3328\n",
      "Epoch 996/1000\n",
      "9719/9719 [==============================] - 4s 438us/step - loss: 3.0861 - acc: 0.3290\n",
      "Epoch 997/1000\n",
      "9719/9719 [==============================] - 4s 444us/step - loss: 3.0951 - acc: 0.3235\n",
      "Epoch 998/1000\n",
      "9719/9719 [==============================] - 5s 476us/step - loss: 3.0497 - acc: 0.3289\n",
      "Epoch 999/1000\n",
      "9719/9719 [==============================] - 5s 477us/step - loss: 3.0918 - acc: 0.3216\n",
      "Epoch 1000/1000\n",
      "9719/9719 [==============================] - 4s 456us/step - loss: 3.0687 - acc: 0.3312\n",
      "Accuracy: 5.678885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2(X_train_new, y_train, X_test_new, y_test,256,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch ', 1, ' out of ', 100, '- loss:', 378949849.5)\n",
      "('Epoch ', 2, ' out of ', 100, '- loss:', 147761707.0)\n",
      "('Epoch ', 3, ' out of ', 100, '- loss:', 73142033.0)\n",
      "('Epoch ', 4, ' out of ', 100, '- loss:', 25956969.90625)\n",
      "('Epoch ', 5, ' out of ', 100, '- loss:', 4834577.47265625)\n",
      "('Epoch ', 6, ' out of ', 100, '- loss:', 969778.787109375)\n",
      "('Epoch ', 7, ' out of ', 100, '- loss:', 411937.79150390625)\n",
      "('Epoch ', 8, ' out of ', 100, '- loss:', 233341.42724609375)\n",
      "('Epoch ', 9, ' out of ', 100, '- loss:', 150442.95275878906)\n",
      "('Epoch ', 10, ' out of ', 100, '- loss:', 105173.48291015625)\n",
      "('Epoch ', 11, ' out of ', 100, '- loss:', 76847.17349243164)\n",
      "('Epoch ', 12, ' out of ', 100, '- loss:', 57685.50369262695)\n",
      "('Epoch ', 13, ' out of ', 100, '- loss:', 44328.76791572571)\n",
      "('Epoch ', 14, ' out of ', 100, '- loss:', 34569.251779556274)\n",
      "('Epoch ', 15, ' out of ', 100, '- loss:', 27380.43602848053)\n",
      "('Epoch ', 16, ' out of ', 100, '- loss:', 21639.78512954712)\n",
      "('Epoch ', 17, ' out of ', 100, '- loss:', 16692.09047603607)\n",
      "('Epoch ', 18, ' out of ', 100, '- loss:', 13114.024879455566)\n",
      "('Epoch ', 19, ' out of ', 100, '- loss:', 10535.813174247742)\n",
      "('Epoch ', 20, ' out of ', 100, '- loss:', 8335.369918823242)\n",
      "('Epoch ', 21, ' out of ', 100, '- loss:', 6661.841809272766)\n",
      "('Epoch ', 22, ' out of ', 100, '- loss:', 5385.9132442474365)\n",
      "('Epoch ', 23, ' out of ', 100, '- loss:', 4449.645170211792)\n",
      "('Epoch ', 24, ' out of ', 100, '- loss:', 3687.901940345764)\n",
      "('Epoch ', 25, ' out of ', 100, '- loss:', 3120.416687965393)\n",
      "('Epoch ', 26, ' out of ', 100, '- loss:', 2584.085214614868)\n",
      "('Epoch ', 27, ' out of ', 100, '- loss:', 2174.8354387283325)\n",
      "('Epoch ', 28, ' out of ', 100, '- loss:', 1861.2361936569214)\n",
      "('Epoch ', 29, ' out of ', 100, '- loss:', 1564.548261642456)\n",
      "('Epoch ', 30, ' out of ', 100, '- loss:', 1372.6509370803833)\n",
      "('Epoch ', 31, ' out of ', 100, '- loss:', 1202.5860013961792)\n",
      "('Epoch ', 32, ' out of ', 100, '- loss:', 1070.9335231781006)\n",
      "('Epoch ', 33, ' out of ', 100, '- loss:', 951.0244007110596)\n",
      "('Epoch ', 34, ' out of ', 100, '- loss:', 839.8821611404419)\n",
      "('Epoch ', 35, ' out of ', 100, '- loss:', 755.3788747787476)\n",
      "('Epoch ', 36, ' out of ', 100, '- loss:', 621.1909837722778)\n",
      "('Epoch ', 37, ' out of ', 100, '- loss:', 613.1668796539307)\n",
      "('Epoch ', 38, ' out of ', 100, '- loss:', 533.3494386672974)\n",
      "('Epoch ', 39, ' out of ', 100, '- loss:', 473.3224287033081)\n",
      "('Epoch ', 40, ' out of ', 100, '- loss:', 462.58507442474365)\n",
      "('Epoch ', 41, ' out of ', 100, '- loss:', 408.37848472595215)\n",
      "('Epoch ', 42, ' out of ', 100, '- loss:', 393.5262403488159)\n",
      "('Epoch ', 43, ' out of ', 100, '- loss:', 381.89051628112793)\n",
      "('Epoch ', 44, ' out of ', 100, '- loss:', 368.70708179473877)\n",
      "('Epoch ', 45, ' out of ', 100, '- loss:', 367.99433517456055)\n",
      "('Epoch ', 46, ' out of ', 100, '- loss:', 352.1091480255127)\n",
      "('Epoch ', 47, ' out of ', 100, '- loss:', 353.81989002227783)\n",
      "('Epoch ', 48, ' out of ', 100, '- loss:', 345.34192943573)\n",
      "('Epoch ', 49, ' out of ', 100, '- loss:', 344.07863426208496)\n",
      "('Epoch ', 50, ' out of ', 100, '- loss:', 340.21982765197754)\n",
      "('Epoch ', 51, ' out of ', 100, '- loss:', 339.3265314102173)\n",
      "('Epoch ', 52, ' out of ', 100, '- loss:', 338.51661014556885)\n",
      "('Epoch ', 53, ' out of ', 100, '- loss:', 337.75414752960205)\n",
      "('Epoch ', 54, ' out of ', 100, '- loss:', 336.999662399292)\n",
      "('Epoch ', 55, ' out of ', 100, '- loss:', 336.2532272338867)\n",
      "('Epoch ', 56, ' out of ', 100, '- loss:', 335.51481437683105)\n",
      "('Epoch ', 57, ' out of ', 100, '- loss:', 334.78446865081787)\n",
      "('Epoch ', 58, ' out of ', 100, '- loss:', 334.0621919631958)\n",
      "('Epoch ', 59, ' out of ', 100, '- loss:', 333.3480052947998)\n",
      "('Epoch ', 60, ' out of ', 100, '- loss:', 332.64192962646484)\n",
      "('Epoch ', 61, ' out of ', 100, '- loss:', 331.9439449310303)\n",
      "('Epoch ', 62, ' out of ', 100, '- loss:', 331.25408267974854)\n",
      "('Epoch ', 63, ' out of ', 100, '- loss:', 330.57232093811035)\n",
      "('Epoch ', 64, ' out of ', 100, '- loss:', 329.8986873626709)\n",
      "('Epoch ', 65, ' out of ', 100, '- loss:', 329.23314476013184)\n",
      "('Epoch ', 66, ' out of ', 100, '- loss:', 328.57570457458496)\n",
      "('Epoch ', 67, ' out of ', 100, '- loss:', 327.9263553619385)\n",
      "('Epoch ', 68, ' out of ', 100, '- loss:', 327.28508281707764)\n",
      "('Epoch ', 69, ' out of ', 100, '- loss:', 326.651873588562)\n",
      "('Epoch ', 70, ' out of ', 100, '- loss:', 326.02670097351074)\n",
      "('Epoch ', 71, ' out of ', 100, '- loss:', 325.4095449447632)\n",
      "('Epoch ', 72, ' out of ', 100, '- loss:', 324.8003759384155)\n",
      "('Epoch ', 73, ' out of ', 100, '- loss:', 324.1991949081421)\n",
      "('Epoch ', 74, ' out of ', 100, '- loss:', 323.60593605041504)\n",
      "('Epoch ', 75, ' out of ', 100, '- loss:', 323.02058506011963)\n",
      "('Epoch ', 76, ' out of ', 100, '- loss:', 322.44310092926025)\n",
      "('Epoch ', 77, ' out of ', 100, '- loss:', 321.8734531402588)\n",
      "('Epoch ', 78, ' out of ', 100, '- loss:', 321.311598777771)\n",
      "('Epoch ', 79, ' out of ', 100, '- loss:', 320.7574853897095)\n",
      "('Epoch ', 80, ' out of ', 100, '- loss:', 320.2110710144043)\n",
      "('Epoch ', 81, ' out of ', 100, '- loss:', 319.6723232269287)\n",
      "('Epoch ', 82, ' out of ', 100, '- loss:', 319.1411714553833)\n",
      "('Epoch ', 83, ' out of ', 100, '- loss:', 318.6175889968872)\n",
      "('Epoch ', 84, ' out of ', 100, '- loss:', 318.10150241851807)\n",
      "('Epoch ', 85, ' out of ', 100, '- loss:', 317.5928602218628)\n",
      "('Epoch ', 86, ' out of ', 100, '- loss:', 317.09161376953125)\n",
      "('Epoch ', 87, ' out of ', 100, '- loss:', 316.5976972579956)\n",
      "('Epoch ', 88, ' out of ', 100, '- loss:', 316.111047744751)\n",
      "('Epoch ', 89, ' out of ', 100, '- loss:', 315.6316204071045)\n",
      "('Epoch ', 90, ' out of ', 100, '- loss:', 315.15932750701904)\n",
      "('Epoch ', 91, ' out of ', 100, '- loss:', 314.6941261291504)\n",
      "('Epoch ', 92, ' out of ', 100, '- loss:', 314.23593616485596)\n",
      "('Epoch ', 93, ' out of ', 100, '- loss:', 313.78469371795654)\n",
      "('Epoch ', 94, ' out of ', 100, '- loss:', 313.34034061431885)\n",
      "('Epoch ', 95, ' out of ', 100, '- loss:', 312.9028034210205)\n",
      "('Epoch ', 96, ' out of ', 100, '- loss:', 312.4720001220703)\n",
      "('Epoch ', 97, ' out of ', 100, '- loss:', 312.0478801727295)\n",
      "('Epoch ', 98, ' out of ', 100, '- loss:', 311.6303462982178)\n",
      "('Epoch ', 99, ' out of ', 100, '- loss:', 311.2193536758423)\n",
      "('Epoch ', 100, ' out of ', 100, '- loss:', 310.8148145675659)\n",
      "('\\nAccuracy:', 0.05162622546777129)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3(X_train_new, y_train, X_test_new, y_test,256,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 1000, 75)          30600     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 75)                45300     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 15999)             1215924   \n",
      "=================================================================\n",
      "Total params: 1,291,824\n",
      "Trainable params: 1,291,824\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "9719/9719 [==============================] - 116s 12ms/step - loss: 8.8293 - acc: 4.1156e-04\n",
      "Epoch 2/10\n",
      "9719/9719 [==============================] - 109s 11ms/step - loss: 7.8406 - acc: 2.0578e-04\n",
      "Epoch 3/10\n",
      "9719/9719 [==============================] - 109s 11ms/step - loss: 7.6903 - acc: 2.0578e-04\n",
      "Epoch 4/10\n",
      "9719/9719 [==============================] - 110s 11ms/step - loss: 7.6554 - acc: 2.0578e-04\n",
      "Epoch 5/10\n",
      "9719/9719 [==============================] - 110s 11ms/step - loss: 7.6334 - acc: 1.0289e-04\n",
      "Epoch 6/10\n",
      "9719/9719 [==============================] - 109s 11ms/step - loss: 7.6215 - acc: 1.0289e-04\n",
      "Epoch 7/10\n",
      "9719/9719 [==============================] - 110s 11ms/step - loss: 7.6147 - acc: 3.0867e-04\n",
      "Epoch 8/10\n",
      "9719/9719 [==============================] - 110s 11ms/step - loss: 7.5996 - acc: 3.0867e-04\n",
      "Epoch 9/10\n",
      "9719/9719 [==============================] - 109s 11ms/step - loss: 7.5834 - acc: 4.1156e-04\n",
      "Epoch 10/10\n",
      "9719/9719 [==============================] - 109s 11ms/step - loss: 7.5282 - acc: 6.1735e-04\n",
      "Accuracy: 0.103252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4(X_train_new, y_train, X_test_new, y_test,256,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 1000)        26000     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, None, 75)          322800    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 75)                45300     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 15999)             1215924   \n",
      "=================================================================\n",
      "Total params: 1,610,024\n",
      "Trainable params: 1,610,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "9719/9719 [==============================] - 407s 42ms/step - loss: 8.8400 - acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "9719/9719 [==============================] - 407s 42ms/step - loss: 7.8420 - acc: 2.0578e-04\n",
      "Epoch 3/50\n",
      "9719/9719 [==============================] - 406s 42ms/step - loss: 7.6900 - acc: 5.1446e-04\n",
      "Epoch 4/50\n",
      "9719/9719 [==============================] - 409s 42ms/step - loss: 7.6542 - acc: 1.0289e-04\n",
      "Epoch 5/50\n",
      "9719/9719 [==============================] - 408s 42ms/step - loss: 7.6324 - acc: 6.1735e-04\n",
      "Epoch 6/50\n",
      "9719/9719 [==============================] - 408s 42ms/step - loss: 7.6194 - acc: 4.1156e-04\n",
      "Epoch 7/50\n",
      "9719/9719 [==============================] - 409s 42ms/step - loss: 7.5962 - acc: 4.1156e-04\n",
      "Epoch 8/50\n",
      "9719/9719 [==============================] - 407s 42ms/step - loss: 7.5394 - acc: 8.2313e-04\n",
      "Epoch 9/50\n",
      "9719/9719 [==============================] - 409s 42ms/step - loss: 7.4534 - acc: 7.2024e-04\n",
      "Epoch 10/50\n",
      "9719/9719 [==============================] - 410s 42ms/step - loss: 7.3379 - acc: 9.2602e-04\n",
      "Epoch 11/50\n",
      "9719/9719 [==============================] - 410s 42ms/step - loss: 7.2013 - acc: 0.0010\n",
      "Epoch 12/50\n",
      "9719/9719 [==============================] - 412s 42ms/step - loss: 7.0799 - acc: 0.0010\n",
      "Epoch 13/50\n",
      "9719/9719 [==============================] - 411s 42ms/step - loss: 6.9741 - acc: 0.0025\n",
      "Epoch 14/50\n",
      "9719/9719 [==============================] - 413s 42ms/step - loss: 6.8949 - acc: 0.0027\n",
      "Epoch 15/50\n",
      "9719/9719 [==============================] - 409s 42ms/step - loss: 6.8040 - acc: 0.0022\n",
      "Epoch 16/50\n",
      "9719/9719 [==============================] - 411s 42ms/step - loss: 6.7260 - acc: 0.0025\n",
      "Epoch 17/50\n",
      "9719/9719 [==============================] - 411s 42ms/step - loss: 6.6742 - acc: 0.0029\n",
      "Epoch 18/50\n",
      "9719/9719 [==============================] - 412s 42ms/step - loss: 6.5800 - acc: 0.0029\n",
      "Epoch 19/50\n",
      "9719/9719 [==============================] - 412s 42ms/step - loss: 6.5240 - acc: 0.0041\n",
      "Epoch 20/50\n",
      "9719/9719 [==============================] - 412s 42ms/step - loss: 6.4864 - acc: 0.0054\n",
      "Epoch 21/50\n",
      "9719/9719 [==============================] - 411s 42ms/step - loss: 6.4179 - acc: 0.0043\n",
      "Epoch 22/50\n",
      "9719/9719 [==============================] - 414s 43ms/step - loss: 6.3782 - acc: 0.0068\n",
      "Epoch 23/50\n",
      "9719/9719 [==============================] - 413s 42ms/step - loss: 6.3238 - acc: 0.0051\n",
      "Epoch 24/50\n",
      "9719/9719 [==============================] - 413s 43ms/step - loss: 6.2891 - acc: 0.0042\n",
      "Epoch 25/50\n",
      "9719/9719 [==============================] - 414s 43ms/step - loss: 6.2643 - acc: 0.0050\n",
      "Epoch 26/50\n",
      "9719/9719 [==============================] - 414s 43ms/step - loss: 6.2359 - acc: 0.0048\n",
      "Epoch 27/50\n",
      "9719/9719 [==============================] - 412s 42ms/step - loss: 6.2091 - acc: 0.0042\n",
      "Epoch 28/50\n",
      "9719/9719 [==============================] - 415s 43ms/step - loss: 6.1761 - acc: 0.0054\n",
      "Epoch 29/50\n",
      "9719/9719 [==============================] - 414s 43ms/step - loss: 6.1610 - acc: 0.0065\n",
      "Epoch 30/50\n",
      "9719/9719 [==============================] - 414s 43ms/step - loss: 6.1277 - acc: 0.0067\n",
      "Epoch 31/50\n",
      "9719/9719 [==============================] - 415s 43ms/step - loss: 6.0961 - acc: 0.0063\n",
      "Epoch 32/50\n",
      "9719/9719 [==============================] - 415s 43ms/step - loss: 6.0738 - acc: 0.0074\n",
      "Epoch 33/50\n",
      "9719/9719 [==============================] - 415s 43ms/step - loss: 6.0621 - acc: 0.0060\n",
      "Epoch 34/50\n",
      "9719/9719 [==============================] - 415s 43ms/step - loss: 6.0305 - acc: 0.0087\n",
      "Epoch 35/50\n",
      "9719/9719 [==============================] - 417s 43ms/step - loss: 6.0011 - acc: 0.0072\n",
      "Epoch 36/50\n",
      "9719/9719 [==============================] - 414s 43ms/step - loss: 5.9661 - acc: 0.0073\n",
      "Epoch 37/50\n",
      "9719/9719 [==============================] - 415s 43ms/step - loss: 5.9435 - acc: 0.0081\n",
      "Epoch 38/50\n",
      "9719/9719 [==============================] - 415s 43ms/step - loss: 5.9305 - acc: 0.0095\n",
      "Epoch 39/50\n",
      "9719/9719 [==============================] - 417s 43ms/step - loss: 5.9077 - acc: 0.0098\n",
      "Epoch 40/50\n",
      "9719/9719 [==============================] - 415s 43ms/step - loss: 5.9053 - acc: 0.0090\n",
      "Epoch 41/50\n",
      "9719/9719 [==============================] - 414s 43ms/step - loss: 5.8901 - acc: 0.0078\n",
      "Epoch 42/50\n",
      "9719/9719 [==============================] - 415s 43ms/step - loss: 5.8534 - acc: 0.0098\n",
      "Epoch 43/50\n",
      "9719/9719 [==============================] - 416s 43ms/step - loss: 5.8557 - acc: 0.0097\n",
      "Epoch 44/50\n",
      "9719/9719 [==============================] - 415s 43ms/step - loss: 5.8255 - acc: 0.0106\n",
      "Epoch 45/50\n",
      "9719/9719 [==============================] - 416s 43ms/step - loss: 5.8107 - acc: 0.0103\n",
      "Epoch 46/50\n",
      "9719/9719 [==============================] - 416s 43ms/step - loss: 5.7883 - acc: 0.0127\n",
      "Epoch 47/50\n",
      "9719/9719 [==============================] - 416s 43ms/step - loss: 5.7822 - acc: 0.0113\n",
      "Epoch 48/50\n",
      "9719/9719 [==============================] - 416s 43ms/step - loss: 5.7664 - acc: 0.0129\n",
      "Epoch 49/50\n",
      "9719/9719 [==============================] - 416s 43ms/step - loss: 5.7490 - acc: 0.0128\n",
      "Epoch 50/50\n",
      "9719/9719 [==============================] - 416s 43ms/step - loss: 5.7442 - acc: 0.0138\n",
      "Accuracy: 1.187403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5(X_train_new, y_train, X_test_new, y_test,256,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 1000)        26000     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 128)               433536    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 15999)             2063871   \n",
      "=================================================================\n",
      "Total params: 2,523,407\n",
      "Trainable params: 2,523,407\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 8.6985 - acc: 2.0578e-04\n",
      "Epoch 2/1000\n",
      "9719/9719 [==============================] - 389s 40ms/step - loss: 7.7785 - acc: 2.0578e-04\n",
      "Epoch 3/1000\n",
      "9719/9719 [==============================] - 389s 40ms/step - loss: 7.6847 - acc: 2.0578e-04\n",
      "Epoch 4/1000\n",
      "9719/9719 [==============================] - 389s 40ms/step - loss: 7.7112 - acc: 3.0867e-04\n",
      "Epoch 5/1000\n",
      "9719/9719 [==============================] - 389s 40ms/step - loss: 7.5689 - acc: 6.1735e-04\n",
      "Epoch 6/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 7.5166 - acc: 5.1446e-04\n",
      "Epoch 7/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 7.4841 - acc: 0.0010\n",
      "Epoch 8/1000\n",
      "9719/9719 [==============================] - 389s 40ms/step - loss: 7.4720 - acc: 8.2313e-04\n",
      "Epoch 9/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 7.4476 - acc: 0.0010\n",
      "Epoch 10/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 7.4256 - acc: 0.0015\n",
      "Epoch 11/1000\n",
      "9719/9719 [==============================] - 389s 40ms/step - loss: 7.4122 - acc: 0.0015\n",
      "Epoch 12/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 7.3676 - acc: 0.0015\n",
      "Epoch 13/1000\n",
      "9719/9719 [==============================] - 389s 40ms/step - loss: 7.3254 - acc: 0.0025\n",
      "Epoch 14/1000\n",
      "9719/9719 [==============================] - 389s 40ms/step - loss: 7.2771 - acc: 0.0033\n",
      "Epoch 15/1000\n",
      "9719/9719 [==============================] - 389s 40ms/step - loss: 7.1989 - acc: 0.0038\n",
      "Epoch 16/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 7.1360 - acc: 0.0056\n",
      "Epoch 17/1000\n",
      "9719/9719 [==============================] - 389s 40ms/step - loss: 7.0563 - acc: 0.0075\n",
      "Epoch 18/1000\n",
      "9719/9719 [==============================] - 389s 40ms/step - loss: 7.0093 - acc: 0.0088\n",
      "Epoch 19/1000\n",
      "9719/9719 [==============================] - 389s 40ms/step - loss: 6.9383 - acc: 0.0109\n",
      "Epoch 20/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 6.8878 - acc: 0.0149\n",
      "Epoch 21/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 6.8380 - acc: 0.0162\n",
      "Epoch 22/1000\n",
      "9719/9719 [==============================] - 389s 40ms/step - loss: 6.7805 - acc: 0.0167\n",
      "Epoch 23/1000\n",
      "9719/9719 [==============================] - 389s 40ms/step - loss: 6.7662 - acc: 0.0195\n",
      "Epoch 24/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 6.6936 - acc: 0.0238\n",
      "Epoch 25/1000\n",
      "9719/9719 [==============================] - 391s 40ms/step - loss: 6.6356 - acc: 0.0245\n",
      "Epoch 26/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 6.5723 - acc: 0.0286\n",
      "Epoch 27/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 6.5229 - acc: 0.0333\n",
      "Epoch 28/1000\n",
      "9719/9719 [==============================] - 391s 40ms/step - loss: 6.4585 - acc: 0.0355\n",
      "Epoch 29/1000\n",
      "9719/9719 [==============================] - 391s 40ms/step - loss: 6.4166 - acc: 0.0341\n",
      "Epoch 30/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 6.3619 - acc: 0.0387\n",
      "Epoch 31/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 6.3019 - acc: 0.0411\n",
      "Epoch 32/1000\n",
      "9719/9719 [==============================] - 391s 40ms/step - loss: 6.2587 - acc: 0.0428\n",
      "Epoch 33/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 6.2093 - acc: 0.0468\n",
      "Epoch 34/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 6.1715 - acc: 0.0471\n",
      "Epoch 35/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 6.1094 - acc: 0.0508\n",
      "Epoch 36/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 6.0929 - acc: 0.0502\n",
      "Epoch 37/1000\n",
      "9719/9719 [==============================] - 391s 40ms/step - loss: 6.0357 - acc: 0.0539\n",
      "Epoch 38/1000\n",
      "9719/9719 [==============================] - 391s 40ms/step - loss: 5.9807 - acc: 0.0570\n",
      "Epoch 39/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 5.9304 - acc: 0.0593\n",
      "Epoch 40/1000\n",
      "9719/9719 [==============================] - 391s 40ms/step - loss: 5.8755 - acc: 0.0635\n",
      "Epoch 41/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 5.8349 - acc: 0.0674\n",
      "Epoch 42/1000\n",
      "9719/9719 [==============================] - 391s 40ms/step - loss: 5.8259 - acc: 0.0685\n",
      "Epoch 43/1000\n",
      "9719/9719 [==============================] - 391s 40ms/step - loss: 5.7843 - acc: 0.0713\n",
      "Epoch 44/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 5.7370 - acc: 0.0756\n",
      "Epoch 45/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 5.7127 - acc: 0.0764\n",
      "Epoch 46/1000\n",
      "9719/9719 [==============================] - 391s 40ms/step - loss: 5.6495 - acc: 0.0804\n",
      "Epoch 47/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 5.6185 - acc: 0.0840\n",
      "Epoch 48/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 5.5881 - acc: 0.0840\n",
      "Epoch 49/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 5.5693 - acc: 0.0845\n",
      "Epoch 50/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 5.5070 - acc: 0.0923\n",
      "Epoch 51/1000\n",
      "9719/9719 [==============================] - 391s 40ms/step - loss: 5.4865 - acc: 0.0883\n",
      "Epoch 52/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 5.4473 - acc: 0.0922\n",
      "Epoch 53/1000\n",
      "9719/9719 [==============================] - 393s 40ms/step - loss: 5.4043 - acc: 0.0990\n",
      "Epoch 54/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 5.3653 - acc: 0.1038\n",
      "Epoch 55/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 5.3506 - acc: 0.1036\n",
      "Epoch 56/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 5.3649 - acc: 0.1041\n",
      "Epoch 57/1000\n",
      "9719/9719 [==============================] - 391s 40ms/step - loss: 5.2687 - acc: 0.1126\n",
      "Epoch 58/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 5.1959 - acc: 0.1162\n",
      "Epoch 59/1000\n",
      "9719/9719 [==============================] - 391s 40ms/step - loss: 5.1663 - acc: 0.1202\n",
      "Epoch 60/1000\n",
      "9719/9719 [==============================] - 391s 40ms/step - loss: 5.1437 - acc: 0.1224\n",
      "Epoch 61/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 5.1383 - acc: 0.1205\n",
      "Epoch 62/1000\n",
      "9719/9719 [==============================] - 391s 40ms/step - loss: 5.0860 - acc: 0.1287\n",
      "Epoch 63/1000\n",
      "9719/9719 [==============================] - 391s 40ms/step - loss: 5.0478 - acc: 0.1276\n",
      "Epoch 64/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 4.9780 - acc: 0.1372\n",
      "Epoch 65/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 4.9944 - acc: 0.1319\n",
      "Epoch 66/1000\n",
      "9719/9719 [==============================] - 393s 40ms/step - loss: 5.0368 - acc: 0.1313\n",
      "Epoch 67/1000\n",
      "9719/9719 [==============================] - 391s 40ms/step - loss: 4.9071 - acc: 0.1416\n",
      "Epoch 68/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 4.8505 - acc: 0.1495\n",
      "Epoch 69/1000\n",
      "9719/9719 [==============================] - 390s 40ms/step - loss: 4.8948 - acc: 0.1463\n",
      "Epoch 70/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 4.8567 - acc: 0.1504\n",
      "Epoch 71/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 4.7465 - acc: 0.1606\n",
      "Epoch 72/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 4.7259 - acc: 0.1602\n",
      "Epoch 73/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 4.8027 - acc: 0.1513\n",
      "Epoch 74/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 4.7302 - acc: 0.1628\n",
      "Epoch 75/1000\n",
      "9719/9719 [==============================] - 391s 40ms/step - loss: 4.6812 - acc: 0.1613\n",
      "Epoch 76/1000\n",
      "9719/9719 [==============================] - 391s 40ms/step - loss: 4.6110 - acc: 0.1711\n",
      "Epoch 77/1000\n",
      "9719/9719 [==============================] - 391s 40ms/step - loss: 4.6524 - acc: 0.1660\n",
      "Epoch 78/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 4.5933 - acc: 0.1717\n",
      "Epoch 79/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 4.5152 - acc: 0.1852\n",
      "Epoch 80/1000\n",
      "9719/9719 [==============================] - 393s 40ms/step - loss: 4.4666 - acc: 0.1883\n",
      "Epoch 81/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 4.4341 - acc: 0.1986\n",
      "Epoch 82/1000\n",
      "9719/9719 [==============================] - 391s 40ms/step - loss: 4.4582 - acc: 0.1910\n",
      "Epoch 83/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 4.3390 - acc: 0.2026\n",
      "Epoch 84/1000\n",
      "9719/9719 [==============================] - 393s 40ms/step - loss: 4.4035 - acc: 0.1948\n",
      "Epoch 85/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 4.3851 - acc: 0.1971\n",
      "Epoch 86/1000\n",
      "9719/9719 [==============================] - 391s 40ms/step - loss: 4.3266 - acc: 0.2076\n",
      "Epoch 87/1000\n",
      "9719/9719 [==============================] - 391s 40ms/step - loss: 4.3522 - acc: 0.2041\n",
      "Epoch 88/1000\n",
      "9719/9719 [==============================] - 391s 40ms/step - loss: 4.2147 - acc: 0.2177\n",
      "Epoch 89/1000\n",
      "9719/9719 [==============================] - 391s 40ms/step - loss: 4.2860 - acc: 0.2111\n",
      "Epoch 90/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 4.2032 - acc: 0.2197\n",
      "Epoch 91/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 4.1835 - acc: 0.2239\n",
      "Epoch 92/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 4.1061 - acc: 0.2336\n",
      "Epoch 93/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 4.1682 - acc: 0.2284\n",
      "Epoch 94/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 4.1134 - acc: 0.2361\n",
      "Epoch 95/1000\n",
      "9719/9719 [==============================] - 391s 40ms/step - loss: 4.0687 - acc: 0.2474\n",
      "Epoch 96/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 4.0039 - acc: 0.2524\n",
      "Epoch 97/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 3.9838 - acc: 0.2590\n",
      "Epoch 98/1000\n",
      "9719/9719 [==============================] - 393s 40ms/step - loss: 3.9335 - acc: 0.2584\n",
      "Epoch 99/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 3.8894 - acc: 0.2617\n",
      "Epoch 100/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 3.9450 - acc: 0.2549\n",
      "Epoch 101/1000\n",
      "9719/9719 [==============================] - 391s 40ms/step - loss: 3.8166 - acc: 0.2761\n",
      "Epoch 102/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 3.8248 - acc: 0.2757\n",
      "Epoch 103/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 3.8260 - acc: 0.2744\n",
      "Epoch 104/1000\n",
      "9719/9719 [==============================] - 393s 40ms/step - loss: 3.7745 - acc: 0.2792\n",
      "Epoch 105/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 3.7406 - acc: 0.2888\n",
      "Epoch 106/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 3.8162 - acc: 0.2731\n",
      "Epoch 107/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 3.6967 - acc: 0.2911\n",
      "Epoch 108/1000\n",
      "9719/9719 [==============================] - 394s 41ms/step - loss: 3.7120 - acc: 0.2869\n",
      "Epoch 109/1000\n",
      "9719/9719 [==============================] - 393s 40ms/step - loss: 3.6341 - acc: 0.3048\n",
      "Epoch 110/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 3.6251 - acc: 0.3056\n",
      "Epoch 111/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 3.5930 - acc: 0.3087\n",
      "Epoch 112/1000\n",
      "9719/9719 [==============================] - 393s 40ms/step - loss: 3.5848 - acc: 0.3117\n",
      "Epoch 113/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 3.4818 - acc: 0.3268\n",
      "Epoch 114/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 3.5776 - acc: 0.3178\n",
      "Epoch 115/1000\n",
      "9719/9719 [==============================] - 393s 40ms/step - loss: 3.5063 - acc: 0.3274\n",
      "Epoch 116/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 3.4445 - acc: 0.3358\n",
      "Epoch 117/1000\n",
      "9719/9719 [==============================] - 394s 40ms/step - loss: 3.3785 - acc: 0.3489\n",
      "Epoch 118/1000\n",
      "9719/9719 [==============================] - 393s 40ms/step - loss: 3.4231 - acc: 0.3418\n",
      "Epoch 119/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 3.4080 - acc: 0.3438\n",
      "Epoch 120/1000\n",
      "9719/9719 [==============================] - 393s 40ms/step - loss: 3.4395 - acc: 0.3430\n",
      "Epoch 121/1000\n",
      "9719/9719 [==============================] - 394s 41ms/step - loss: 3.4200 - acc: 0.3457\n",
      "Epoch 122/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 3.2385 - acc: 0.3734\n",
      "Epoch 123/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 3.2070 - acc: 0.3752\n",
      "Epoch 124/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 3.2225 - acc: 0.3783\n",
      "Epoch 125/1000\n",
      "9719/9719 [==============================] - 394s 41ms/step - loss: 3.2124 - acc: 0.3792\n",
      "Epoch 126/1000\n",
      "9719/9719 [==============================] - 394s 41ms/step - loss: 3.1374 - acc: 0.3911\n",
      "Epoch 127/1000\n",
      "9719/9719 [==============================] - 395s 41ms/step - loss: 3.0829 - acc: 0.3990\n",
      "Epoch 128/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 3.1284 - acc: 0.3999\n",
      "Epoch 129/1000\n",
      "9719/9719 [==============================] - 394s 41ms/step - loss: 3.1064 - acc: 0.3957\n",
      "Epoch 130/1000\n",
      "9719/9719 [==============================] - 393s 40ms/step - loss: 3.0600 - acc: 0.4058\n",
      "Epoch 131/1000\n",
      "9719/9719 [==============================] - 394s 41ms/step - loss: 3.0354 - acc: 0.4118\n",
      "Epoch 132/1000\n",
      "9719/9719 [==============================] - 393s 40ms/step - loss: 3.0600 - acc: 0.4042\n",
      "Epoch 133/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 3.0918 - acc: 0.4028\n",
      "Epoch 134/1000\n",
      "9719/9719 [==============================] - 395s 41ms/step - loss: 2.9915 - acc: 0.4200\n",
      "Epoch 135/1000\n",
      "9719/9719 [==============================] - 394s 41ms/step - loss: 2.9132 - acc: 0.4326\n",
      "Epoch 136/1000\n",
      "9719/9719 [==============================] - 396s 41ms/step - loss: 2.8977 - acc: 0.4320\n",
      "Epoch 137/1000\n",
      "9719/9719 [==============================] - 393s 40ms/step - loss: 2.8949 - acc: 0.4423\n",
      "Epoch 138/1000\n",
      "9719/9719 [==============================] - 393s 40ms/step - loss: 2.8903 - acc: 0.4392\n",
      "Epoch 139/1000\n",
      "9719/9719 [==============================] - 393s 40ms/step - loss: 2.9356 - acc: 0.4325\n",
      "Epoch 140/1000\n",
      "9719/9719 [==============================] - 394s 41ms/step - loss: 2.8402 - acc: 0.4452\n",
      "Epoch 141/1000\n",
      "9719/9719 [==============================] - 395s 41ms/step - loss: 2.8511 - acc: 0.4485\n",
      "Epoch 142/1000\n",
      "9719/9719 [==============================] - 393s 40ms/step - loss: 2.8073 - acc: 0.4545\n",
      "Epoch 143/1000\n",
      "9719/9719 [==============================] - 393s 40ms/step - loss: 2.7298 - acc: 0.4769\n",
      "Epoch 144/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 2.7164 - acc: 0.4754\n",
      "Epoch 145/1000\n",
      "9719/9719 [==============================] - 394s 41ms/step - loss: 2.7154 - acc: 0.4770\n",
      "Epoch 146/1000\n",
      "9719/9719 [==============================] - 394s 41ms/step - loss: 2.6375 - acc: 0.4957\n",
      "Epoch 147/1000\n",
      "9719/9719 [==============================] - 393s 40ms/step - loss: 2.7150 - acc: 0.4776\n",
      "Epoch 148/1000\n",
      "9719/9719 [==============================] - 394s 41ms/step - loss: 2.6524 - acc: 0.4954\n",
      "Epoch 149/1000\n",
      "9719/9719 [==============================] - 393s 40ms/step - loss: 2.7140 - acc: 0.4737\n",
      "Epoch 150/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 2.6915 - acc: 0.4873\n",
      "Epoch 151/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 2.5492 - acc: 0.5162\n",
      "Epoch 152/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9719/9719 [==============================] - 394s 41ms/step - loss: 2.6241 - acc: 0.4943\n",
      "Epoch 153/1000\n",
      "9719/9719 [==============================] - 394s 41ms/step - loss: 2.4909 - acc: 0.5291\n",
      "Epoch 154/1000\n",
      "9719/9719 [==============================] - 393s 40ms/step - loss: 2.5134 - acc: 0.5232\n",
      "Epoch 155/1000\n",
      "9719/9719 [==============================] - 394s 41ms/step - loss: 2.5713 - acc: 0.5080\n",
      "Epoch 156/1000\n",
      "9719/9719 [==============================] - 394s 41ms/step - loss: 2.4376 - acc: 0.5407\n",
      "Epoch 157/1000\n",
      "9719/9719 [==============================] - 394s 41ms/step - loss: 2.3997 - acc: 0.5495\n",
      "Epoch 158/1000\n",
      "9719/9719 [==============================] - 393s 40ms/step - loss: 2.3856 - acc: 0.5575\n",
      "Epoch 159/1000\n",
      "9719/9719 [==============================] - 394s 41ms/step - loss: 2.4097 - acc: 0.5475\n",
      "Epoch 160/1000\n",
      "9719/9719 [==============================] - 394s 41ms/step - loss: 2.4443 - acc: 0.5388\n",
      "Epoch 161/1000\n",
      "9719/9719 [==============================] - 393s 40ms/step - loss: 2.3181 - acc: 0.5719\n",
      "Epoch 162/1000\n",
      "9719/9719 [==============================] - 393s 40ms/step - loss: 2.3983 - acc: 0.5456\n",
      "Epoch 163/1000\n",
      "9719/9719 [==============================] - 394s 41ms/step - loss: 2.4100 - acc: 0.5530\n",
      "Epoch 164/1000\n",
      "9719/9719 [==============================] - 395s 41ms/step - loss: 2.3589 - acc: 0.5537\n",
      "Epoch 165/1000\n",
      "9719/9719 [==============================] - 393s 40ms/step - loss: 2.3266 - acc: 0.5667\n",
      "Epoch 166/1000\n",
      "9719/9719 [==============================] - 394s 41ms/step - loss: 2.2737 - acc: 0.5780\n",
      "Epoch 167/1000\n",
      "9719/9719 [==============================] - 393s 40ms/step - loss: 2.2690 - acc: 0.5826\n",
      "Epoch 168/1000\n",
      "9719/9719 [==============================] - 395s 41ms/step - loss: 2.4025 - acc: 0.5462\n",
      "Epoch 169/1000\n",
      "9719/9719 [==============================] - 394s 41ms/step - loss: 2.1991 - acc: 0.6013\n",
      "Epoch 170/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 2.1556 - acc: 0.6133\n",
      "Epoch 171/1000\n",
      "9719/9719 [==============================] - 392s 40ms/step - loss: 2.1600 - acc: 0.6061\n",
      "Epoch 172/1000\n",
      "4608/9719 [=============>................] - ETA: 3:28 - loss: 2.1308 - acc: 0.6211"
     ]
    }
   ],
   "source": [
    "model6(X_train_new, y_train, X_test_new, y_test,256,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 1000)        26000     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 128)               433536    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20372)             2627988   \n",
      "=================================================================\n",
      "Total params: 3,087,524\n",
      "Trainable params: 3,087,524\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "12544/22579 [===============>..............] - ETA: 6:29 - loss: 9.4335 - acc: 1.5944e-04"
     ]
    }
   ],
   "source": [
    "model7(X_train_new, y_train, X_test_new, y_test,256,10,\"GRU_model_test.json\",model_h5_file=\"GRU_model_test.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
