{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy \n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.Data import IUPACData \n",
    "\n",
    "def protein2integer(in_seq):\n",
    "    \n",
    "    ## define universe of possible input values\n",
    "    all_protein_letters = list(IUPACData.extended_protein_letters)\n",
    "    #print(all_protein_letters)\n",
    "    ## define a mapping of chars to integers\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(all_protein_letters))\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(all_protein_letters))\n",
    "    ## integer encode input data\n",
    "    integer_encoded = [char_to_int[char] for char in in_seq.upper()]\n",
    "    \n",
    "    #return(integer_encoded,len(all_protein_letters))\n",
    "    return(integer_encoded)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MARPO07937' 'ORYBR13189' 'ORYGL12366' 'ORYLO20560' 'ORYNI16379'\n",
      " 'ORYRU16587' 'ORYSI15948' 'ORYSJ14856' 'BRADI07563' 'HORVV106231'\n",
      " 'AEGTA03913' 'WHEAT40487' 'TRIUA17650' 'ERATE34499' 'SORBI12540'\n",
      " 'MAIZE00159' 'SETIT35121' 'MUSAC02596' 'MUSAM06245' 'CHEQI00829'\n",
      " 'NICAT07910' 'SOLTU21094' 'SOYBN32269' 'MEDTR35254' 'POPTR21272'\n",
      " 'PRUPE14530' 'ARAAL19814' 'BRARP07873' 'BRANA06689' 'ARALY22171'\n",
      " 'ARATH34990' 'THECC11816' 'GOSHI65213' 'ORYNI25992' 'ORYPU22376'\n",
      " 'ORYRU26544' 'ORYSI26003' 'ORYSJ23753' 'BRADI09931' 'HORVV192917'\n",
      " 'WHEAT23509' 'ERATE16670' 'MAIZE31955' 'SETIT10568' 'MUSAC31008'\n",
      " 'MUSAM27905' 'SOLLC02705' 'SOLTU04879' 'LUPAN08914' 'MANES15049'\n",
      " 'POPTR16484' 'PRUPE13257' 'BRANA90718' 'BRAOL47337' 'ARALY00095'\n",
      " 'ARATH00066' 'THECC03451' 'ORYBR16014' 'ORYGL27982' 'ORYLO22608'\n",
      " 'ORYNI36636' 'ORYPU31377' 'ORYRU37270' 'ORYSI36479' 'ORYSJ33184'\n",
      " 'HORVV130178' 'AEGTA25528' 'WHEAT33067' 'ERATE21849' 'SORBI01205'\n",
      " 'MAIZE11545' 'CHEQI00389' 'SOLLC13604' 'BRANA38027' 'BRAOL53590'\n",
      " 'GOSHI51151']\n",
      "['MAAMTMTRPNDPFTSDIARFHEVKGAKDEPFAELTRYHEVRGVREMVESFRVREVPSYYVKPVNERRFTPPSAAVLSMEQQIPCIDLEALSGQELLSAIANACRDWGFFQVLNHGLPSQLVQNMAKQSSEFFAQPLEEKMKCSTPARVSGPVHFGGGGNRDWRDVLKLNCAPASIVAKEYWPQRPAGFRDTMEEYSSQQQALAIRLLKLISESLGLESNYLVAACGEPKVVMAINHYPPCPDPSLTMGIKAHSDPNTITMLLQDDVGGLQVFKEDRWIDVRPLPNALVINVGDQLQILSNGKYSSCLHRVVNNNRQARTSIATFFSPAHACIIGPAPGLVDEVNPAIYPNIVYADYIKAFYTQALGPNNKNGGYLAGIELHRRYNCYTSSSSISS'\n",
      " 'MAEQLISTADHDTLPGSYVRPEAQRPRLAEVVADASIPVVDLADPDRAHLVSQVGAACRSHGFFQVLNHGVPVELILSGGAVAHEFFRLPAEEMAKLYSDDPAKKIRLSTSFNVRKETVHNWRDYLRLHCYPLDRYLPDWPSNPTSFREIVSTYCKEVRELGFRLYGAISESLDLEHDYIRNVLGEQEQHMAVNFYPKCPEPELTFGLPAHTDPNALTILLMDQQVAGLQVLNEGKWIAVNPQPNALVINIGDQLQALSNGRYKSVWHRAVVNSDKARMSVASFLCPCNDVLIGPAQKLITDGSPAVYRNYTYDEYYKKFWSRNLDQEHCLELFRTQPTTPSDHSISNS']\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "(76, 3)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "data_path = 'features.csv'\n",
    "with open(data_path, 'r') as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    # get all the rows as a list\n",
    "    dataset = list(reader)\n",
    "    # transform data into numpy array\n",
    "    dataset = np.array(dataset).astype(str)\n",
    "\n",
    "print(dataset[:,0])\n",
    "print(dataset[0:2,1])\n",
    "print(dataset[:,2].astype(int))\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(76,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset[:,1].shape)\n",
    "integer_encoded_proteins = np.array([protein2integer(seq) for seq in dataset[:,1]])\n",
    "len(integer_encoded_proteins)\n",
    "integer_encoded_proteins[0]\n",
    "#np.array(integer_encoded_proteins).shape\n",
    "integer_encoded_proteins.shape\n",
    "#protein2integer(dataset[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76,)\n",
      "(76,)\n",
      "(76,)\n",
      "['MARPO07937' 'ORYBR13189' 'ORYGL12366']\n",
      "[list([10, 0, 0, 10, 16, 10, 16, 14, 12, 11, 2, 12, 4, 16, 15, 2, 7, 0, 14, 4, 6, 3, 17, 8, 5, 0, 8, 2, 3, 12, 4, 0, 3, 9, 16, 14, 19, 6, 3, 17, 14, 5, 17, 14, 3, 10, 17, 3, 15, 4, 14, 17, 14, 3, 17, 12, 15, 19, 19, 17, 8, 12, 17, 11, 3, 14, 14, 4, 16, 12, 12, 15, 0, 0, 17, 9, 15, 10, 3, 13, 13, 7, 12, 1, 7, 2, 9, 3, 0, 9, 15, 5, 13, 3, 9, 9, 15, 0, 7, 0, 11, 0, 1, 14, 2, 18, 5, 4, 4, 13, 17, 9, 11, 6, 5, 9, 12, 15, 13, 9, 17, 13, 11, 10, 0, 8, 13, 15, 15, 3, 4, 4, 0, 13, 12, 9, 3, 3, 8, 10, 8, 1, 15, 16, 12, 0, 14, 17, 15, 5, 12, 17, 6, 4, 5, 5, 5, 5, 11, 14, 2, 18, 14, 2, 17, 9, 8, 9, 11, 1, 0, 12, 0, 15, 7, 17, 0, 8, 3, 19, 18, 12, 13, 14, 12, 0, 5, 4, 14, 2, 16, 10, 3, 3, 19, 15, 15, 13, 13, 13, 0, 9, 0, 7, 14, 9, 9, 8, 9, 7, 15, 3, 15, 9, 5, 9, 3, 15, 11, 19, 9, 17, 0, 0, 1, 5, 3, 12, 8, 17, 17, 10, 0, 7, 11, 6, 19, 12, 12, 1, 12, 2, 12, 15, 9, 16, 10, 5, 7, 8, 0, 6, 15, 2, 12, 11, 16, 7, 16, 10, 9, 9, 13, 2, 2, 17, 5, 5, 9, 13, 17, 4, 8, 3, 2, 14, 18, 7, 2, 17, 14, 12, 9, 12, 11, 0, 9, 17, 7, 11, 17, 5, 2, 13, 9, 13, 7, 9, 15, 11, 5, 8, 19, 15, 15, 1, 9, 6, 14, 17, 17, 11, 11, 11, 14, 13, 0, 14, 16, 15, 7, 0, 16, 4, 4, 15, 12, 0, 6, 0, 1, 7, 7, 5, 12, 0, 12, 5, 9, 17, 2, 3, 17, 11, 12, 0, 7, 19, 12, 11, 7, 17, 19, 0, 2, 19, 7, 8, 0, 4, 19, 16, 13, 0, 9, 5, 12, 11, 11, 8, 11, 5, 5, 19, 9, 0, 5, 7, 3, 9, 6, 14, 14, 19, 11, 1, 19, 16, 15, 15, 15, 15, 7, 15, 15])\n",
      " list([10, 0, 3, 13, 9, 7, 15, 16, 0, 2, 6, 2, 16, 9, 12, 5, 15, 19, 17, 14, 12, 3, 0, 13, 14, 12, 14, 9, 0, 3, 17, 17, 0, 2, 0, 15, 7, 12, 17, 17, 2, 9, 0, 2, 12, 2, 14, 0, 6, 9, 17, 15, 13, 17, 5, 0, 0, 1, 14, 15, 6, 5, 4, 4, 13, 17, 9, 11, 6, 5, 17, 12, 17, 3, 9, 7, 9, 15, 5, 5, 0, 17, 0, 6, 3, 4, 4, 14, 9, 12, 0, 3, 3, 10, 0, 8, 9, 19, 15, 2, 2, 12, 0, 8, 8, 7, 14, 9, 15, 16, 15, 4, 11, 17, 14, 8, 3, 16, 17, 6, 11, 18, 14, 2, 19, 9, 14, 9, 6, 1, 19, 12, 9, 2, 14, 19, 9, 12, 2, 18, 12, 15, 11, 12, 16, 15, 4, 14, 3, 7, 17, 15, 16, 19, 1, 8, 3, 17, 14, 3, 9, 5, 4, 14, 9, 19, 5, 0, 7, 15, 3, 15, 9, 2, 9, 3, 6, 2, 19, 7, 14, 11, 17, 9, 5, 3, 13, 3, 13, 6, 10, 0, 17, 11, 4, 19, 12, 8, 1, 12, 3, 12, 3, 9, 16, 4, 5, 9, 12, 0, 6, 16, 2, 12, 11, 0, 9, 16, 7, 9, 9, 10, 2, 13, 13, 17, 0, 5, 9, 13, 17, 9, 11, 3, 5, 8, 18, 7, 0, 17, 11, 12, 13, 12, 11, 0, 9, 17, 7, 11, 7, 5, 2, 13, 9, 13, 0, 9, 15, 11, 5, 14, 19, 8, 15, 17, 18, 6, 14, 0, 17, 17, 11, 15, 2, 8, 0, 14, 10, 15, 17, 0, 15, 4, 9, 1, 12, 1, 11, 2, 17, 9, 7, 5, 12, 0, 13, 8, 9, 7, 16, 2, 5, 15, 12, 0, 17, 19, 14, 11, 19, 16, 19, 2, 3, 19, 19, 8, 8, 4, 18, 15, 14, 11, 9, 2, 13, 3, 6, 1, 9, 3, 9, 4, 14, 16, 13, 12, 16, 16, 12, 15, 2, 6, 15, 7, 15, 11, 15])\n",
      " list([10, 0, 2, 13, 9, 7, 15, 16, 0, 2, 6, 2, 16, 9, 12, 5, 11, 19, 17, 14, 12, 3, 0, 13, 14, 12, 14, 9, 0, 2, 17, 9, 15, 2, 0, 15, 7, 12, 17, 17, 2, 9, 0, 11, 12, 2, 14, 0, 8, 9, 17, 15, 13, 17, 5, 0, 0, 1, 14, 15, 6, 5, 4, 4, 13, 17, 9, 11, 6, 5, 17, 12, 17, 3, 9, 16, 9, 15, 17, 9, 0, 17, 0, 6, 2, 4, 4, 14, 9, 12, 0, 3, 3, 8, 0, 8, 9, 19, 15, 2, 2, 12, 0, 8, 8, 7, 14, 9, 15, 16, 15, 4, 11, 17, 14, 8, 3, 16, 17, 6, 11, 18, 14, 2, 19, 9, 14, 9, 6, 1, 19, 12, 9, 6, 14, 19, 9, 12, 2, 18, 12, 15, 11, 12, 12, 15, 4, 14, 3, 7, 7, 15, 16, 19, 1, 8, 3, 17, 14, 3, 9, 5, 4, 14, 9, 19, 5, 0, 7, 15, 3, 15, 9, 5, 9, 3, 13, 2, 19, 17, 8, 8, 17, 9, 5, 3, 13, 3, 13, 6, 10, 0, 17, 11, 4, 19, 12, 8, 1, 12, 3, 12, 3, 9, 16, 4, 5, 9, 12, 0, 6, 16, 2, 12, 11, 0, 9, 16, 7, 9, 9, 10, 2, 13, 13, 17, 0, 5, 9, 13, 17, 9, 8, 3, 5, 14, 18, 7, 0, 17, 11, 12, 13, 12, 11, 0, 9, 17, 7, 11, 7, 5, 2, 13, 9, 13, 13, 0, 9, 15, 11, 5, 14, 19, 8, 15, 17, 18, 6, 14, 0, 17, 17, 11, 15, 2, 8, 0, 14, 10, 15, 17, 0, 15, 4, 9, 1, 12, 1, 11, 2, 17, 9, 7, 5, 12, 0, 13, 8, 9, 7, 16, 2, 5, 15, 12, 0, 17, 19, 14, 11, 19, 16, 19, 2, 3, 19, 19, 8, 8, 4, 18, 15, 14, 11, 9, 2, 13, 3, 6, 1, 9, 3, 9, 4, 14, 16, 16, 12, 16, 2, 16, 15])]\n",
      "[1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Loading the input values to X and Label values Y using slicing.\n",
    "G = dataset[:, 0]\n",
    "X = integer_encoded_proteins\n",
    "Y = dataset[:, 2].astype(int)\n",
    "\n",
    "print(G.shape)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "print(G[0:3,])\n",
    "print(X[0:3,])\n",
    "print(Y[0:3,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum review length: 456\n",
      "Minimum review length: 122\n",
      "<type 'numpy.ndarray'>\n",
      "(76,)\n",
      "(76,)\n",
      "(76,)\n",
      "(60, 16)\n",
      "((60,), (16,))\n",
      "ARAAL19814\n",
      "[10, 0, 5, 8, 9, 7, 15, 16, 5, 9, 14, 9, 16, 16, 9, 12, 5, 11, 19, 17, 14, 12, 4, 15, 2, 14, 12, 14, 9, 15, 3, 17, 15, 13, 9, 3, 2, 4, 12, 9, 7, 2, 9, 15, 15, 16, 2, 14, 15, 14, 9, 17, 13, 13, 7, 6, 13, 0, 1, 16, 14, 4, 5, 4, 4, 13, 17, 7, 11, 6, 5, 17, 2, 8, 3, 16, 7, 2, 3, 10, 17, 15, 17, 0, 11, 3, 4, 4, 15, 10, 15, 10, 3, 3, 8, 10, 8, 9, 19, 15, 2, 2, 12, 16, 14, 16, 16, 14, 9, 15, 16, 15, 4, 11, 17, 8, 8, 3, 3, 7, 11, 11, 18, 14, 2, 19, 9, 14, 9, 6, 1, 19, 12, 7, 2, 8, 19, 7, 6, 3, 18, 12, 15, 11, 12, 7, 12, 4, 8, 11, 17, 17, 15, 8, 19, 15, 14, 3, 17, 14, 3, 17, 5, 4, 14, 7, 3, 3, 9, 7, 15, 3, 15, 9, 5, 9, 3, 16, 2, 19, 9, 14, 8, 17, 9, 5, 3, 13, 5, 13, 6, 10, 0, 17, 11, 19, 19, 12, 12, 1, 12, 3, 12, 3, 9, 16, 19, 5, 9, 12, 0, 6, 16, 2, 12, 11, 0, 9, 16, 7, 9, 9, 13, 2, 15, 16, 17, 1, 5, 9, 13, 7, 9, 7, 2, 5, 13, 18, 4, 0, 7, 11, 12, 6, 12, 2, 0, 4, 17, 7, 11, 7, 5, 2, 13, 9, 13, 0, 9, 15, 11, 5, 17, 19, 8, 15, 17, 18, 6, 14, 0, 17, 16, 11, 16, 3, 10, 12, 14, 9, 15, 17, 0, 15, 4, 9, 1, 12, 0, 2, 1, 0, 7, 10, 15, 12, 0, 8, 12, 9, 18, 3, 0, 3, 3, 2, 3, 15, 8, 12, 17, 19, 14, 2, 4, 16, 19, 0, 3, 19, 19, 8, 8, 4, 18, 15, 14, 11, 9, 2, 13, 3, 6, 1, 9, 3, 11, 4, 9, 11, 6]\n",
      "1\n",
      "ARAAL19814\n",
      "[10, 0, 5, 8, 9, 7, 15, 16, 5, 9, 14, 9, 16, 16, 9, 12, 5, 11, 19, 17, 14, 12, 4, 15, 2, 14, 12, 14, 9, 15, 3, 17, 15, 13, 9, 3, 2, 4, 12, 9, 7, 2, 9, 15, 15, 16, 2, 14, 15, 14, 9, 17, 13, 13, 7, 6, 13, 0, 1, 16, 14, 4, 5, 4, 4, 13, 17, 7, 11, 6, 5, 17, 2, 8, 3, 16, 7, 2, 3, 10, 17, 15, 17, 0, 11, 3, 4, 4, 15, 10, 15, 10, 3, 3, 8, 10, 8, 9, 19, 15, 2, 2, 12, 16, 14, 16, 16, 14, 9, 15, 16, 15, 4, 11, 17, 8, 8, 3, 3, 7, 11, 11, 18, 14, 2, 19, 9, 14, 9, 6, 1, 19, 12, 7, 2, 8, 19, 7, 6, 3, 18, 12, 15, 11, 12, 7, 12, 4, 8, 11, 17, 17, 15, 8, 19, 15, 14, 3, 17, 14, 3, 17, 5, 4, 14, 7, 3, 3, 9, 7, 15, 3, 15, 9, 5, 9, 3, 16, 2, 19, 9, 14, 8, 17, 9, 5, 3, 13, 5, 13, 6, 10, 0, 17, 11, 19, 19, 12, 12, 1, 12, 3, 12, 3, 9, 16, 19, 5, 9, 12, 0, 6, 16, 2, 12, 11, 0, 9, 16, 7, 9, 9, 13, 2, 15, 16, 17, 1, 5, 9, 13, 7, 9, 7, 2, 5, 13, 18, 4, 0, 7, 11, 12, 6, 12, 2, 0, 4, 17, 7, 11, 7, 5, 2, 13, 9, 13, 0, 9, 15, 11, 5, 17, 19, 8, 15, 17, 18, 6, 14, 0, 17, 16, 11, 16, 3, 10, 12, 14, 9, 15, 17, 0, 15, 4, 9, 1, 12, 0, 2, 1, 0, 7, 10, 15, 12, 0, 8, 12, 9, 18, 3, 0, 3, 3, 2, 3, 15, 8, 12, 17, 19, 14, 2, 4, 16, 19, 0, 3, 19, 19, 8, 8, 4, 18, 15, 14, 11, 9, 2, 13, 3, 6, 1, 9, 3, 11, 4, 9, 11, 6]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print('Maximum review length: {}'.format(len(max(X, key=len))))\n",
    "print('Minimum review length: {}'.format(len(min(X, key=len))))\n",
    "print(type(X))\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(G.shape)\n",
    "\n",
    "indices = numpy.random.permutation(X.shape[0])\n",
    "train_size = int(indices.size*0.8)\n",
    "train_idx, test_idx = indices[:train_size], indices[train_size:]\n",
    "print(len(train_idx),len(test_idx))\n",
    "X_train, X_test = X[train_idx,], X[test_idx,]\n",
    "print(X_train.shape,X_test.shape)\n",
    "y_train, y_test = Y[train_idx,], Y[test_idx,]\n",
    "G_train, G_test = G[train_idx,], G[test_idx,]\n",
    "\n",
    "print(G[train_idx[0],])\n",
    "print(X[train_idx[0],])\n",
    "print(Y[train_idx[0],])\n",
    "\n",
    "print(G_train[0,])\n",
    "print(X_train[0,])\n",
    "print(y_train[0,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 456, 32)           832       \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 456, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 228, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 57,237\n",
      "Trainable params: 57,237\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "60/60 [==============================] - 2s 29ms/step - loss: 0.6538 - acc: 0.4500\n",
      "Epoch 2/50\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.5235 - acc: 0.4500\n",
      "Epoch 3/50\n",
      "60/60 [==============================] - 1s 14ms/step - loss: 0.3231 - acc: 0.4500\n",
      "Epoch 4/50\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.3503 - acc: 0.4500\n",
      "Epoch 5/50\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.2419 - acc: 0.4500\n",
      "Epoch 6/50\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.1370 - acc: 0.4500\n",
      "Epoch 7/50\n",
      "60/60 [==============================] - 1s 17ms/step - loss: 0.0572 - acc: 0.4500\n",
      "Epoch 8/50\n",
      "60/60 [==============================] - 1s 15ms/step - loss: -0.0480 - acc: 0.4500\n",
      "Epoch 9/50\n",
      "60/60 [==============================] - 1s 16ms/step - loss: -0.1749 - acc: 0.4500\n",
      "Epoch 10/50\n",
      "60/60 [==============================] - 1s 18ms/step - loss: -0.5005 - acc: 0.4500\n",
      "Epoch 11/50\n",
      "60/60 [==============================] - 1s 17ms/step - loss: -0.9748 - acc: 0.4500\n",
      "Epoch 12/50\n",
      "60/60 [==============================] - 1s 18ms/step - loss: -1.6189 - acc: 0.6833\n",
      "Epoch 13/50\n",
      "60/60 [==============================] - 1s 16ms/step - loss: -2.2810 - acc: 0.6667\n",
      "Epoch 14/50\n",
      "60/60 [==============================] - 1s 14ms/step - loss: -2.4094 - acc: 0.6500\n",
      "Epoch 15/50\n",
      "60/60 [==============================] - 1s 17ms/step - loss: -2.9847 - acc: 0.7500\n",
      "Epoch 16/50\n",
      "60/60 [==============================] - 1s 16ms/step - loss: -3.1028 - acc: 0.7500\n",
      "Epoch 17/50\n",
      "60/60 [==============================] - 1s 16ms/step - loss: -3.2989 - acc: 0.6833\n",
      "Epoch 18/50\n",
      "60/60 [==============================] - 1s 16ms/step - loss: -3.4174 - acc: 0.7500\n",
      "Epoch 19/50\n",
      "60/60 [==============================] - 1s 16ms/step - loss: -3.4216 - acc: 0.7500\n",
      "Epoch 20/50\n",
      "60/60 [==============================] - 1s 17ms/step - loss: -3.4312 - acc: 0.7500\n",
      "Epoch 21/50\n",
      "60/60 [==============================] - 1s 15ms/step - loss: -3.4309 - acc: 0.7500\n",
      "Epoch 22/50\n",
      "60/60 [==============================] - 1s 15ms/step - loss: -3.4388 - acc: 0.7500\n",
      "Epoch 23/50\n",
      "60/60 [==============================] - 1s 14ms/step - loss: -3.4417 - acc: 0.7500\n",
      "Epoch 24/50\n",
      "60/60 [==============================] - 1s 14ms/step - loss: -3.4432 - acc: 0.7500\n",
      "Epoch 25/50\n",
      "60/60 [==============================] - 1s 14ms/step - loss: -3.4443 - acc: 0.7500\n",
      "Epoch 26/50\n",
      "60/60 [==============================] - 1s 14ms/step - loss: -3.4451 - acc: 0.7500\n",
      "Epoch 27/50\n",
      "60/60 [==============================] - 1s 14ms/step - loss: -3.4461 - acc: 0.7500\n",
      "Epoch 28/50\n",
      "60/60 [==============================] - 1s 15ms/step - loss: -3.4466 - acc: 0.7500\n",
      "Epoch 29/50\n",
      "60/60 [==============================] - 1s 14ms/step - loss: -3.4470 - acc: 0.7500\n",
      "Epoch 30/50\n",
      "60/60 [==============================] - 1s 14ms/step - loss: -3.4475 - acc: 0.7500\n",
      "Epoch 31/50\n",
      "60/60 [==============================] - 1s 14ms/step - loss: -3.4479 - acc: 0.7500\n",
      "Epoch 32/50\n",
      "60/60 [==============================] - 1s 14ms/step - loss: -3.4482 - acc: 0.7500\n",
      "Epoch 33/50\n",
      "60/60 [==============================] - 1s 14ms/step - loss: -3.4485 - acc: 0.7500\n",
      "Epoch 34/50\n",
      "60/60 [==============================] - 1s 14ms/step - loss: -3.4489 - acc: 0.7500\n",
      "Epoch 35/50\n",
      "60/60 [==============================] - 1s 14ms/step - loss: -3.4491 - acc: 0.7500\n",
      "Epoch 36/50\n",
      "60/60 [==============================] - 1s 14ms/step - loss: -3.4494 - acc: 0.7500\n",
      "Epoch 37/50\n",
      "60/60 [==============================] - 1s 15ms/step - loss: -3.4496 - acc: 0.7500\n",
      "Epoch 38/50\n",
      "60/60 [==============================] - 1s 15ms/step - loss: -3.4498 - acc: 0.7500\n",
      "Epoch 39/50\n",
      "60/60 [==============================] - 1s 13ms/step - loss: -3.4501 - acc: 0.7500\n",
      "Epoch 40/50\n",
      "60/60 [==============================] - 1s 14ms/step - loss: -3.4502 - acc: 0.7500\n",
      "Epoch 41/50\n",
      "60/60 [==============================] - 1s 14ms/step - loss: -3.4504 - acc: 0.7500\n",
      "Epoch 42/50\n",
      "60/60 [==============================] - 1s 14ms/step - loss: -3.4506 - acc: 0.7500\n",
      "Epoch 43/50\n",
      "60/60 [==============================] - 1s 14ms/step - loss: -3.4508 - acc: 0.7500\n",
      "Epoch 44/50\n",
      "60/60 [==============================] - 1s 15ms/step - loss: -3.4509 - acc: 0.7500\n",
      "Epoch 45/50\n",
      "60/60 [==============================] - 1s 14ms/step - loss: -3.4510 - acc: 0.7500\n",
      "Epoch 46/50\n",
      "60/60 [==============================] - 1s 15ms/step - loss: -3.4512 - acc: 0.7500\n",
      "Epoch 47/50\n",
      "60/60 [==============================] - 1s 14ms/step - loss: -3.4513 - acc: 0.7500\n",
      "Epoch 48/50\n",
      "60/60 [==============================] - 1s 14ms/step - loss: -3.4514 - acc: 0.7500\n",
      "Epoch 49/50\n",
      "60/60 [==============================] - 1s 14ms/step - loss: -3.4515 - acc: 0.7500\n",
      "Epoch 50/50\n",
      "60/60 [==============================] - 1s 16ms/step - loss: -3.4516 - acc: 0.7500\n",
      "Accuracy: 68.75%\n"
     ]
    }
   ],
   "source": [
    "# https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
    "# truncate and pad input sequences\n",
    "top_words = len(list(IUPACData.extended_protein_letters)) # = 26\n",
    "max_review_length = len(max(X, key=len)) # = 500\n",
    "X_train_new = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test_new = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train_new, y_train, epochs=50, batch_size=10) #epochs=3, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test_new, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 456)\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  5  8  9\n",
      "  7 15 16  5  9 14  9 16 16  9 12  5 11 19 17 14 12  4 15  2 14 12 14  9\n",
      " 15  3 17 15 13  9  3  2  4 12  9  7  2  9 15 15 16  2 14 15 14  9 17 13\n",
      " 13  7  6 13  0  1 16 14  4  5  4  4 13 17  7 11  6  5 17  2  8  3 16  7\n",
      "  2  3 10 17 15 17  0 11  3  4  4 15 10 15 10  3  3  8 10  8  9 19 15  2\n",
      "  2 12 16 14 16 16 14  9 15 16 15  4 11 17  8  8  3  3  7 11 11 18 14  2\n",
      " 19  9 14  9  6  1 19 12  7  2  8 19  7  6  3 18 12 15 11 12  7 12  4  8\n",
      " 11 17 17 15  8 19 15 14  3 17 14  3 17  5  4 14  7  3  3  9  7 15  3 15\n",
      "  9  5  9  3 16  2 19  9 14  8 17  9  5  3 13  5 13  6 10  0 17 11 19 19\n",
      " 12 12  1 12  3 12  3  9 16 19  5  9 12  0  6 16  2 12 11  0  9 16  7  9\n",
      "  9 13  2 15 16 17  1  5  9 13  7  9  7  2  5 13 18  4  0  7 11 12  6 12\n",
      "  2  0  4 17  7 11  7  5  2 13  9 13  0  9 15 11  5 17 19  8 15 17 18  6\n",
      " 14  0 17 16 11 16  3 10 12 14  9 15 17  0 15  4  9  1 12  0  2  1  0  7\n",
      " 10 15 12  0  8 12  9 18  3  0  3  3  2  3 15  8 12 17 19 14  2  4 16 19\n",
      "  0  3 19 19  8  8  4 18 15 14 11  9  2 13  3  6  1  9  3 11  4  9 11  6]\n",
      "(60,)\n",
      "[10, 0, 5, 8, 9, 7, 15, 16, 5, 9, 14, 9, 16, 16, 9, 12, 5, 11, 19, 17, 14, 12, 4, 15, 2, 14, 12, 14, 9, 15, 3, 17, 15, 13, 9, 3, 2, 4, 12, 9, 7, 2, 9, 15, 15, 16, 2, 14, 15, 14, 9, 17, 13, 13, 7, 6, 13, 0, 1, 16, 14, 4, 5, 4, 4, 13, 17, 7, 11, 6, 5, 17, 2, 8, 3, 16, 7, 2, 3, 10, 17, 15, 17, 0, 11, 3, 4, 4, 15, 10, 15, 10, 3, 3, 8, 10, 8, 9, 19, 15, 2, 2, 12, 16, 14, 16, 16, 14, 9, 15, 16, 15, 4, 11, 17, 8, 8, 3, 3, 7, 11, 11, 18, 14, 2, 19, 9, 14, 9, 6, 1, 19, 12, 7, 2, 8, 19, 7, 6, 3, 18, 12, 15, 11, 12, 7, 12, 4, 8, 11, 17, 17, 15, 8, 19, 15, 14, 3, 17, 14, 3, 17, 5, 4, 14, 7, 3, 3, 9, 7, 15, 3, 15, 9, 5, 9, 3, 16, 2, 19, 9, 14, 8, 17, 9, 5, 3, 13, 5, 13, 6, 10, 0, 17, 11, 19, 19, 12, 12, 1, 12, 3, 12, 3, 9, 16, 19, 5, 9, 12, 0, 6, 16, 2, 12, 11, 0, 9, 16, 7, 9, 9, 13, 2, 15, 16, 17, 1, 5, 9, 13, 7, 9, 7, 2, 5, 13, 18, 4, 0, 7, 11, 12, 6, 12, 2, 0, 4, 17, 7, 11, 7, 5, 2, 13, 9, 13, 0, 9, 15, 11, 5, 17, 19, 8, 15, 17, 18, 6, 14, 0, 17, 16, 11, 16, 3, 10, 12, 14, 9, 15, 17, 0, 15, 4, 9, 1, 12, 0, 2, 1, 0, 7, 10, 15, 12, 0, 8, 12, 9, 18, 3, 0, 3, 3, 2, 3, 15, 8, 12, 17, 19, 14, 2, 4, 16, 19, 0, 3, 19, 19, 8, 8, 4, 18, 15, 14, 11, 9, 2, 13, 3, 6, 1, 9, 3, 11, 4, 9, 11, 6]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_new.shape)\n",
    "print(X_train_new[0,:])\n",
    "print(X_train.shape)\n",
    "print(X_train[0,])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 16)                7312      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 7,457\n",
      "Trainable params: 7,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 0.5922 - acc: 0.4500\n",
      "Epoch 2/50\n",
      "60/60 [==============================] - 0s 172us/step - loss: 0.2883 - acc: 0.4500\n",
      "Epoch 3/50\n",
      "60/60 [==============================] - 0s 180us/step - loss: -0.0962 - acc: 0.4500\n",
      "Epoch 4/50\n",
      "60/60 [==============================] - 0s 181us/step - loss: -0.5720 - acc: 0.4500\n",
      "Epoch 5/50\n",
      "60/60 [==============================] - 0s 199us/step - loss: -1.1924 - acc: 0.4500\n",
      "Epoch 6/50\n",
      "60/60 [==============================] - 0s 162us/step - loss: -1.8810 - acc: 0.4500\n",
      "Epoch 7/50\n",
      "60/60 [==============================] - 0s 190us/step - loss: -2.7706 - acc: 0.4500\n",
      "Epoch 8/50\n",
      "60/60 [==============================] - 0s 247us/step - loss: -3.1656 - acc: 0.4500\n",
      "Epoch 9/50\n",
      "60/60 [==============================] - 0s 188us/step - loss: -3.4161 - acc: 0.4500\n",
      "Epoch 10/50\n",
      "60/60 [==============================] - 0s 174us/step - loss: -3.4956 - acc: 0.4500\n",
      "Epoch 11/50\n",
      "60/60 [==============================] - 0s 164us/step - loss: -3.4996 - acc: 0.4500\n",
      "Epoch 12/50\n",
      "60/60 [==============================] - 0s 165us/step - loss: -3.5007 - acc: 0.7167\n",
      "Epoch 13/50\n",
      "60/60 [==============================] - 0s 152us/step - loss: -3.5014 - acc: 0.7667\n",
      "Epoch 14/50\n",
      "60/60 [==============================] - 0s 187us/step - loss: -3.5021 - acc: 0.7667\n",
      "Epoch 15/50\n",
      "60/60 [==============================] - 0s 182us/step - loss: -3.5029 - acc: 0.7667\n",
      "Epoch 16/50\n",
      "60/60 [==============================] - 0s 158us/step - loss: -3.5038 - acc: 0.7667\n",
      "Epoch 17/50\n",
      "60/60 [==============================] - 0s 175us/step - loss: -3.5046 - acc: 0.7667\n",
      "Epoch 18/50\n",
      "60/60 [==============================] - 0s 265us/step - loss: -3.5056 - acc: 0.7667\n",
      "Epoch 19/50\n",
      "60/60 [==============================] - 0s 165us/step - loss: -3.5066 - acc: 0.7667\n",
      "Epoch 20/50\n",
      "60/60 [==============================] - 0s 160us/step - loss: -3.5074 - acc: 0.7667\n",
      "Epoch 21/50\n",
      "60/60 [==============================] - 0s 188us/step - loss: -3.5086 - acc: 0.7667\n",
      "Epoch 22/50\n",
      "60/60 [==============================] - 0s 200us/step - loss: -3.5095 - acc: 0.7667\n",
      "Epoch 23/50\n",
      "60/60 [==============================] - 0s 150us/step - loss: -3.5107 - acc: 0.7667\n",
      "Epoch 24/50\n",
      "60/60 [==============================] - 0s 175us/step - loss: -3.5119 - acc: 0.7667\n",
      "Epoch 25/50\n",
      "60/60 [==============================] - 0s 184us/step - loss: -3.5130 - acc: 0.7667\n",
      "Epoch 26/50\n",
      "60/60 [==============================] - 0s 153us/step - loss: -3.5141 - acc: 0.7667\n",
      "Epoch 27/50\n",
      "60/60 [==============================] - 0s 191us/step - loss: -3.5153 - acc: 0.7667\n",
      "Epoch 28/50\n",
      "60/60 [==============================] - 0s 183us/step - loss: -3.5165 - acc: 0.7667\n",
      "Epoch 29/50\n",
      "60/60 [==============================] - 0s 182us/step - loss: -3.5179 - acc: 0.7667\n",
      "Epoch 30/50\n",
      "60/60 [==============================] - 0s 191us/step - loss: -3.5190 - acc: 0.7667\n",
      "Epoch 31/50\n",
      "60/60 [==============================] - 0s 183us/step - loss: -3.5203 - acc: 0.7667\n",
      "Epoch 32/50\n",
      "60/60 [==============================] - 0s 234us/step - loss: -3.5216 - acc: 0.7667\n",
      "Epoch 33/50\n",
      "60/60 [==============================] - 0s 223us/step - loss: -3.5230 - acc: 0.7667\n",
      "Epoch 34/50\n",
      "60/60 [==============================] - 0s 206us/step - loss: -3.5244 - acc: 0.7667\n",
      "Epoch 35/50\n",
      "60/60 [==============================] - 0s 172us/step - loss: -3.5258 - acc: 0.7667\n",
      "Epoch 36/50\n",
      "60/60 [==============================] - 0s 215us/step - loss: -3.5271 - acc: 0.7667\n",
      "Epoch 37/50\n",
      "60/60 [==============================] - 0s 173us/step - loss: -3.5285 - acc: 0.7667\n",
      "Epoch 38/50\n",
      "60/60 [==============================] - 0s 150us/step - loss: -3.5300 - acc: 0.7667\n",
      "Epoch 39/50\n",
      "60/60 [==============================] - 0s 213us/step - loss: -3.5315 - acc: 0.7667\n",
      "Epoch 40/50\n",
      "60/60 [==============================] - 0s 170us/step - loss: -3.5329 - acc: 0.7667\n",
      "Epoch 41/50\n",
      "60/60 [==============================] - 0s 194us/step - loss: -3.5343 - acc: 0.7667\n",
      "Epoch 42/50\n",
      "60/60 [==============================] - 0s 199us/step - loss: -3.5359 - acc: 0.7667\n",
      "Epoch 43/50\n",
      "60/60 [==============================] - 0s 182us/step - loss: -3.5375 - acc: 0.7667\n",
      "Epoch 44/50\n",
      "60/60 [==============================] - 0s 221us/step - loss: -3.5389 - acc: 0.7667\n",
      "Epoch 45/50\n",
      "60/60 [==============================] - 0s 192us/step - loss: -3.5404 - acc: 0.7667\n",
      "Epoch 46/50\n",
      "60/60 [==============================] - 0s 198us/step - loss: -3.5421 - acc: 0.7667\n",
      "Epoch 47/50\n",
      "60/60 [==============================] - 0s 175us/step - loss: -3.5433 - acc: 0.7667\n",
      "Epoch 48/50\n",
      "60/60 [==============================] - 0s 212us/step - loss: -3.5450 - acc: 0.7667\n",
      "Epoch 49/50\n",
      "60/60 [==============================] - 0s 299us/step - loss: -3.5467 - acc: 0.7667\n",
      "Epoch 50/50\n",
      "60/60 [==============================] - 0s 237us/step - loss: -3.5481 - acc: 0.7667\n",
      "acc: 68.75%\n"
     ]
    }
   ],
   "source": [
    "# Initializing the Sequential model from KERAS.\n",
    "model2 = Sequential()\n",
    "\n",
    "max_review_length = len(max(X, key=len))\n",
    "\n",
    "# Creating a 16 neuron hidden layer with Linear Rectified activation function.\n",
    "#model.add(Dense(16, input_dim=1, init='uniform', activation='relu'))\n",
    "model2.add(Dense(16, input_dim=max_review_length, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "# Creating a 8 neuron hidden layer.\n",
    "model2.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "# Adding a output layer.\n",
    "model2.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "# Compiling the model\n",
    "model2.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model2.summary())\n",
    "\n",
    "# Fitting the model\n",
    "#model.fit(X, Y, nb_epoch=150, batch_size=10)\n",
    "#scores = model.evaluate(X, Y)\n",
    "model2.fit(X_train_new, y_train, epochs=50, batch_size=10)\n",
    "scores = model2.evaluate(X_test_new, y_test, verbose=0)\n",
    "\n",
    "print(\"%s: %.2f%%\" % (model2.metrics_names[1], scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
